{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NoPeekNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "goi4DjQZ8PCt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "129dadc5-f4c6-44ff-c7a1-534db35c696b"
      },
      "source": [
        "! pip install syft"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting syft\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/2e/16bdefc78eb089e1efa9704c33b8f76f035a30dc935bedd7cbb22f6dabaa/syft-0.1.21a1-py3-none-any.whl (219kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 5.0MB/s \n",
            "\u001b[?25hCollecting msgpack>=0.6.1 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/7e/ae9e91c1bb8d846efafd1f353476e3fd7309778b582d2fb4cea4cc15b9a2/msgpack-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 45.7MB/s \n",
            "\u001b[?25hCollecting websocket-client>=0.56.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 40.8MB/s \n",
            "\u001b[?25hCollecting websockets>=7.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/5e/2fe6afbb796c6ac5c006460b5503cd674d33706660337f2dbff10d4aa12d/websockets-8.0-cp36-cp36m-manylinux1_x86_64.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 22.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Collecting flask-socketio>=3.3.2 (from syft)\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/68/fe4806d3a0a5909d274367eb9b3b87262906c1515024f46c2443a36a0c82/Flask_SocketIO-4.1.0-py2.py3-none-any.whl\n",
            "Collecting tf-encrypted>=0.5.4 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/ce/da9916e7e78f736894b15538b702c0b213fd5d60a7fd6e481d74033a90c0/tf_encrypted-0.5.6-py3-none-manylinux1_x86_64.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 46.8MB/s \n",
            "\u001b[?25hCollecting zstd>=1.4.0.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/27/1ea8086d37424e83ab692015cc8dd7d5e37cf791e339633a40dc828dfb74/zstd-1.4.0.0.tar.gz (450kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 46.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Collecting lz4>=2.1.6 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 46.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.16.4)\n",
            "Requirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.1)\n",
            "Requirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.21.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client>=0.56.0->syft) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (4.3.0)\n",
            "Collecting python-socketio>=2.1.0 (from flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/1b/57e860a86f2a01be86ae1dacfa0cd8c4dfbfcd4593322268b61b5a07b564/python_socketio-4.2.0-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 22.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Collecting pyyaml>=5.1 (from tf-encrypted>=0.5.4->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/837fefac7475963d1eccf4aa684c23b95aa6c1d033a2c5965ccb11e22623/PyYAML-5.1.1.tar.gz (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 45.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (0.15.4)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (2.10.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (7.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (0.13.2)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->syft) (0.46)\n",
            "Collecting python-engineio>=3.8.0 (from python-socketio>=2.1.0->flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/b8/0fc389ca5c445051b37b17802f80bbf1b51c1e3b48b772ee608efbb90583/python_engineio-3.8.2.post1-py2.py3-none-any.whl (119kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 45.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.7.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.1.7)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.11.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=1.0.2->syft) (1.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (2.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.1.1)\n",
            "Building wheels for collected packages: zstd, pyyaml\n",
            "  Building wheel for zstd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/9a/f4/3105b5209674ac77fcca7fede95184c62a95df0196888e0e76\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/27/a1/775c62ddea7bfa62324fd1f65847ed31c55dadb6051481ba3f\n",
            "Successfully built zstd pyyaml\n",
            "Installing collected packages: msgpack, websocket-client, websockets, python-engineio, python-socketio, flask-socketio, pyyaml, tf-encrypted, zstd, lz4, syft\n",
            "  Found existing installation: msgpack 0.5.6\n",
            "    Uninstalling msgpack-0.5.6:\n",
            "      Successfully uninstalled msgpack-0.5.6\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed flask-socketio-4.1.0 lz4-2.1.10 msgpack-0.6.1 python-engineio-3.8.2.post1 python-socketio-4.2.0 pyyaml-5.1.1 syft-0.1.21a1 tf-encrypted-0.5.6 websocket-client-0.56.0 websockets-8.0 zstd-1.4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAtZf94FyoRR",
        "colab_type": "text"
      },
      "source": [
        "### DISTANCE CORRELATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL0BJSEWIS2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OQ5u_b5GCISS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "1e221dc4-8dc6-4e22-d966-7514d853aa70"
      },
      "source": [
        "import syft as sy  # <-- NEW: import the Pysyft library\n",
        "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")  # <-- NEW: define remote worker bob\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")  # <-- NEW: and alice"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0712 09:44:33.994026 139926403164032 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0712 09:44:34.012714 139926403164032 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0oACLZaE3U7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dist_matrix(X,remote=True):\n",
        "  N = X.shape[0]\n",
        "  #print(\"N=\",N)\n",
        "  dist = torch.zeros(N,N)\n",
        "  #print('X size:',X.size())\n",
        "  X = X.view(N,-1)\n",
        "  #print(X.location.id)\n",
        "  if remote:\n",
        "    dist = dist.send(X.location.id)\n",
        "  #print('dist',dist.location.id)\n",
        "  #print(X.shape)\n",
        "  #print(X.size())\n",
        "  for i in range(N):\n",
        "    for j in range(i,N):\n",
        "      #x1_norm = (X[i]**2).sum().view(-1, 1)\n",
        "      #x2_norm = (X[j]**2).sum().view(-1, 1)\n",
        "      #dist[i,j] = x1_norm + x2_norm - 2.0 * torch.matmul(X[i], X[j])\n",
        "     # print(X.size())\n",
        "      tmp = torch.matmul((X[i]-X[j]).t(),(X[i]-X[j]))\n",
        "      #print(tmp.location.id)\n",
        "      dist[i,j] = tmp   \n",
        "      dist[j,i] = dist[i,j]\n",
        "  return dist\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skESsf9pPnQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def a_dot_l(dist,remote):\n",
        "  N = dist.shape[0]\n",
        "  a_l = torch.zeros(N)\n",
        "  if remote:\n",
        "    a_l = a_l.send(dist.location.id)\n",
        "  for l in range(N):\n",
        "    #print(a_l)\n",
        "    #print(a_l[l])\n",
        "    #print(dist[:,l])\n",
        "    tmp = dist[:,l].sum()\n",
        "    l = torch.tensor(l)\n",
        "    l = l.send(bob)\n",
        "    a_l[l] = tmp\n",
        "  return  1./N*a_l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaz1kYpQRDfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def a_k_dot(dist,remote):\n",
        "  N = dist.shape[0]\n",
        "  a_k = torch.zeros(N)\n",
        "  if remote:\n",
        "    a_k = a_k.send(dist.location.id)\n",
        "  for k in range(N):\n",
        "    k = torch.tensor(k)\n",
        "    k = k.send(bob)\n",
        "    a_k[k] = dist[k,:].sum()\n",
        "  return  1./N*a_k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1nMuQBNF-W7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def A_matrix(dist,remote):\n",
        "  N = dist.shape[0]\n",
        "  A = dist\n",
        "  a_l = a_dot_l(dist,remote)\n",
        "  a_k = a_k_dot(dist,remote)\n",
        "  for k in range(N):\n",
        "    A[k,:] -= a_l\n",
        "    A[:,k] -= a_k\n",
        "  I = torch.ones(N,N).send(dist.location.id)\n",
        "  a_dot = 1/N**2*dist.sum()*I\n",
        "  A += a_dot\n",
        "  return A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMErNRneCcyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def distance_covariance(X,Y,remote=True):\n",
        "  dist_x = dist_matrix(X,remote) \n",
        "  dist_y = dist_matrix(Y,remote)\n",
        "  N = dist_x.shape[0]\n",
        "  A = A_matrix(dist_x,remote)\n",
        "  B = A_matrix(dist_y,remote)\n",
        "  C = A*B\n",
        "  return 1/N**2*C.sum()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjaB0iDhKHLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def distance_variance(X,remote):\n",
        "  dist_x = dist_matrix(X,remote) \n",
        "  N = dist_x.shape[0]\n",
        "  A = A_matrix(dist_x,remote)\n",
        "  #print(A)\n",
        "  return 1/N**2*(A**2).sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4UHnYyzLVis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def distance_correlation(X,Y,remote=True):\n",
        "  cov = distance_covariance(X,Y,remote)\n",
        "  #print(cov)\n",
        "  V_x = distance_variance(X,remote)\n",
        "  V_y = distance_variance(Y,remote)\n",
        "  #print(V_x,V_y)\n",
        "  corr = cov/torch.sqrt(V_x*V_y)\n",
        "  return corr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAzbZQIaR96w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_dcor(X,Y,remote=True):\n",
        "  return np.log(distance_correlation(X,Y,remote))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SvwVEvtJjvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_dcor(X,Y,remote):\n",
        "  #n = len(X.size())\n",
        "  n = len(X.shape)\n",
        "  a = X.shape[0]\n",
        "  #print(X.size())\n",
        "  X_new = X.view(a,-1)\n",
        "  Y_new = Y.view(a,-1)\n",
        "  return distance_correlation(X_new,Y_new,remote)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFBi4a3dmCy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_log_dcor(X,Y,remote):\n",
        "  return np.log(batch_dcor(X,Y,remote))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4e5fXNDlMfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(0)\n",
        "X = torch.randn(5,20,20)\n",
        "\n",
        "torch.manual_seed(1)\n",
        "Y = torch.randn(5,20,20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kr6KMgBBCRXd"
      },
      "source": [
        "### NoPeekNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QbQ04GjBCRXf",
        "colab": {}
      },
      "source": [
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 64\n",
        "        self.test_batch_size = 1000\n",
        "        self.epochs = 10\n",
        "        self.lr = 0.01\n",
        "        self.momentum = 0.5\n",
        "        self.no_cuda = False\n",
        "        self.seed = 1\n",
        "        self.log_interval = 30\n",
        "        self.save_model = False\n",
        "\n",
        "args = Arguments()\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "if use_cuda:\n",
        "        # TODO Quickhack. Actually need to fix the problem moving the model to CUDA\\n\",\n",
        "        torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "#device = torch.device(\"cpu\")\n",
        "\n",
        "#kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "kwargs = {'num_workers': 0, 'pin_memory': False} if use_cuda else {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4012c0a7-709b-4158-de9d-98b66018c02f",
        "id": "0ZKD-LEFCRXj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n",
        "    .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
        "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=args.test_batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9912422 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 23995116.26it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 367336.51it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 5423743.67it/s]                           \n",
            "8192it [00:00, 140984.43it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "th_L8BehCRXp",
        "colab": {}
      },
      "source": [
        "class Net1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net1, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        return F.max_pool2d(x, 2, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "boSVyHAVCRXw",
        "colab": {}
      },
      "source": [
        "class Net2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net2, self).__init__()\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-AiVVo6rCRXy",
        "colab": {}
      },
      "source": [
        "models = [Net1().to(device), Net1().to(device)]\n",
        "#models = [Net1(), Net1()]\n",
        "models[0] = models[0].send(bob)\n",
        "models[1] = models[1].send(alice)\n",
        "\n",
        "\n",
        "\n",
        "opt1 = optim.SGD(params=models[0].parameters(),lr=0.1)\n",
        "opt2 = optim.SGD(params=models[1].parameters(),lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-WUGy0weCRX0",
        "colab": {}
      },
      "source": [
        "def train(args, model, device, federated_train_loader, optimizer, epoch, alpha1=0.1,alpha2=0.9):\n",
        "    model.train()\n",
        "    for batch_idx, (data, targs) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
        "        #IF ON DATA LOCATION TO GET THE RIGHT MODEL\n",
        "        if data.location.id == 'bob':\n",
        "          mod_c,opt_c = models[0], opt1\n",
        "        else : \n",
        "          mod_c,opt_c = models[1], opt2\n",
        "        \n",
        "        #print(\"data\",data.clone().get().size())\n",
        "        #1) erase previous gradients (if they exist)\n",
        "        optimizer.step()\n",
        "        opt_c.step()\n",
        "        opt_c.zero_grad()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        tg_copy = targs.copy()\n",
        "        target = tg_copy.get()\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        # 2) make a prediction until cut layer (client location)\n",
        "        pred_c = mod_c(data)\n",
        "        copy = pred_c.copy()\n",
        "        \n",
        "\n",
        "        \n",
        "        \n",
        "        # 3) get this to the server \n",
        "        inp = copy.get()\n",
        "\n",
        "        # compute the distance correlation\n",
        "        dist = batch_dcor(data,pred_c,remote=True)\n",
        "        dist.backward(create_graph=True)\n",
        "        \n",
        "        \n",
        "        # 4) make prediction with second part of the model (server location)\n",
        "        pred = model(inp)\n",
        "\n",
        "        # 5) calculate how much we missed \n",
        "        loss = F.nll_loss(pred, target)\n",
        "        loss.backward()\n",
        "        #print(dist.grad)\n",
        "        print(inp.grad)\n",
        "        #gradient = alpha1*dist.grad + alpha2*inp.grad\n",
        "        gradient = inp.grad\n",
        "        gradient = gradient.send(data.location)\n",
        "        print(gradient.shape)\n",
        "        #dist.backward()\n",
        "        pred_c.backward(gradient)\n",
        "        \n",
        "        \n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            #loss = loss.get() # <-- NEW: get the loss back\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} \\tDCor:'.format(\n",
        "                epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,\n",
        "                100. * batch_idx / len(federated_train_loader), loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wOPCfF0_BbJE",
        "colab": {}
      },
      "source": [
        "def train(args, model, device, federated_train_loader, optimizer, epoch, alpha1=0.1,alpha2=0.9):\n",
        "    model.train()\n",
        "    for batch_idx, (data, targs) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
        "        #IF ON DATA LOCATION TO GET THE RIGHT MODEL\n",
        "        if data.location.id == 'bob':\n",
        "          mod_c,opt_c = models[0], opt1\n",
        "        else : \n",
        "          mod_c,opt_c = models[1], opt2\n",
        "        \n",
        "        #print(\"data\",data.clone().get().size())\n",
        "       # 1) erase previous gradients (if they exist)\n",
        "        optimizer.step()\n",
        "        opt_c.step()\n",
        "        opt_c.zero_grad()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        tg_copy = targs.copy()\n",
        "        target = tg_copy.get()\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        # 2) make a prediction until cut layer (client location)\n",
        "        #pred_c = mod_c(data)\n",
        "        #copy = pred_c.copy()\n",
        "        \n",
        "\n",
        "        \n",
        "        \n",
        "        # 3) get this to the server \n",
        "        #inp = copy.get()\n",
        "        X = data.clone().get()\n",
        "        M = mod_c.copy()\n",
        "        #M = M.get()\n",
        "        #print(mod_c)\n",
        "        inp =M(X)\n",
        "        # compute the distance correlation\n",
        "        dcor = batch_dcor(X,inp)\n",
        "        dcor.backward(retain_graph=True)\n",
        "        print(\"dcor\",dcor)\n",
        "        \n",
        "        # 4) make prediction with second part of the model (server location)\n",
        "        pred = model(inp)\n",
        "\n",
        "        # 5) calculate how much we missed \n",
        "        loss = F.nll_loss(pred, target)\n",
        "        loss.backward()\n",
        "        #print(dcor.grad)\n",
        "        #print(inp.grad)\n",
        "        #gradient = alpha1*dcor.grad + alpha2*inp.grad\n",
        "        #gradient = gradient.send(data.location)\n",
        "        #dist.backward()\n",
        "        #pred_c.backward(gradient)\n",
        "        \n",
        "        \n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            #loss = loss.get() # <-- NEW: get the loss back\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} \\tDCor :'.format(\n",
        "                epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,\n",
        "                100. * batch_idx / len(federated_train_loader), loss.item(),dcor.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5gP68QJwCRX1",
        "colab": {}
      },
      "source": [
        "def test(args, model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    M1 = models[0].copy()\n",
        "    M2 = models[1].copy()\n",
        "    M1 = M1.get()\n",
        "    M2 = M2.get()\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(M1(data))\n",
        "            #output2 = model(M2(data))\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "45ee4ed4-cc34-4b92-a834-719e43e1f1da",
        "id": "fn_AncP2CRX3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "model = Net2().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(args, model, device, federated_train_loader, optimizer, epoch)\n",
        "    test(args, model, device, test_loader)\n",
        "\n",
        "if (args.save_model):\n",
        "    torch.save(model.state_dict(), \"mnist_cnn.pt\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[ 4.9752e-06,  7.4517e-06, -8.4466e-06,  ..., -2.8684e-06,\n",
            "           -5.0234e-08,  4.1778e-06],\n",
            "          [-7.3676e-06,  2.2317e-06, -2.8635e-07,  ..., -1.4061e-05,\n",
            "            2.5435e-06,  2.3895e-06],\n",
            "          [-2.3287e-05,  6.9854e-06,  3.5475e-05,  ..., -1.6095e-05,\n",
            "           -6.3854e-06,  3.9669e-06],\n",
            "          ...,\n",
            "          [-1.0427e-05,  1.6473e-06,  1.6383e-05,  ..., -1.2764e-05,\n",
            "           -6.8108e-06,  9.6995e-06],\n",
            "          [-1.6151e-06, -7.7561e-06,  9.7921e-06,  ...,  4.5062e-05,\n",
            "            2.2536e-06, -3.5593e-05],\n",
            "          [ 3.1657e-06, -2.7025e-07, -1.1114e-05,  ..., -1.3155e-06,\n",
            "            1.7459e-05, -2.0189e-06]],\n",
            "\n",
            "         [[-6.6879e-06, -1.9316e-05, -1.0677e-05,  ...,  1.6253e-05,\n",
            "            7.0103e-07,  3.4035e-06],\n",
            "          [ 1.6189e-05,  1.9798e-05, -1.0862e-05,  ..., -3.3709e-06,\n",
            "           -1.9081e-05,  2.8781e-06],\n",
            "          [ 3.1082e-05,  3.9036e-05,  9.1551e-06,  ...,  9.8036e-06,\n",
            "            3.4379e-05,  2.1815e-06],\n",
            "          ...,\n",
            "          [ 2.6868e-05, -1.0271e-05,  1.0663e-05,  ..., -1.9751e-05,\n",
            "            2.7212e-05, -6.0413e-06],\n",
            "          [ 1.4995e-05, -7.2382e-06, -2.0918e-06,  ...,  2.0516e-05,\n",
            "            2.6679e-05,  8.9607e-06],\n",
            "          [-1.1705e-05,  8.3407e-06,  1.3587e-05,  ...,  3.3810e-05,\n",
            "           -1.2450e-05,  3.0038e-06]],\n",
            "\n",
            "         [[-2.7947e-06, -3.9662e-06,  2.1801e-06,  ..., -1.7613e-05,\n",
            "            6.5799e-06,  2.4996e-06],\n",
            "          [-6.2028e-06,  2.2808e-05, -1.6724e-05,  ..., -7.6187e-06,\n",
            "            1.1557e-05, -8.8441e-06],\n",
            "          [-1.4379e-05,  5.6351e-06,  1.9192e-05,  ..., -5.8224e-06,\n",
            "            2.4343e-05,  4.3505e-06],\n",
            "          ...,\n",
            "          [-2.9034e-05, -5.3859e-06, -4.7907e-05,  ...,  1.2638e-05,\n",
            "            3.4665e-05, -2.0471e-05],\n",
            "          [ 5.0215e-06, -2.2253e-06,  2.5463e-07,  ..., -2.6098e-05,\n",
            "           -1.3572e-05,  3.2481e-05],\n",
            "          [-1.3097e-05, -6.9625e-06, -2.8213e-05,  ...,  2.5160e-05,\n",
            "           -1.2113e-05,  3.6480e-06]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.9140e-06, -1.2313e-05,  2.0439e-05,  ...,  1.7567e-05,\n",
            "           -6.6751e-06,  2.6585e-06],\n",
            "          [-2.6905e-06,  3.2528e-06,  1.7422e-06,  ..., -1.5851e-05,\n",
            "           -8.3451e-06, -1.0771e-05],\n",
            "          [-1.7525e-06,  1.3767e-05,  3.4306e-05,  ...,  2.7423e-05,\n",
            "           -5.0152e-05,  1.4132e-05],\n",
            "          ...,\n",
            "          [ 2.8539e-05,  1.8727e-05, -7.1365e-05,  ..., -1.8773e-05,\n",
            "            2.5201e-05, -2.9016e-05],\n",
            "          [ 5.9233e-06,  1.1747e-05, -1.2689e-05,  ...,  1.7064e-05,\n",
            "            1.3173e-05,  1.1479e-05],\n",
            "          [-4.6339e-06,  3.3432e-06,  2.3097e-05,  ...,  7.8298e-06,\n",
            "           -7.4418e-06,  5.2798e-06]],\n",
            "\n",
            "         [[ 9.7987e-06,  7.3264e-06, -9.9255e-06,  ..., -1.4196e-05,\n",
            "            1.2816e-05,  1.8834e-06],\n",
            "          [-1.5701e-05, -7.4111e-06, -2.2664e-06,  ...,  4.5839e-05,\n",
            "           -1.7216e-05,  1.2896e-05],\n",
            "          [ 1.2190e-05, -1.5979e-06, -9.5819e-07,  ..., -3.0051e-06,\n",
            "           -2.2209e-05,  5.2433e-06],\n",
            "          ...,\n",
            "          [-3.0876e-05, -1.6392e-05, -1.9535e-05,  ..., -9.4229e-06,\n",
            "           -4.9743e-06, -9.5251e-06],\n",
            "          [ 7.9190e-06, -6.9241e-06, -1.4119e-05,  ..., -7.8730e-06,\n",
            "           -2.5963e-05,  1.6038e-06],\n",
            "          [ 9.1952e-06,  1.4813e-05,  1.0330e-06,  ...,  1.0032e-05,\n",
            "           -2.9051e-05, -1.9239e-05]],\n",
            "\n",
            "         [[ 1.1181e-05, -1.4441e-05,  1.1926e-06,  ...,  4.4887e-06,\n",
            "            2.1212e-06, -1.7285e-06],\n",
            "          [-3.6861e-06, -1.9955e-05,  1.2511e-05,  ..., -2.9234e-05,\n",
            "           -1.5939e-05,  3.8398e-06],\n",
            "          [-1.2881e-05, -4.4080e-06,  1.2798e-05,  ..., -2.1720e-05,\n",
            "            5.1743e-05, -4.3952e-06],\n",
            "          ...,\n",
            "          [ 6.2058e-06, -3.0073e-05, -2.8697e-05,  ..., -7.7473e-06,\n",
            "            3.7143e-05,  1.2433e-05],\n",
            "          [-1.6122e-05, -4.0178e-05,  1.8943e-05,  ..., -1.5659e-05,\n",
            "            3.3869e-07,  2.7353e-05],\n",
            "          [ 6.3915e-06, -4.5395e-06,  3.0930e-05,  ..., -3.4774e-06,\n",
            "           -3.1450e-06, -7.7981e-06]]],\n",
            "\n",
            "\n",
            "        [[[-8.3161e-06, -8.1031e-06,  6.5048e-06,  ...,  3.8939e-06,\n",
            "           -5.5544e-06, -3.1270e-06],\n",
            "          [-5.0707e-07, -4.4567e-05,  5.2521e-05,  ..., -1.7541e-05,\n",
            "            4.3083e-05, -1.1491e-06],\n",
            "          [-9.0524e-06, -2.9965e-05,  3.1255e-05,  ...,  3.4254e-05,\n",
            "            1.9808e-06,  1.1404e-05],\n",
            "          ...,\n",
            "          [-2.8858e-06,  1.8772e-05, -2.3940e-05,  ...,  4.0779e-05,\n",
            "            1.8441e-05,  1.4134e-05],\n",
            "          [-5.2183e-06,  1.3642e-05,  1.8232e-05,  ...,  2.5542e-05,\n",
            "            2.2452e-05, -3.4467e-05],\n",
            "          [-1.4445e-05,  8.1936e-06, -1.9481e-05,  ..., -2.4482e-05,\n",
            "            1.3831e-05,  2.4296e-06]],\n",
            "\n",
            "         [[ 8.5669e-06, -1.9072e-05, -1.6426e-06,  ...,  1.3142e-06,\n",
            "           -2.3461e-05, -6.2929e-07],\n",
            "          [ 7.6205e-06, -1.2318e-05,  2.2500e-05,  ...,  2.9081e-07,\n",
            "            8.0255e-06,  1.9164e-05],\n",
            "          [ 1.1615e-06,  6.8511e-06,  4.2541e-05,  ..., -1.5220e-05,\n",
            "            7.3756e-06, -6.9491e-06],\n",
            "          ...,\n",
            "          [ 1.7412e-05,  2.1090e-05,  3.1321e-05,  ...,  1.7537e-05,\n",
            "           -5.3109e-06, -4.6321e-06],\n",
            "          [ 1.4766e-06, -1.8400e-05, -1.5165e-05,  ...,  1.4617e-05,\n",
            "           -2.0444e-05,  8.8855e-07],\n",
            "          [-1.6932e-05,  1.2139e-05, -4.1613e-06,  ..., -1.3764e-06,\n",
            "           -2.4854e-05, -6.4745e-06]],\n",
            "\n",
            "         [[ 1.2188e-05,  8.1208e-06,  4.2066e-06,  ..., -5.2151e-07,\n",
            "           -2.0491e-05,  1.2490e-05],\n",
            "          [-3.9404e-06, -1.1540e-05,  5.8225e-06,  ...,  1.3496e-05,\n",
            "            3.0625e-06, -6.6572e-06],\n",
            "          [ 2.0597e-05, -8.2150e-06, -4.9840e-05,  ..., -4.0778e-05,\n",
            "           -4.5684e-05,  7.7307e-07],\n",
            "          ...,\n",
            "          [-1.7530e-05, -1.4240e-05, -1.3415e-05,  ...,  6.1241e-06,\n",
            "           -2.2731e-05, -4.8131e-06],\n",
            "          [ 9.2259e-06, -9.8697e-06, -2.3713e-05,  ..., -1.7582e-05,\n",
            "           -3.5495e-05,  3.0933e-05],\n",
            "          [-1.2279e-05, -1.7035e-05,  3.2388e-05,  ...,  1.6609e-08,\n",
            "            2.7411e-05,  2.6316e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3008e-05, -1.3510e-05, -1.3288e-05,  ..., -3.1215e-05,\n",
            "           -9.8854e-06,  3.0257e-06],\n",
            "          [-1.7140e-05,  3.6501e-06,  3.2288e-05,  ..., -1.9684e-05,\n",
            "           -2.3254e-07, -1.8270e-05],\n",
            "          [-5.8993e-06,  2.5013e-05,  2.1465e-05,  ...,  2.2947e-05,\n",
            "           -9.7834e-06, -1.0278e-05],\n",
            "          ...,\n",
            "          [ 1.9100e-05, -2.2465e-07,  3.9689e-05,  ...,  9.4560e-06,\n",
            "           -3.7730e-05, -3.0602e-05],\n",
            "          [-3.2432e-07,  3.7984e-05,  7.4423e-06,  ..., -3.9732e-05,\n",
            "           -6.0649e-06, -9.8526e-06],\n",
            "          [ 5.6724e-06, -3.2552e-05,  9.6739e-06,  ..., -6.0334e-06,\n",
            "           -5.0909e-06, -9.0874e-06]],\n",
            "\n",
            "         [[ 8.9610e-08,  2.5578e-05, -1.7516e-05,  ..., -1.5440e-05,\n",
            "            4.8112e-06,  9.2614e-06],\n",
            "          [-1.6054e-05, -1.3498e-05,  1.9571e-06,  ..., -1.4027e-05,\n",
            "           -1.5419e-05,  8.8473e-06],\n",
            "          [ 4.4703e-06,  2.1263e-06,  5.0842e-05,  ..., -2.8928e-05,\n",
            "            3.7758e-05, -7.7995e-06],\n",
            "          ...,\n",
            "          [-1.7325e-05,  2.9932e-05,  6.6501e-06,  ..., -1.8144e-05,\n",
            "            1.7330e-05,  5.3283e-07],\n",
            "          [-1.4478e-06, -1.5537e-05, -6.1238e-05,  ..., -1.6851e-05,\n",
            "           -3.3948e-06, -3.1003e-06],\n",
            "          [ 1.6606e-05,  1.6788e-05, -7.6107e-06,  ..., -1.6900e-05,\n",
            "            2.0959e-05,  4.0445e-06]],\n",
            "\n",
            "         [[-1.0998e-05,  8.6399e-06, -4.6736e-06,  ..., -2.0236e-05,\n",
            "            2.3850e-05, -6.9130e-06],\n",
            "          [-2.9867e-06,  1.3586e-05,  5.8579e-05,  ..., -1.8192e-05,\n",
            "           -2.4258e-05, -1.8460e-06],\n",
            "          [ 2.6263e-06, -2.8334e-05,  8.3714e-06,  ...,  3.8285e-06,\n",
            "           -2.7580e-05, -2.7617e-05],\n",
            "          ...,\n",
            "          [-1.3339e-05,  2.4920e-05, -3.3268e-05,  ...,  3.0495e-05,\n",
            "            2.6096e-05,  2.0741e-06],\n",
            "          [ 9.6900e-07,  1.5815e-05,  3.1013e-05,  ..., -3.3114e-05,\n",
            "           -7.3979e-06,  4.9473e-06],\n",
            "          [-1.2140e-05, -1.1880e-05,  2.3706e-05,  ...,  8.2716e-06,\n",
            "            8.8333e-06, -3.8660e-06]]],\n",
            "\n",
            "\n",
            "        [[[-4.9702e-06, -2.5502e-06,  5.4076e-06,  ...,  9.9425e-06,\n",
            "           -2.2311e-07,  1.0760e-05],\n",
            "          [-2.0445e-06, -3.4296e-05, -1.7340e-05,  ..., -4.4899e-06,\n",
            "            1.0132e-05,  2.8802e-05],\n",
            "          [-1.1304e-05, -1.3333e-05,  3.2448e-05,  ..., -2.6453e-05,\n",
            "            1.3783e-05,  1.1102e-05],\n",
            "          ...,\n",
            "          [ 4.1441e-06, -4.4593e-05, -7.2705e-06,  ...,  2.8598e-05,\n",
            "            4.1778e-05,  4.3220e-06],\n",
            "          [-2.1949e-05,  1.0107e-05,  1.2658e-05,  ...,  5.2855e-06,\n",
            "            2.8705e-05, -1.3101e-05],\n",
            "          [ 4.9571e-06, -3.4957e-06, -2.9569e-06,  ..., -3.0021e-06,\n",
            "            1.3658e-05, -3.0694e-06]],\n",
            "\n",
            "         [[ 7.1123e-06, -1.0484e-05, -1.6240e-05,  ..., -4.6471e-06,\n",
            "            1.1396e-05, -2.7574e-06],\n",
            "          [-1.4490e-05,  6.9233e-06,  1.5540e-05,  ...,  2.5013e-05,\n",
            "           -3.5967e-06, -2.4947e-05],\n",
            "          [-1.1347e-05,  2.8836e-05,  4.5932e-05,  ...,  2.8764e-05,\n",
            "            1.3876e-05,  2.0724e-05],\n",
            "          ...,\n",
            "          [-1.1251e-05, -1.5899e-05,  6.4275e-05,  ...,  5.4628e-06,\n",
            "           -9.3038e-06,  1.4611e-05],\n",
            "          [-2.8439e-06, -2.8888e-05,  1.2849e-05,  ...,  1.0285e-05,\n",
            "           -1.6194e-05, -6.9265e-06],\n",
            "          [-1.1346e-06,  3.9061e-06, -2.6909e-05,  ...,  7.1309e-06,\n",
            "           -1.1241e-05, -1.8656e-06]],\n",
            "\n",
            "         [[ 7.5388e-06,  1.6158e-05,  6.8064e-06,  ...,  1.1926e-05,\n",
            "           -1.1836e-05, -2.3370e-05],\n",
            "          [-3.0714e-05, -3.5311e-05, -6.3062e-06,  ...,  6.4220e-06,\n",
            "           -2.4429e-05,  8.0246e-06],\n",
            "          [-4.9630e-06,  5.5554e-06, -7.4981e-06,  ...,  5.5437e-06,\n",
            "           -1.0970e-05, -3.0542e-05],\n",
            "          ...,\n",
            "          [ 1.7837e-06, -2.1884e-05, -6.2999e-06,  ..., -6.1068e-06,\n",
            "           -2.6735e-05, -2.2106e-05],\n",
            "          [-1.1731e-05, -1.3711e-05, -3.9029e-05,  ..., -7.8365e-06,\n",
            "            1.3387e-06,  1.6912e-05],\n",
            "          [-4.5766e-08,  3.1730e-05,  9.7771e-06,  ..., -1.8684e-05,\n",
            "            7.6041e-06, -1.6391e-06]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1007e-05, -2.4854e-05,  5.9147e-06,  ..., -1.2867e-05,\n",
            "           -2.0433e-05, -1.3160e-06],\n",
            "          [ 6.4721e-07,  4.0409e-05,  3.5844e-05,  ..., -4.8281e-06,\n",
            "           -6.5021e-06,  1.1635e-05],\n",
            "          [-2.1710e-05, -6.9286e-06,  4.0178e-05,  ..., -3.4145e-05,\n",
            "            1.3992e-06,  4.3266e-06],\n",
            "          ...,\n",
            "          [ 4.9672e-06,  4.4623e-06, -2.1408e-05,  ..., -1.5033e-05,\n",
            "           -1.1195e-05, -1.2224e-05],\n",
            "          [-1.9478e-06,  3.3348e-05, -1.5912e-05,  ...,  2.3706e-05,\n",
            "           -1.7954e-05, -1.0099e-06],\n",
            "          [-6.3404e-06,  7.6644e-06, -3.0485e-05,  ..., -9.1139e-06,\n",
            "           -9.2186e-06,  1.6715e-06]],\n",
            "\n",
            "         [[-1.2479e-05,  5.3336e-06, -1.3390e-05,  ..., -9.7907e-06,\n",
            "            1.3913e-05, -6.6659e-06],\n",
            "          [ 7.4395e-06,  7.7127e-06,  2.5011e-05,  ..., -2.3934e-05,\n",
            "            2.8742e-06, -2.7405e-05],\n",
            "          [ 1.8147e-05,  2.3260e-06,  4.2402e-05,  ...,  4.5061e-05,\n",
            "           -2.0243e-05, -1.0226e-05],\n",
            "          ...,\n",
            "          [ 4.4481e-06,  2.3107e-05, -6.1904e-06,  ...,  9.0518e-07,\n",
            "           -1.3845e-05,  2.1947e-06],\n",
            "          [ 3.6903e-06, -6.7106e-06,  1.1895e-05,  ..., -1.4624e-05,\n",
            "            8.4169e-06,  2.2696e-06],\n",
            "          [ 1.6326e-06, -1.2553e-05, -3.0051e-06,  ..., -2.6616e-05,\n",
            "            4.9730e-06, -3.8881e-06]],\n",
            "\n",
            "         [[-9.9664e-06, -5.7323e-06,  1.6003e-05,  ..., -1.5813e-05,\n",
            "           -1.0402e-05,  1.2895e-05],\n",
            "          [ 1.1227e-05,  2.3461e-05,  7.7451e-06,  ..., -3.1097e-05,\n",
            "            3.3030e-05, -1.3007e-05],\n",
            "          [-2.9164e-05, -1.2408e-05,  1.8795e-05,  ..., -6.2529e-05,\n",
            "           -1.2124e-05, -4.5896e-08],\n",
            "          ...,\n",
            "          [ 7.0784e-06, -1.2946e-06, -3.0502e-05,  ...,  2.7236e-06,\n",
            "           -9.2019e-06,  6.2398e-07],\n",
            "          [-9.9811e-06,  3.7296e-05, -1.2245e-06,  ..., -1.5464e-05,\n",
            "            5.3023e-06,  2.6932e-06],\n",
            "          [-1.1345e-06,  2.3865e-05, -2.1041e-06,  ..., -5.7448e-06,\n",
            "           -8.0834e-06, -6.4015e-06]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 8.4344e-06,  7.7645e-07,  1.7106e-06,  ...,  1.5600e-05,\n",
            "           -3.3843e-06, -6.9367e-06],\n",
            "          [-3.2170e-07, -3.5250e-06,  8.2860e-06,  ..., -4.3244e-06,\n",
            "           -8.5508e-06, -2.5648e-05],\n",
            "          [ 8.7622e-06, -4.9406e-05, -8.2810e-07,  ...,  2.6070e-05,\n",
            "           -1.2705e-06, -6.9313e-06],\n",
            "          ...,\n",
            "          [ 1.9681e-05,  1.0119e-05, -8.6347e-06,  ...,  6.8043e-07,\n",
            "           -4.9826e-06,  3.9677e-05],\n",
            "          [-1.5095e-05,  2.0368e-06, -1.8254e-05,  ..., -1.2464e-05,\n",
            "            1.4370e-05,  8.4869e-06],\n",
            "          [ 3.6834e-06, -8.3453e-07, -2.8624e-05,  ...,  1.2460e-05,\n",
            "           -1.2252e-05, -4.2676e-06]],\n",
            "\n",
            "         [[ 1.8712e-05,  1.1896e-05,  6.7897e-06,  ..., -4.3284e-06,\n",
            "           -6.1536e-06, -5.9018e-06],\n",
            "          [ 1.0755e-05,  7.4246e-06,  1.5196e-05,  ..., -6.4873e-06,\n",
            "            2.7050e-05,  1.1280e-07],\n",
            "          [-6.9057e-06,  1.6794e-06,  3.2321e-05,  ..., -1.5156e-05,\n",
            "           -1.3209e-05,  5.2180e-06],\n",
            "          ...,\n",
            "          [ 3.2440e-05, -5.9678e-06,  8.0350e-06,  ...,  1.5363e-05,\n",
            "            4.0311e-05, -2.2694e-05],\n",
            "          [-6.7452e-06, -2.0710e-05, -1.5061e-05,  ..., -5.2724e-06,\n",
            "           -8.5154e-06, -2.2977e-05],\n",
            "          [-3.1162e-06,  9.3255e-06,  2.0860e-06,  ..., -2.9937e-05,\n",
            "           -3.1077e-05,  8.8708e-06]],\n",
            "\n",
            "         [[ 5.5012e-07, -1.4325e-05,  1.0035e-05,  ...,  1.3380e-05,\n",
            "            7.2866e-06,  3.5089e-06],\n",
            "          [-1.6713e-05,  4.5183e-06,  2.4861e-05,  ..., -5.8320e-06,\n",
            "            4.1312e-06, -4.2489e-06],\n",
            "          [ 6.7250e-06,  1.7185e-05, -1.9209e-05,  ..., -2.6430e-05,\n",
            "            2.9625e-05, -2.8543e-05],\n",
            "          ...,\n",
            "          [ 2.2196e-05, -3.1043e-06, -2.7153e-05,  ..., -6.5571e-06,\n",
            "           -1.6282e-05,  8.6979e-06],\n",
            "          [-7.0167e-06,  7.7298e-06, -7.7441e-06,  ...,  3.5953e-05,\n",
            "           -7.4992e-06,  9.3872e-06],\n",
            "          [-6.7404e-06,  6.0637e-06, -6.3527e-06,  ...,  6.4522e-06,\n",
            "            5.4044e-06,  5.3488e-06]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.0566e-06, -1.1323e-05,  2.3757e-05,  ..., -3.5615e-06,\n",
            "           -1.0197e-05, -4.2215e-07],\n",
            "          [ 1.8153e-05,  5.2117e-06, -9.6772e-06,  ...,  2.2261e-05,\n",
            "            1.0255e-05, -6.8260e-06],\n",
            "          [-2.8983e-05, -8.0070e-06, -3.0556e-05,  ..., -2.8164e-05,\n",
            "            6.4422e-06, -1.8866e-05],\n",
            "          ...,\n",
            "          [ 9.9380e-06,  6.8163e-06, -2.2645e-05,  ..., -1.0733e-06,\n",
            "           -1.6644e-05,  1.6519e-07],\n",
            "          [-5.6533e-06, -1.4057e-05,  1.1084e-05,  ...,  5.9472e-06,\n",
            "            1.7476e-06,  1.1382e-05],\n",
            "          [-6.5633e-06, -1.4169e-05,  1.1502e-05,  ..., -1.9462e-05,\n",
            "            2.9696e-06,  1.3200e-05]],\n",
            "\n",
            "         [[-6.9845e-07, -1.2644e-05,  1.2888e-05,  ...,  4.1061e-06,\n",
            "            9.7316e-06, -2.6236e-06],\n",
            "          [ 5.4291e-06,  2.5723e-05, -1.3537e-05,  ..., -2.5944e-05,\n",
            "            1.8772e-05,  1.1660e-05],\n",
            "          [-7.9160e-06, -2.9232e-05,  8.1357e-07,  ...,  2.0762e-05,\n",
            "            1.9955e-05,  3.9226e-05],\n",
            "          ...,\n",
            "          [-8.6401e-06,  2.5913e-05, -2.8619e-05,  ...,  2.0284e-05,\n",
            "           -2.7383e-06,  5.3008e-07],\n",
            "          [ 5.7749e-06,  2.5425e-06, -2.8993e-06,  ..., -3.4380e-06,\n",
            "           -8.6842e-06,  4.3155e-06],\n",
            "          [-6.5161e-06,  2.6278e-06,  1.3301e-05,  ..., -2.8852e-06,\n",
            "           -1.3527e-05, -6.1105e-06]],\n",
            "\n",
            "         [[ 1.8615e-06, -5.6402e-06,  1.1840e-05,  ...,  1.3822e-05,\n",
            "           -8.1880e-06, -6.7086e-06],\n",
            "          [ 7.3221e-06, -7.7891e-06,  1.2513e-05,  ..., -6.8215e-06,\n",
            "           -2.8046e-05,  6.6851e-06],\n",
            "          [ 1.3037e-05, -3.8359e-06,  2.0491e-05,  ..., -3.0498e-05,\n",
            "           -5.4533e-05, -2.1950e-05],\n",
            "          ...,\n",
            "          [ 3.7245e-06,  1.9452e-05,  2.5344e-06,  ...,  3.3635e-05,\n",
            "            9.4229e-06, -7.2360e-06],\n",
            "          [-3.0402e-06, -1.0930e-05,  6.4771e-06,  ..., -8.7214e-06,\n",
            "            6.0412e-06, -1.8590e-06],\n",
            "          [ 3.4100e-06, -7.2603e-06,  6.7861e-06,  ..., -5.4991e-06,\n",
            "            1.4146e-05, -8.7906e-06]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2510e-05, -1.0683e-05, -6.2427e-07,  ..., -2.9993e-06,\n",
            "           -6.6845e-06, -2.4141e-06],\n",
            "          [-1.0777e-05,  7.4493e-07, -1.2656e-05,  ..., -1.2993e-05,\n",
            "            1.1297e-05, -2.8377e-06],\n",
            "          [-1.3124e-05,  3.6977e-05,  3.1782e-05,  ...,  3.1675e-05,\n",
            "           -4.5739e-06, -1.9584e-05],\n",
            "          ...,\n",
            "          [ 2.8073e-05,  2.1992e-05,  4.7284e-05,  ...,  4.8968e-05,\n",
            "           -3.0540e-05,  1.5315e-05],\n",
            "          [-2.6247e-05,  4.7441e-05, -6.5840e-06,  ..., -6.1461e-07,\n",
            "           -3.5305e-06,  9.8529e-06],\n",
            "          [ 2.8691e-06, -2.3292e-05,  2.3306e-05,  ...,  2.2227e-07,\n",
            "           -1.1135e-05, -7.7242e-06]],\n",
            "\n",
            "         [[-1.7144e-05,  1.1003e-05, -1.0240e-05,  ...,  1.9545e-05,\n",
            "            2.4576e-05, -8.5685e-07],\n",
            "          [ 5.5398e-06, -8.2926e-06, -3.7354e-05,  ..., -5.5678e-06,\n",
            "           -1.7822e-05, -7.0551e-06],\n",
            "          [ 1.6011e-05,  1.5355e-05,  2.5650e-05,  ...,  7.6753e-07,\n",
            "           -1.7547e-05,  1.3096e-05],\n",
            "          ...,\n",
            "          [ 1.1706e-05, -2.5738e-05, -1.4962e-05,  ...,  3.5427e-05,\n",
            "            1.9154e-05, -4.5561e-06],\n",
            "          [ 4.4676e-06,  2.1858e-05,  3.7567e-05,  ..., -1.0695e-05,\n",
            "           -4.1128e-05, -1.5957e-05],\n",
            "          [ 8.5897e-06,  3.0961e-05, -1.5162e-05,  ..., -1.2817e-05,\n",
            "           -1.6392e-05, -2.9648e-06]],\n",
            "\n",
            "         [[-9.1903e-06, -2.8000e-05, -1.7344e-05,  ..., -1.4475e-05,\n",
            "           -2.6622e-05, -1.0976e-05],\n",
            "          [ 8.2601e-06, -4.0995e-06,  4.2409e-05,  ...,  4.0190e-06,\n",
            "           -2.8445e-05,  1.0243e-06],\n",
            "          [ 1.8457e-05,  1.8266e-05, -3.0302e-05,  ..., -7.8267e-05,\n",
            "           -2.6848e-06, -1.0607e-05],\n",
            "          ...,\n",
            "          [ 9.9416e-06, -1.2081e-06, -5.2627e-05,  ..., -1.2493e-05,\n",
            "            1.7885e-05, -3.5658e-06],\n",
            "          [-2.7701e-05, -3.2662e-05,  2.2243e-05,  ...,  1.5941e-05,\n",
            "            1.0488e-05, -1.7637e-06],\n",
            "          [-1.6380e-05,  2.2373e-06, -1.0273e-05,  ...,  1.1584e-05,\n",
            "            3.2962e-07, -1.1060e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.2477e-05,  2.8118e-05,  9.2899e-06,  ...,  9.3703e-06,\n",
            "            3.0689e-06, -4.7121e-06],\n",
            "          [ 1.4335e-05, -4.4023e-05, -5.9020e-06,  ..., -3.3119e-05,\n",
            "            1.7093e-05,  1.0604e-05],\n",
            "          [ 2.4240e-05, -1.7889e-05, -1.8785e-06,  ...,  6.7024e-05,\n",
            "           -5.7937e-06, -5.6008e-06],\n",
            "          ...,\n",
            "          [ 2.5408e-06,  3.6227e-05,  3.6911e-05,  ..., -1.7645e-06,\n",
            "           -1.2204e-05, -2.2197e-05],\n",
            "          [ 2.4631e-05,  1.7359e-05,  4.6330e-06,  ..., -1.3954e-05,\n",
            "           -3.1250e-06,  2.0364e-05],\n",
            "          [-5.8933e-06,  1.9268e-05,  2.4434e-05,  ...,  1.1383e-05,\n",
            "            2.3398e-06,  3.3982e-06]],\n",
            "\n",
            "         [[ 1.3859e-05, -1.5705e-05,  2.1402e-05,  ..., -3.0389e-05,\n",
            "            3.6445e-06, -6.1707e-06],\n",
            "          [ 4.2335e-07, -1.0011e-05,  1.9199e-05,  ...,  1.8123e-05,\n",
            "            6.3015e-06,  1.8455e-05],\n",
            "          [-2.7316e-05, -3.0019e-05, -1.0297e-05,  ..., -1.1673e-05,\n",
            "           -5.5355e-06, -3.6536e-06],\n",
            "          ...,\n",
            "          [ 2.0046e-05, -4.4604e-05, -2.7547e-05,  ..., -4.5410e-05,\n",
            "           -1.0738e-05,  3.9700e-06],\n",
            "          [ 2.7770e-05, -3.1532e-05,  1.8680e-05,  ...,  1.6311e-05,\n",
            "           -2.5619e-05, -8.2268e-06],\n",
            "          [-1.2583e-05, -1.5477e-05, -1.7816e-05,  ..., -1.7548e-06,\n",
            "            1.0530e-05, -8.5971e-06]],\n",
            "\n",
            "         [[ 6.9146e-06, -1.2632e-05,  1.7422e-05,  ..., -1.3158e-05,\n",
            "            1.1014e-05, -8.9453e-06],\n",
            "          [-5.2788e-06,  1.3104e-05, -4.4368e-06,  ..., -1.3658e-05,\n",
            "           -1.9812e-05, -2.2280e-06],\n",
            "          [-2.9375e-05,  6.4273e-06,  1.9817e-05,  ...,  5.7285e-05,\n",
            "            5.6805e-06,  2.5664e-05],\n",
            "          ...,\n",
            "          [ 1.6639e-05, -4.0527e-06, -3.0168e-05,  ...,  1.3925e-05,\n",
            "           -2.5303e-06,  6.3227e-07],\n",
            "          [ 9.1790e-06,  2.0114e-06,  2.7422e-05,  ..., -1.5024e-05,\n",
            "           -1.4303e-05,  1.4412e-06],\n",
            "          [ 1.1017e-06,  7.7786e-06, -3.0622e-05,  ..., -7.3499e-06,\n",
            "            9.5235e-06,  4.3849e-07]]],\n",
            "\n",
            "\n",
            "        [[[-1.5825e-06, -1.0636e-05, -1.4062e-05,  ...,  8.9747e-06,\n",
            "            3.6582e-06,  2.0171e-06],\n",
            "          [-1.7617e-06,  2.0306e-05, -8.7425e-06,  ..., -2.4891e-05,\n",
            "           -1.3376e-06,  2.8792e-05],\n",
            "          [-9.0857e-06, -2.9547e-05,  1.9309e-05,  ...,  9.7067e-06,\n",
            "           -1.5654e-05,  1.1047e-05],\n",
            "          ...,\n",
            "          [ 9.9214e-06, -1.5598e-05,  1.6639e-06,  ...,  4.0526e-05,\n",
            "           -2.3590e-05,  7.2509e-06],\n",
            "          [-2.6982e-06,  7.6137e-06, -3.5063e-05,  ...,  5.1485e-06,\n",
            "            1.0145e-05,  1.5319e-05],\n",
            "          [ 5.4959e-06, -1.1867e-05,  1.6669e-05,  ...,  1.6445e-05,\n",
            "           -5.6451e-06, -8.8140e-06]],\n",
            "\n",
            "         [[-6.3735e-06,  6.8407e-06, -9.3166e-06,  ..., -1.9837e-05,\n",
            "           -8.6152e-06, -6.5380e-07],\n",
            "          [ 4.3448e-06, -2.0256e-05, -1.8091e-05,  ...,  1.3077e-05,\n",
            "            2.6407e-05, -2.3351e-06],\n",
            "          [ 1.2774e-05,  4.9146e-05, -1.1936e-06,  ...,  1.0342e-05,\n",
            "            1.4928e-05, -1.1992e-05],\n",
            "          ...,\n",
            "          [ 6.4629e-06,  2.0941e-05,  1.2726e-05,  ..., -5.9345e-06,\n",
            "            4.0955e-05, -5.6535e-05],\n",
            "          [ 2.1680e-06,  5.5424e-06, -8.9343e-06,  ...,  5.8268e-05,\n",
            "           -3.6651e-06, -5.6296e-06],\n",
            "          [-1.0767e-05,  2.5087e-06,  9.4511e-06,  ..., -2.7790e-05,\n",
            "            1.3743e-05,  4.6572e-06]],\n",
            "\n",
            "         [[-2.4174e-06, -9.6000e-06,  1.0226e-05,  ...,  1.1900e-06,\n",
            "            1.3740e-05,  3.6562e-06],\n",
            "          [ 1.0917e-05, -3.5835e-05,  3.2282e-06,  ...,  2.3086e-05,\n",
            "           -1.0824e-05,  2.7547e-06],\n",
            "          [-1.7968e-05,  8.1968e-06,  3.9347e-07,  ...,  6.5122e-06,\n",
            "            3.2556e-05, -8.1983e-06],\n",
            "          ...,\n",
            "          [-1.9286e-05, -6.7719e-06,  2.9958e-05,  ...,  5.0147e-05,\n",
            "           -5.0365e-05,  4.7277e-06],\n",
            "          [ 3.1311e-06,  1.5502e-06, -2.9148e-06,  ...,  3.2781e-06,\n",
            "           -6.2445e-06,  1.0308e-05],\n",
            "          [-8.0154e-06, -3.6518e-06, -2.3702e-05,  ..., -7.4713e-06,\n",
            "            1.1022e-05, -8.0615e-06]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.8697e-07,  4.4065e-06, -1.6848e-05,  ..., -1.1699e-05,\n",
            "           -1.3797e-05, -3.1659e-06],\n",
            "          [ 1.1568e-05,  9.4062e-06, -1.7509e-06,  ..., -1.6392e-05,\n",
            "            6.3849e-06, -2.9725e-07],\n",
            "          [ 1.8005e-06,  2.9449e-05,  2.1279e-05,  ...,  1.8526e-05,\n",
            "           -1.3433e-05, -6.7392e-06],\n",
            "          ...,\n",
            "          [-8.6972e-06, -1.5227e-05, -4.4737e-05,  ..., -2.0374e-05,\n",
            "           -4.2001e-05, -1.8147e-05],\n",
            "          [ 2.7695e-05, -2.3707e-06,  3.6636e-05,  ..., -3.0449e-06,\n",
            "            2.4162e-05,  1.8985e-06],\n",
            "          [ 2.7217e-06,  8.8516e-06,  4.8867e-05,  ...,  8.3041e-06,\n",
            "           -3.0600e-06,  8.8947e-06]],\n",
            "\n",
            "         [[ 1.5212e-05,  7.6495e-08, -2.2883e-06,  ...,  1.4399e-05,\n",
            "            2.6038e-05,  1.0974e-05],\n",
            "          [-1.2397e-05, -3.2617e-06, -3.3119e-05,  ...,  2.1436e-05,\n",
            "           -2.1504e-05, -1.7843e-05],\n",
            "          [-3.4126e-06,  2.4538e-06, -7.9889e-06,  ...,  2.7473e-05,\n",
            "           -3.6886e-05,  1.6169e-07],\n",
            "          ...,\n",
            "          [-4.4387e-07, -3.1301e-05, -3.1407e-06,  ...,  2.9049e-05,\n",
            "            1.1126e-06, -9.1936e-07],\n",
            "          [ 3.5741e-05, -3.1937e-05, -2.2110e-05,  ...,  1.1117e-05,\n",
            "           -3.7777e-05, -1.6184e-05],\n",
            "          [-2.6757e-06,  2.8855e-05, -4.8947e-06,  ..., -6.5455e-06,\n",
            "           -2.3873e-05,  4.9703e-07]],\n",
            "\n",
            "         [[ 1.2240e-06, -4.7992e-07, -4.1802e-07,  ...,  1.5892e-05,\n",
            "           -8.5391e-06,  1.8664e-06],\n",
            "          [-1.7283e-05,  3.0735e-06, -2.4824e-05,  ...,  9.3571e-06,\n",
            "           -1.8033e-05, -3.3414e-07],\n",
            "          [ 1.4588e-05,  1.6434e-05, -1.4501e-05,  ..., -3.7178e-05,\n",
            "            4.6232e-05, -5.3944e-06],\n",
            "          ...,\n",
            "          [ 1.4965e-05, -2.1685e-05, -3.2295e-05,  ..., -2.8519e-05,\n",
            "            1.2192e-05,  5.6396e-06],\n",
            "          [-2.6591e-05, -6.7851e-05,  2.6336e-05,  ...,  1.0442e-05,\n",
            "           -1.4886e-05, -1.8313e-05],\n",
            "          [ 3.2301e-06,  6.0926e-06,  2.0322e-05,  ...,  7.4283e-06,\n",
            "            1.1512e-05, -1.2846e-06]]]])\n",
            "torch.Size([64, 20, 12, 12])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-0325af6d78a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model = Net2().to(device)\\noptimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\\n\\nfor epoch in range(1, args.epochs + 1):\\n    train(args, model, device, federated_train_loader, optimizer, epoch)\\n    test(args, model, device, test_loader)\\n\\nif (args.save_model):\\n    torch.save(model.state_dict(), \"mnist_cnn.pt\")'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-cde8777a0dd9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, device, federated_train_loader, optimizer, epoch, alpha1, alpha2)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m#dist.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mpred_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    675\u001b[0m                 \u001b[0;31m# Send the new command to the appropriate class and get the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m                 \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# For inplace methods, just directly return self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_pointer_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/workers/base.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, recipient, message, return_ids)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSGTYPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCMD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecipient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mResponseSignatureError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/workers/base.py\u001b[0m in \u001b[0;36msend_msg\u001b[0;34m(self, msg_type, message, location)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Step 2: send the message and wait for a response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mbin_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Step 3: deserialize the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/workers/virtual.py\u001b[0m in \u001b[0;36m_send_msg\u001b[0;34m(self, message, location)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mVirtualWorker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseWorker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFederatedClient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBaseWorker\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/workers/virtual.py\u001b[0m in \u001b[0;36m_recv_msg\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/workers/base.py\u001b[0m in \u001b[0;36mrecv_msg\u001b[0;34m(self, bin_message)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"worker {self} received {sy.codes.code2MSGTYPE[msg_type]} {contents}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# Step 1: route message to appropriate function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message_router\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmsg_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m# Step 2: Serialize the message to simple python objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/workers/base.py\u001b[0m in \u001b[0;36mexecute_command\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                     \u001b[0;31m# TODO Andrew thinks this is gross, please fix. Instead need to properly deserialize strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m                     \u001b[0;31m# we can make some errors more descriptive with this method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mroute_method_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# means that there is a wrapper to remove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m                         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: invalid gradient at index 0 - got [0] but expected shape compatible with [64, 20, 12, 12]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22MPahr4zXTV",
        "colab_type": "text"
      },
      "source": [
        "###Tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ETbNMPoLxcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Q = torch.zeros(3,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxTNcVGSL1Dz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = torch.tensor(1.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnGR-NkCL4wb",
        "colab_type": "code",
        "outputId": "fa26e58a-69a0-45e1-e387-03c3a51583f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "Q"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QbBgkZxIiDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Q = Q.send(bob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhFlwfVWIiAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Q[1,1] = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z865KjivIh9t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c3352f55-be2d-44ca-c02f-1c19466e00ea"
      },
      "source": [
        "Q.clone().get()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 2., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vatfhd_WI1U7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = c.send(bob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEVWNdr-I1Xx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Q[1,2] = c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiTZDTNWIxxo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "b62d28d8-effa-4bdc-a3f4-fb8a7b1bfdb1"
      },
      "source": [
        "Q.clone().get()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 2., 1.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IG_NiEML5qN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Q[1,1]=c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr-eg-jyL8is",
        "colab_type": "code",
        "outputId": "eeea912f-f7bb-4dd5-8dc0-3f67c5531fbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSaWH8bAL9fM",
        "colab_type": "code",
        "outputId": "c5c13e4d-b184-4f02-ec75-6cf00d7a82eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "Q"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db4VUTPdL_FQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor([0.,1.,2.])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jbBdkuHoltD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bff79c2c-9a20-480b-85b7-e4d68e0deb96"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktAlcuhe_Z1f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "210377f2-4360-4b11-821b-05877469f661"
      },
      "source": [
        "x.size()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op4yq83P_bKh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3f1b6e04-f59a-434a-adae-024a34a777d9"
      },
      "source": [
        "x.view(1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXY8cCz-_dDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = x.send(bob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vef2adXtIbLk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7acc4499-6e29-4008-e745-f0e927ce1ca3"
      },
      "source": [
        "bob"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:bob #objects:24>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztOYVKa3IcQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = x.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg_L9Tzs9cDY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "b5445599-40d2-42cb-a4e1-143865a70348"
      },
      "source": [
        "N.send(bob)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-25d649797adb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'torch.Size' object has no attribute 'send'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_GJzokj9hz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x[0]=N"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6FXrSG2Dmb9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d1e7785f-35d5-4a60-f48e-05612056c11f"
      },
      "source": [
        "x"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:58102664934 -> bob:24894408443]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14Zv-rBuDylU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2a1aaf08-7616-4054-cc45-aaf3fff43a79"
      },
      "source": [
        "x.clone().get()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 1., 2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-gmEbU0D0U9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9c3dcfae-c1f8-43a5-b3dd-2b3f30d3e19d"
      },
      "source": [
        "x"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:58102664934 -> bob:24894408443]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2QqfSxUXt5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = torch.tensor(2)\n",
        "l = l.send(bob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jZ0jjzQXvI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x[l]=10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3Xyub9HXxxS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0bc4f1c5-8024-4d10-94f5-079b563d4b76"
      },
      "source": [
        "l"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzDnJGpqYF36",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f55a7483-a202-486e-ce5a-5b0b8fe96271"
      },
      "source": [
        "int(l)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsIzhNwVYHNG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3fc9948d-0c0a-491c-f481-b54ed97b1629"
      },
      "source": [
        "x.clone().get()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 3.,  1., 10.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70fbq3wdYYdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGBQLPhzCF4o",
        "colab_type": "text"
      },
      "source": [
        "### Issue"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uCY2GaRCHo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = torch.tensor([1.,2.,3.,4.],requires_grad=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL4KJLkmCMcm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b = a**2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prETgP0mOHk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b = torch.tensor([1.,4.,9.,16.],requires_grad=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRzg6JohQFqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrERaws7CyjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = b.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_kbiD0hC1hf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3844f1a9-13d2-4220-dcc3-cb0019c0116b"
      },
      "source": [
        "c"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(30., grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpg3PKHdDAbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhRorhuoO9pZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b.backward(torch.tensor([1.,1.,1.,1.]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAwkYRDeORGo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5a8ce044-ea45-4dba-9da3-c13d02c51019"
      },
      "source": [
        "b.grad"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFAQ18oEDIzM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2b68e86a-2fa9-4b70-9f3e-c02734f69fc7"
      },
      "source": [
        "a.grad"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 4., 6., 8.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNLaR1mON1Uv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21fcDpzNXMbv",
        "colab_type": "text"
      },
      "source": [
        "#### TEST1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wKwcOuPQMuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = torch.tensor([1.,2.,3.,4.],requires_grad=True)\n",
        "a = a.send(bob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHoqy-HsQMpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b = a**2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtpVg__AWozG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b_ = b.clone().get()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKnnkCDJWr3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = b_.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7Hm7I7tWvin",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vum3CXQgWxMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grad = b_.grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PS2njA_W0lF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grad = grad.send(bob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-flJaFGW3ij",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3769423b-82d2-4a4a-d94f-bea2921f113b"
      },
      "source": [
        "b.backward(grad)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:49838401799 -> bob:67097995970]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdCojc6LW-Xq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "56825cbb-db1c-4b0b-b5be-49e856b22608"
      },
      "source": [
        "a.grad.clone().get()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 4., 6., 8.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrDlNIGJXE1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1IfUPGsXYYf",
        "colab_type": "text"
      },
      "source": [
        "#### TEST2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QFp_augMZsfB",
        "colab": {}
      },
      "source": [
        "a = torch.tensor([1.,2.,3.,4.],requires_grad=True)\n",
        "a = a.send(bob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vy_d_KFpZsfZ",
        "colab": {}
      },
      "source": [
        "b = a**2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Coi48KxhZsfc",
        "colab": {}
      },
      "source": [
        "b_ = b.clone().get()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aoRuhAaZ5Oi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = b+2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yPWPASfZZsff",
        "colab": {}
      },
      "source": [
        "c = b_.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KcQXhSEJZsfi",
        "colab": {}
      },
      "source": [
        "c.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jDxqzcerZsfo",
        "colab": {}
      },
      "source": [
        "grad = b_.grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8ed531xNZsfq",
        "colab": {}
      },
      "source": [
        "grad = grad.send(bob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cdaf6157-71db-4ce8-8778-8176de1fde21",
        "id": "mmurt3Y6aPxG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "b.backward(grad)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[PointerTensor | me:13838942116 -> bob:80963266849]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d42a04a1-d82b-41dc-c137-09a44640ca9d",
        "id": "1fjCK2hTaPxQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "a.grad.clone().get()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 4., 6., 8.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMIwbdfgaR2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw0Nbh1amvDA",
        "colab_type": "text"
      },
      "source": [
        "#### TEST3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N46BlwF3nAk1",
        "colab": {}
      },
      "source": [
        "a = torch.tensor([1.,2.,3.,4.],requires_grad=True)\n",
        "#a = a.send(bob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PMe4St9EnAk5",
        "colab": {}
      },
      "source": [
        "b = a**2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da9dgw_AnFLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = b**3 + 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IGTmMhYnIgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = d.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjsmH3RqnNJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNpP0OWrnRBg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6281faa8-2c96-484c-fb59-991df53f8ae4"
      },
      "source": [
        "a.grad"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6.0000e+00, 1.9200e+02, 1.4580e+03, 6.1440e+03])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEQvvayknTmV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "73ad533c-b216-4a42-bd0f-501847b960ff"
      },
      "source": [
        "bob.clear_objects()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:bob #objects:0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8In6HF_fnbvx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2b6f28ca-d63c-445f-d2cd-43052eb6859d"
      },
      "source": [
        "### Forward part\n",
        "# First tensor, sent to client's location\n",
        "a = torch.tensor([1.,2.,3.,4.],requires_grad=True)\n",
        "a = a.send(bob)\n",
        "\n",
        "# Second tensor, cloned and sent to server\n",
        "b = a**2\n",
        "b_ = b.clone().get()\n",
        "\n",
        "# Third tensor, cloned and sent to client\n",
        "c = b_**3\n",
        "c_ = c.clone().send(bob)\n",
        "\n",
        "#Fourth tensor \n",
        "d = c_.sum()\n",
        "\n",
        "### Backward part\n",
        "d.backward()\n",
        "g1 = c_.grad.clone().get()\n",
        "d.get()\n",
        "c.backward(g1)\n",
        "g2 = b_.grad.clone().send(bob)\n",
        "print(\"b shape:\",b.shape)\n",
        "print(\"gradient shape:\", g2.shape)\n",
        "b.backward(g2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b shape: torch.Size([4])\n",
            "gradient shape: torch.Size([4])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ea3378717307>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"b shape:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradient shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    675\u001b[0m                 \u001b[0;31m# Send the new command to the appropriate class and get the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m                 \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# For inplace methods, just directly return self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_pointer_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/workers/base.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, recipient, message, return_ids)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSGTYPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCMD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecipient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mResponseSignatureError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/workers/base.py\u001b[0m in \u001b[0;36msend_msg\u001b[0;34m(self, msg_type, message, location)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Step 2: send the message and wait for a response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mbin_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Step 3: deserialize the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/workers/virtual.py\u001b[0m in \u001b[0;36m_send_msg\u001b[0;34m(self, message, location)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mVirtualWorker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseWorker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFederatedClient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBaseWorker\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/workers/virtual.py\u001b[0m in \u001b[0;36m_recv_msg\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/workers/base.py\u001b[0m in \u001b[0;36mrecv_msg\u001b[0;34m(self, bin_message)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"worker {self} received {sy.codes.code2MSGTYPE[msg_type]} {contents}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# Step 1: route message to appropriate function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message_router\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmsg_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m# Step 2: Serialize the message to simple python objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/workers/base.py\u001b[0m in \u001b[0;36mexecute_command\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                     \u001b[0;31m# TODO Andrew thinks this is gross, please fix. Instead need to properly deserialize strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m                     \u001b[0;31m# we can make some errors more descriptive with this method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mroute_method_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# means that there is a wrapper to remove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m                         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: invalid gradient at index 0 - got [0] but expected shape compatible with [4]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrQ5sVU8oXZV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "f9481ec3-ac30-482d-de88-1ec65b86f4f6"
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{344562030: tensor([ 1.,  4.,  9., 16.], grad_fn=<PowBackward0>),\n",
              " 2181393947: tensor(4898., grad_fn=<SumBackward0>),\n",
              " 20740364325: tensor([  3.,  48., 243., 768.]),\n",
              " 29463151178: tensor([3.0000e+00, 6.6000e+01, 7.3100e+02, 4.0980e+03], requires_grad=True),\n",
              " 34315854109: tensor([1., 1., 1., 1.]),\n",
              " 86730410175: tensor([1., 2., 3., 4.], requires_grad=True)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN7VbZYgohoh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "72ee3c28-6e5d-426c-f81a-91adc83a9bf2"
      },
      "source": [
        "g2.location"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VirtualWorker id:bob #objects:6>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-eLsD5ZoqXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}