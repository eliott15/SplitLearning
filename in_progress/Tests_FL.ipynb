{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tests_FL.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "bPjHa6Wamn3p",
        "rtIUdMxh07km",
        "lAtZf94FyoRR",
        "2exc6QImzapk"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACNGxsd3JSWO",
        "colab_type": "text"
      },
      "source": [
        "## TEST1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U37bMczwIhor",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1436
        },
        "outputId": "b6f9b053-ddb8-416e-e84b-1611753f81ef"
      },
      "source": [
        "! pip install syft"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting syft\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/2e/16bdefc78eb089e1efa9704c33b8f76f035a30dc935bedd7cbb22f6dabaa/syft-0.1.21a1-py3-none-any.whl (219kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Collecting websocket-client>=0.56.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 53.8MB/s \n",
            "\u001b[?25hCollecting zstd>=1.4.0.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/37/6a7ba746ebddbd6cd06de84367515d6bc239acd94fb3e0b1c85788176ca2/zstd-1.4.1.0.tar.gz (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 59.9MB/s \n",
            "\u001b[?25hCollecting tf-encrypted>=0.5.4 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/ff/7dbd5fc77fcec0df1798268a6b72a2ab0150b854761bc39c77d566798f0b/tf_encrypted-0.5.7-py3-none-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 50.0MB/s \n",
            "\u001b[?25hCollecting websockets>=7.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/4b/ad228451b1c071c5c52616b7d4298ebcfcac5ae8515ede959db19e4cd56d/websockets-8.0.2-cp36-cp36m-manylinux1_x86_64.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 35.7MB/s \n",
            "\u001b[?25hCollecting flask-socketio>=3.3.2 (from syft)\n",
            "  Downloading https://files.pythonhosted.org/packages/33/31/f779e69e59f528684d8c9925b3c82a9303d148655d9671ba2975ab8c3894/Flask_SocketIO-4.2.0-py2.py3-none-any.whl\n",
            "Collecting lz4>=2.1.6 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 55.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Requirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.16.4)\n",
            "Requirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Collecting msgpack>=0.6.1 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/7e/ae9e91c1bb8d846efafd1f353476e3fd7309778b582d2fb4cea4cc15b9a2/msgpack-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 56.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.21.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client>=0.56.0->syft) (1.12.0)\n",
            "Collecting pyyaml>=5.1 (from tf-encrypted>=0.5.4->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/e8/b3212641ee2718d556df0f23f78de8303f068fe29cdaa7a91018849582fe/PyYAML-5.1.2.tar.gz (265kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 60.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Collecting python-socketio>=4.3.0 (from flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/5a/9429c1fbc399b6079725150a36491efd6bd4691c11110f5a57e8c991de96/python_socketio-4.3.0-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 20.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (4.3.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (2.10.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (7.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (0.15.5)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (0.13.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.11.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.1.7)\n",
            "Collecting python-engineio>=3.9.0 (from python-socketio>=4.3.0->flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/ba/5a689b07d399cd91cd91875232a1af8a63f0bd2cd0d0898da295f127544e/python_engineio-3.9.2-py2.py3-none-any.whl (119kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 56.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->syft) (0.46)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=1.0.2->syft) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (2.8.0)\n",
            "Building wheels for collected packages: zstd, pyyaml\n",
            "  Building wheel for zstd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for zstd: filename=zstd-1.4.1.0-cp36-cp36m-linux_x86_64.whl size=1067083 sha256=125e93c1103cbab5340d8477eaa8ca2f69be700e3f6366235b16cc41c6ffd36b\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/3f/ee/ac08c81af7c1b24a80c746df669ea3cb37542d27877d66ccf4\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1.2-cp36-cp36m-linux_x86_64.whl size=44105 sha256=10d0c0672be0b57f87030abe83f708488974ddba9ec6171bf4f600f1f24bfa0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/45/dd/65f0b38450c47cf7e5312883deb97d065e030c5cca0a365030\n",
            "Successfully built zstd pyyaml\n",
            "Installing collected packages: websocket-client, zstd, pyyaml, tf-encrypted, websockets, python-engineio, python-socketio, flask-socketio, lz4, msgpack, syft\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: msgpack 0.5.6\n",
            "    Uninstalling msgpack-0.5.6:\n",
            "      Successfully uninstalled msgpack-0.5.6\n",
            "Successfully installed flask-socketio-4.2.0 lz4-2.1.10 msgpack-0.6.1 python-engineio-3.9.2 python-socketio-4.3.0 pyyaml-5.1.2 syft-0.1.21a1 tf-encrypted-0.5.7 websocket-client-0.56.0 websockets-8.0.2 zstd-1.4.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kOjSp3E9PJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "#torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "#torch.set_default_tensor_type(torch.cuda.FloatTensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjVGMR0_9fdD",
        "colab_type": "code",
        "outputId": "ac0c050d-b482-4672-c168-c1b01ca1ca6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "import syft as sy  # <-- NEW: import the Pysyft library\n",
        "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")  # <-- NEW: define remote worker bob\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")  # <-- NEW: and alice"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0805 09:36:16.813091 140601580705664 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0805 09:36:16.825485 140601580705664 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G0ReVW36MwPD"
      },
      "source": [
        "### SPLIT LEARNING CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w_f9LQKeMwPF",
        "colab": {}
      },
      "source": [
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 64\n",
        "        self.test_batch_size = 1000\n",
        "        self.epochs = 10\n",
        "        self.lr = 0.01\n",
        "        self.momentum = 0.5\n",
        "        self.no_cuda = True\n",
        "        self.seed = 1\n",
        "        self.log_interval = 30\n",
        "        self.save_model = False\n",
        "\n",
        "args = Arguments()\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "#device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0bb7f562-5d4e-4ea0-c499-da398dbc200f",
        "id": "5cU69GeVMwPI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n",
        "    .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
        "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=args.test_batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 16384/9912422 [00:00<01:28, 111689.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 29211926.35it/s]                           \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 450595.88it/s]\n",
            "  1%|          | 16384/1648877 [00:00<00:11, 145218.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 7234277.54it/s]                            \n",
            "8192it [00:00, 183981.98it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aUH8X9LTMwPQ",
        "colab": {}
      },
      "source": [
        "class Net1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net1, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        return F.max_pool2d(x, 2, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X1fYDUeFMwPU",
        "colab": {}
      },
      "source": [
        "class Net2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net2, self).__init__()\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dbKkMeGaMwPY",
        "colab": {}
      },
      "source": [
        "models = [Net1(),Net1()]\n",
        "models[0] = models[0].send(bob)\n",
        "models[1] = models[1].send(alice)\n",
        "\n",
        "\n",
        "opt1 = optim.SGD(params=models[0].parameters(),lr=0.1)\n",
        "opt2 = optim.SGD(params=models[1].parameters(),lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OIbseBcjMwPa",
        "colab": {}
      },
      "source": [
        "def train(args, model, device, federated_train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, targs) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
        "        #IF ON DATA LOCATION TO GET THE RIGHT MODEL\n",
        "        if data.location.id == 'bob':\n",
        "          mod_c,opt_c = models[0], opt1\n",
        "        else : \n",
        "          mod_c,opt_c = models[1], opt2\n",
        "          \n",
        "       # 1) erase previous gradients (if they exist)\n",
        "        optimizer.step()\n",
        "        opt_c.step()\n",
        "        opt_c.zero_grad()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        \n",
        "        #model.send(data.location) # <-- NEW: send the model to the right location\n",
        "        #target= tar.get()\n",
        "        tg_copy = targs.copy()\n",
        "        target = tg_copy.get()\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        #optimizer.zero_grad()\n",
        "        # 2) make a prediction until cut layer (client location)\n",
        "        pred_c = mod_c(data)\n",
        "        copy = pred_c.copy()\n",
        "        # 3) get this to the server \n",
        "        inp = copy.get()\n",
        "\n",
        "        # 4) make prediction with second part of the model (server location)\n",
        "        pred = model(inp)\n",
        "\n",
        "        # 5) calculate how much we missed \n",
        "        #print(pred.size(),target.size())\n",
        "        loss = F.nll_loss(pred, target)\n",
        "        loss.backward()\n",
        "        \n",
        "        gradient = inp.grad\n",
        "        #print()\n",
        "        gradient = gradient.view(inp.shape)\n",
        "        G = gradient.send(data.location)\n",
        "        #print(G.shape)\n",
        "        #print(pred_c.shape)\n",
        "        pred_c.backward(G)\n",
        "        #print(data.grad)\n",
        "        #target = target.send(data.location)\n",
        "        #optimizer.step()\n",
        "        #model.get() # <-- NEW: get the model back\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            #loss = loss.get() # <-- NEW: get the loss back\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,\n",
        "                100. * batch_idx / len(federated_train_loader), loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lf7X3HeeMwPc",
        "colab": {}
      },
      "source": [
        "def test(args, model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    M1 = models[0].copy()\n",
        "    M2 = models[1].copy()\n",
        "    M1 = M1.get()\n",
        "    M2 = M2.get()\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(M1(data))\n",
        "            #output2 = model(M2(data))\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0dd9e7e2-6c5d-4500-cf70-12e40a8e6bcb",
        "id": "HaC3g2taMwPg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        }
      },
      "source": [
        "%%time\n",
        "model = Net2().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(args, model, device, federated_train_loader, optimizer, epoch)\n",
        "    test(args, model, device, test_loader)\n",
        "\n",
        "if (args.save_model):\n",
        "    torch.save(model.state_dict(), \"mnist_cnn.pt\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60032 (0%)]\tLoss: 2.312780\n",
            "Train Epoch: 1 [1920/60032 (3%)]\tLoss: 2.102405\n",
            "Train Epoch: 1 [3840/60032 (6%)]\tLoss: 1.226992\n",
            "Train Epoch: 1 [5760/60032 (10%)]\tLoss: 0.818510\n",
            "Train Epoch: 1 [7680/60032 (13%)]\tLoss: 0.420083\n",
            "Train Epoch: 1 [9600/60032 (16%)]\tLoss: 0.317328\n",
            "Train Epoch: 1 [11520/60032 (19%)]\tLoss: 0.342280\n",
            "Train Epoch: 1 [13440/60032 (22%)]\tLoss: 0.242250\n",
            "Train Epoch: 1 [15360/60032 (26%)]\tLoss: 0.291382\n",
            "Train Epoch: 1 [17280/60032 (29%)]\tLoss: 0.335301\n",
            "Train Epoch: 1 [19200/60032 (32%)]\tLoss: 0.238702\n",
            "Train Epoch: 1 [21120/60032 (35%)]\tLoss: 0.142208\n",
            "Train Epoch: 1 [23040/60032 (38%)]\tLoss: 0.229823\n",
            "Train Epoch: 1 [24960/60032 (42%)]\tLoss: 0.355077\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-0325af6d78a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model = Net2().to(device)\\noptimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\\n\\nfor epoch in range(1, args.epochs + 1):\\n    train(args, model, device, federated_train_loader, optimizer, epoch)\\n    test(args, model, device, test_loader)\\n\\nif (args.save_model):\\n    torch.save(model.state_dict(), \"mnist_cnn.pt\")'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-d1f716c4160d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, device, federated_train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#print(pred.size(),target.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m                     \u001b[0;31m# we can make some errors more descriptive with this method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mroute_method_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# means that there is a wrapper to remove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m                         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m                         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6_Q0yuxJWpt",
        "colab_type": "text"
      },
      "source": [
        "## TEST2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPjHa6Wamn3p",
        "colab_type": "text"
      },
      "source": [
        "### INSTALLATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze8ktuwfdPBL",
        "colab_type": "code",
        "outputId": "699cc980-edfa-4189-c331-1d9ab7aff2f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "! git clone https://github.com/OpenMined/PySyft.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PySyft'...\n",
            "remote: Enumerating objects: 58, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 28164 (delta 25), reused 16 (delta 8), pack-reused 28106\u001b[K\n",
            "Receiving objects: 100% (28164/28164), 31.90 MiB | 24.90 MiB/s, done.\n",
            "Resolving deltas: 100% (18559/18559), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_48unP9TJqO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f7d048a3-3385-436b-f4f9-83b436a23959"
      },
      "source": [
        "% cd PySyft"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/PySyft\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33CzrAr6rYJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! git checkout d126b3110a3970bef8932ffaf8987ba77d32deb1 ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y8R-IOtSySh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! git checkout 33f18dac67e9cc33e05c6698a5c48ad36de05755 ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD5PLlacXla9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "96aabb95-32ea-4d08-8248-4e2c818fc183"
      },
      "source": [
        "% cd .."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fI_8lu51vdI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mv native.py PySyft/syft/frameworks/torch/tensors/interpreters/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-4fMK4qddor",
        "colab_type": "code",
        "outputId": "9ba1f394-47df-4b37-c3f9-c5f7567f1b10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd PySyft"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/PySyft\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fssmoTQdlb5",
        "colab_type": "code",
        "outputId": "7326e83e-ba14-4604-bd59-c547a873c736",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "! ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONTRIBUTING.md  INSTALLATION.md  requirements_dev.txt\t   syft\n",
            "docker-image\t LICENSE\t  requirements.txt\t   test\n",
            "docs\t\t Makefile\t  run_websocket_server.py\n",
            "examples\t pyproject.toml   setup.cfg\n",
            "images\t\t README.md\t  setup.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNJSOBHKJdyQ",
        "colab_type": "code",
        "outputId": "a335c5bd-7be2-4225-a1ef-a859a25d4380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 12836
        }
      },
      "source": [
        "! python3 setup.py install"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating syft.egg-info\n",
            "writing syft.egg-info/PKG-INFO\n",
            "writing dependency_links to syft.egg-info/dependency_links.txt\n",
            "writing requirements to syft.egg-info/requires.txt\n",
            "writing top-level names to syft.egg-info/top_level.txt\n",
            "writing manifest file 'syft.egg-info/SOURCES.txt'\n",
            "writing manifest file 'syft.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/test\n",
            "copying test/test_sandbox.py -> build/lib/test\n",
            "copying test/test_udacity.py -> build/lib/test\n",
            "copying test/__init__.py -> build/lib/test\n",
            "copying test/conftest.py -> build/lib/test\n",
            "copying test/test_exceptions.py -> build/lib/test\n",
            "copying test/test___init__.py -> build/lib/test\n",
            "copying test/test_dependency_check.py -> build/lib/test\n",
            "copying test/test_grid.py -> build/lib/test\n",
            "copying test/test_local_worker.py -> build/lib/test\n",
            "copying test/test_serde.py -> build/lib/test\n",
            "creating build/lib/syft\n",
            "copying syft/grid.py -> build/lib/syft\n",
            "copying syft/codes.py -> build/lib/syft\n",
            "copying syft/__init__.py -> build/lib/syft\n",
            "copying syft/exceptions.py -> build/lib/syft\n",
            "copying syft/dependency_check.py -> build/lib/syft\n",
            "creating build/lib/test/workers\n",
            "copying test/workers/__init__.py -> build/lib/test/workers\n",
            "copying test/workers/test_worker.py -> build/lib/test/workers\n",
            "copying test/workers/test_base.py -> build/lib/test/workers\n",
            "copying test/workers/test_virtual.py -> build/lib/test/workers\n",
            "copying test/workers/test_websocket_worker.py -> build/lib/test/workers\n",
            "creating build/lib/test/torch\n",
            "copying test/torch/test_functions.py -> build/lib/test/torch\n",
            "copying test/torch/__init__.py -> build/lib/test/torch\n",
            "copying test/torch/test_hook.py -> build/lib/test/torch\n",
            "copying test/torch/test_federated_learning.py -> build/lib/test/torch\n",
            "creating build/lib/test/generic\n",
            "copying test/generic/__init__.py -> build/lib/test/generic\n",
            "copying test/generic/test_id_provider.py -> build/lib/test/generic\n",
            "creating build/lib/test/federated\n",
            "copying test/federated/__init__.py -> build/lib/test/federated\n",
            "copying test/federated/test_plan.py -> build/lib/test/federated\n",
            "copying test/federated/test_federated_client.py -> build/lib/test/federated\n",
            "copying test/federated/test_train_config.py -> build/lib/test/federated\n",
            "creating build/lib/test/torch/pointers\n",
            "copying test/torch/pointers/__init__.py -> build/lib/test/torch/pointers\n",
            "copying test/torch/pointers/test_callable_pointer.py -> build/lib/test/torch/pointers\n",
            "copying test/torch/pointers/test_pointer_tensor.py -> build/lib/test/torch/pointers\n",
            "creating build/lib/test/torch/differential_privacy\n",
            "copying test/torch/differential_privacy/__init__.py -> build/lib/test/torch/differential_privacy\n",
            "copying test/torch/differential_privacy/test_pate.py -> build/lib/test/torch/differential_privacy\n",
            "creating build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_logging.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_gc.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_large_precision.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/__init__.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_autograd.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_polynomial.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_tensor.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_additive_shared.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_variable.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_native.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_precision.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_parameter.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_multi_pointer.py -> build/lib/test/torch/tensors\n",
            "creating build/lib/test/torch/federated\n",
            "copying test/torch/federated/__init__.py -> build/lib/test/torch/federated\n",
            "copying test/torch/federated/test_dataset.py -> build/lib/test/torch/federated\n",
            "copying test/torch/federated/test_dataloader.py -> build/lib/test/torch/federated\n",
            "copying test/torch/federated/test_utils.py -> build/lib/test/torch/federated\n",
            "creating build/lib/test/torch/crypto\n",
            "copying test/torch/crypto/__init__.py -> build/lib/test/torch/crypto\n",
            "copying test/torch/crypto/test_snn.py -> build/lib/test/torch/crypto\n",
            "creating build/lib/syft/frameworks\n",
            "copying syft/frameworks/__init__.py -> build/lib/syft/frameworks\n",
            "creating build/lib/syft/serde\n",
            "copying syft/serde/serde.py -> build/lib/syft/serde\n",
            "copying syft/serde/__init__.py -> build/lib/syft/serde\n",
            "copying syft/serde/torch_serde.py -> build/lib/syft/serde\n",
            "copying syft/serde/native_serde.py -> build/lib/syft/serde\n",
            "creating build/lib/syft/workers\n",
            "copying syft/workers/virtual.py -> build/lib/syft/workers\n",
            "copying syft/workers/__init__.py -> build/lib/syft/workers\n",
            "copying syft/workers/websocket_client.py -> build/lib/syft/workers\n",
            "copying syft/workers/tfe.py -> build/lib/syft/workers\n",
            "copying syft/workers/websocket_server.py -> build/lib/syft/workers\n",
            "copying syft/workers/abstract.py -> build/lib/syft/workers\n",
            "copying syft/workers/base.py -> build/lib/syft/workers\n",
            "creating build/lib/syft/generic\n",
            "copying syft/generic/id_provider.py -> build/lib/syft/generic\n",
            "copying syft/generic/__init__.py -> build/lib/syft/generic\n",
            "copying syft/generic/object_storage.py -> build/lib/syft/generic\n",
            "creating build/lib/syft/federated\n",
            "copying syft/federated/__init__.py -> build/lib/syft/federated\n",
            "copying syft/federated/federated_client.py -> build/lib/syft/federated\n",
            "copying syft/federated/train_config.py -> build/lib/syft/federated\n",
            "copying syft/federated/plan.py -> build/lib/syft/federated\n",
            "creating build/lib/syft/frameworks/torch\n",
            "copying syft/frameworks/torch/__init__.py -> build/lib/syft/frameworks/torch\n",
            "copying syft/frameworks/torch/overload_torch.py -> build/lib/syft/frameworks/torch\n",
            "copying syft/frameworks/torch/functions.py -> build/lib/syft/frameworks/torch\n",
            "copying syft/frameworks/torch/torch_attributes.py -> build/lib/syft/frameworks/torch\n",
            "creating build/lib/syft/frameworks/keras\n",
            "copying syft/frameworks/keras/__init__.py -> build/lib/syft/frameworks/keras\n",
            "copying syft/frameworks/keras/hook.py -> build/lib/syft/frameworks/keras\n",
            "creating build/lib/syft/frameworks/torch/pointers\n",
            "copying syft/frameworks/torch/pointers/callable_pointer.py -> build/lib/syft/frameworks/torch/pointers\n",
            "copying syft/frameworks/torch/pointers/__init__.py -> build/lib/syft/frameworks/torch/pointers\n",
            "copying syft/frameworks/torch/pointers/object_wrapper.py -> build/lib/syft/frameworks/torch/pointers\n",
            "copying syft/frameworks/torch/pointers/pointer_tensor.py -> build/lib/syft/frameworks/torch/pointers\n",
            "copying syft/frameworks/torch/pointers/object_pointer.py -> build/lib/syft/frameworks/torch/pointers\n",
            "creating build/lib/syft/frameworks/torch/differential_privacy\n",
            "copying syft/frameworks/torch/differential_privacy/__init__.py -> build/lib/syft/frameworks/torch/differential_privacy\n",
            "copying syft/frameworks/torch/differential_privacy/pate.py -> build/lib/syft/frameworks/torch/differential_privacy\n",
            "creating build/lib/syft/frameworks/torch/tensors\n",
            "copying syft/frameworks/torch/tensors/__init__.py -> build/lib/syft/frameworks/torch/tensors\n",
            "creating build/lib/syft/frameworks/torch/federated\n",
            "copying syft/frameworks/torch/federated/dataloader.py -> build/lib/syft/frameworks/torch/federated\n",
            "copying syft/frameworks/torch/federated/__init__.py -> build/lib/syft/frameworks/torch/federated\n",
            "copying syft/frameworks/torch/federated/dataset.py -> build/lib/syft/frameworks/torch/federated\n",
            "copying syft/frameworks/torch/federated/utils.py -> build/lib/syft/frameworks/torch/federated\n",
            "creating build/lib/syft/frameworks/torch/crypto\n",
            "copying syft/frameworks/torch/crypto/__init__.py -> build/lib/syft/frameworks/torch/crypto\n",
            "copying syft/frameworks/torch/crypto/securenn.py -> build/lib/syft/frameworks/torch/crypto\n",
            "copying syft/frameworks/torch/crypto/spdz.py -> build/lib/syft/frameworks/torch/crypto\n",
            "creating build/lib/syft/frameworks/torch/hook\n",
            "copying syft/frameworks/torch/hook/__init__.py -> build/lib/syft/frameworks/torch/hook\n",
            "copying syft/frameworks/torch/hook/hook.py -> build/lib/syft/frameworks/torch/hook\n",
            "copying syft/frameworks/torch/hook/hook_args.py -> build/lib/syft/frameworks/torch/hook\n",
            "creating build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/build_gradients.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/large_precision.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/autograd.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/gradients.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/additive_shared.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/__init__.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/gradients_core.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/polynomial.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/native.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/precision.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/multi_pointer.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/plusisminus.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/abstract.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "creating build/lib/syft/frameworks/torch/tensors/decorators\n",
            "copying syft/frameworks/torch/tensors/decorators/__init__.py -> build/lib/syft/frameworks/torch/tensors/decorators\n",
            "copying syft/frameworks/torch/tensors/decorators/logging.py -> build/lib/syft/frameworks/torch/tensors/decorators\n",
            "creating build/lib/syft/frameworks/keras/model\n",
            "copying syft/frameworks/keras/model/__init__.py -> build/lib/syft/frameworks/keras/model\n",
            "copying syft/frameworks/keras/model/sequential.py -> build/lib/syft/frameworks/keras/model\n",
            "creating build/lib/syft/frameworks/keras/layers\n",
            "copying syft/frameworks/keras/layers/__init__.py -> build/lib/syft/frameworks/keras/layers\n",
            "copying syft/frameworks/keras/layers/constructor.py -> build/lib/syft/frameworks/keras/layers\n",
            "creating build/lib/test/keras\n",
            "copying test/keras/test_sequential.py -> build/lib/test/keras\n",
            "copying syft/frameworks/keras/README.md -> build/lib/syft/frameworks/keras\n",
            "copying syft/frameworks/torch/tensors/interpreters/derivatives.yaml -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/test_sandbox.py -> build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/test_udacity.py -> build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/__init__.py -> build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/conftest.py -> build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/test_exceptions.py -> build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/test___init__.py -> build/bdist.linux-x86_64/egg/test\n",
            "creating build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/workers/__init__.py -> build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/workers/test_worker.py -> build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/workers/test_base.py -> build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/workers/test_virtual.py -> build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/workers/test_websocket_worker.py -> build/bdist.linux-x86_64/egg/test/workers\n",
            "creating build/bdist.linux-x86_64/egg/test/torch\n",
            "copying build/lib/test/torch/test_functions.py -> build/bdist.linux-x86_64/egg/test/torch\n",
            "creating build/bdist.linux-x86_64/egg/test/torch/pointers\n",
            "copying build/lib/test/torch/pointers/__init__.py -> build/bdist.linux-x86_64/egg/test/torch/pointers\n",
            "copying build/lib/test/torch/pointers/test_callable_pointer.py -> build/bdist.linux-x86_64/egg/test/torch/pointers\n",
            "copying build/lib/test/torch/pointers/test_pointer_tensor.py -> build/bdist.linux-x86_64/egg/test/torch/pointers\n",
            "copying build/lib/test/torch/__init__.py -> build/bdist.linux-x86_64/egg/test/torch\n",
            "creating build/bdist.linux-x86_64/egg/test/torch/differential_privacy\n",
            "copying build/lib/test/torch/differential_privacy/__init__.py -> build/bdist.linux-x86_64/egg/test/torch/differential_privacy\n",
            "copying build/lib/test/torch/differential_privacy/test_pate.py -> build/bdist.linux-x86_64/egg/test/torch/differential_privacy\n",
            "creating build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_logging.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_gc.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_large_precision.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/__init__.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_autograd.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_polynomial.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_tensor.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_additive_shared.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_variable.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_native.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_precision.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_parameter.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_multi_pointer.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/test_hook.py -> build/bdist.linux-x86_64/egg/test/torch\n",
            "copying build/lib/test/torch/test_federated_learning.py -> build/bdist.linux-x86_64/egg/test/torch\n",
            "creating build/bdist.linux-x86_64/egg/test/torch/federated\n",
            "copying build/lib/test/torch/federated/__init__.py -> build/bdist.linux-x86_64/egg/test/torch/federated\n",
            "copying build/lib/test/torch/federated/test_dataset.py -> build/bdist.linux-x86_64/egg/test/torch/federated\n",
            "copying build/lib/test/torch/federated/test_dataloader.py -> build/bdist.linux-x86_64/egg/test/torch/federated\n",
            "copying build/lib/test/torch/federated/test_utils.py -> build/bdist.linux-x86_64/egg/test/torch/federated\n",
            "creating build/bdist.linux-x86_64/egg/test/torch/crypto\n",
            "copying build/lib/test/torch/crypto/__init__.py -> build/bdist.linux-x86_64/egg/test/torch/crypto\n",
            "copying build/lib/test/torch/crypto/test_snn.py -> build/bdist.linux-x86_64/egg/test/torch/crypto\n",
            "creating build/bdist.linux-x86_64/egg/test/generic\n",
            "copying build/lib/test/generic/__init__.py -> build/bdist.linux-x86_64/egg/test/generic\n",
            "copying build/lib/test/generic/test_id_provider.py -> build/bdist.linux-x86_64/egg/test/generic\n",
            "copying build/lib/test/test_dependency_check.py -> build/bdist.linux-x86_64/egg/test\n",
            "creating build/bdist.linux-x86_64/egg/test/federated\n",
            "copying build/lib/test/federated/__init__.py -> build/bdist.linux-x86_64/egg/test/federated\n",
            "copying build/lib/test/federated/test_plan.py -> build/bdist.linux-x86_64/egg/test/federated\n",
            "copying build/lib/test/federated/test_federated_client.py -> build/bdist.linux-x86_64/egg/test/federated\n",
            "copying build/lib/test/federated/test_train_config.py -> build/bdist.linux-x86_64/egg/test/federated\n",
            "creating build/bdist.linux-x86_64/egg/test/keras\n",
            "copying build/lib/test/keras/test_sequential.py -> build/bdist.linux-x86_64/egg/test/keras\n",
            "copying build/lib/test/test_grid.py -> build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/test_local_worker.py -> build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/test_serde.py -> build/bdist.linux-x86_64/egg/test\n",
            "creating build/bdist.linux-x86_64/egg/syft\n",
            "copying build/lib/syft/grid.py -> build/bdist.linux-x86_64/egg/syft\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks\n",
            "copying build/lib/syft/frameworks/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/pointers/callable_pointer.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/pointers/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/pointers/object_wrapper.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/pointers/pointer_tensor.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/pointers/object_pointer.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/differential_privacy\n",
            "copying build/lib/syft/frameworks/torch/differential_privacy/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/differential_privacy\n",
            "copying build/lib/syft/frameworks/torch/differential_privacy/pate.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/differential_privacy\n",
            "copying build/lib/syft/frameworks/torch/overload_torch.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors\n",
            "copying build/lib/syft/frameworks/torch/tensors/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/build_gradients.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/derivatives.yaml -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/large_precision.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/autograd.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/gradients.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/additive_shared.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/gradients_core.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/polynomial.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/native.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/precision.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/multi_pointer.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/plusisminus.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/abstract.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/decorators\n",
            "copying build/lib/syft/frameworks/torch/tensors/decorators/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/decorators\n",
            "copying build/lib/syft/frameworks/torch/tensors/decorators/logging.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/decorators\n",
            "copying build/lib/syft/frameworks/torch/functions.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch\n",
            "copying build/lib/syft/frameworks/torch/torch_attributes.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated\n",
            "copying build/lib/syft/frameworks/torch/federated/dataloader.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated\n",
            "copying build/lib/syft/frameworks/torch/federated/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated\n",
            "copying build/lib/syft/frameworks/torch/federated/dataset.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated\n",
            "copying build/lib/syft/frameworks/torch/federated/utils.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto\n",
            "copying build/lib/syft/frameworks/torch/crypto/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto\n",
            "copying build/lib/syft/frameworks/torch/crypto/securenn.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto\n",
            "copying build/lib/syft/frameworks/torch/crypto/spdz.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook\n",
            "copying build/lib/syft/frameworks/torch/hook/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook\n",
            "copying build/lib/syft/frameworks/torch/hook/hook.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook\n",
            "copying build/lib/syft/frameworks/torch/hook/hook_args.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/keras\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/keras/model\n",
            "copying build/lib/syft/frameworks/keras/model/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras/model\n",
            "copying build/lib/syft/frameworks/keras/model/sequential.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras/model\n",
            "copying build/lib/syft/frameworks/keras/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras\n",
            "copying build/lib/syft/frameworks/keras/hook.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras\n",
            "copying build/lib/syft/frameworks/keras/README.md -> build/bdist.linux-x86_64/egg/syft/frameworks/keras\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/keras/layers\n",
            "copying build/lib/syft/frameworks/keras/layers/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras/layers\n",
            "copying build/lib/syft/frameworks/keras/layers/constructor.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras/layers\n",
            "creating build/bdist.linux-x86_64/egg/syft/serde\n",
            "copying build/lib/syft/serde/serde.py -> build/bdist.linux-x86_64/egg/syft/serde\n",
            "copying build/lib/syft/serde/__init__.py -> build/bdist.linux-x86_64/egg/syft/serde\n",
            "copying build/lib/syft/serde/torch_serde.py -> build/bdist.linux-x86_64/egg/syft/serde\n",
            "copying build/lib/syft/serde/native_serde.py -> build/bdist.linux-x86_64/egg/syft/serde\n",
            "copying build/lib/syft/codes.py -> build/bdist.linux-x86_64/egg/syft\n",
            "copying build/lib/syft/__init__.py -> build/bdist.linux-x86_64/egg/syft\n",
            "creating build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/virtual.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/__init__.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/websocket_client.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/tfe.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/websocket_server.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/abstract.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/base.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/exceptions.py -> build/bdist.linux-x86_64/egg/syft\n",
            "creating build/bdist.linux-x86_64/egg/syft/generic\n",
            "copying build/lib/syft/generic/id_provider.py -> build/bdist.linux-x86_64/egg/syft/generic\n",
            "copying build/lib/syft/generic/__init__.py -> build/bdist.linux-x86_64/egg/syft/generic\n",
            "copying build/lib/syft/generic/object_storage.py -> build/bdist.linux-x86_64/egg/syft/generic\n",
            "creating build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/federated/__init__.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/federated/federated_client.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/federated/train_config.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/federated/plan.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/dependency_check.py -> build/bdist.linux-x86_64/egg/syft\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_sandbox.py to test_sandbox.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_udacity.py to test_udacity.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/conftest.py to conftest.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_exceptions.py to test_exceptions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test___init__.py to test___init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/workers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/workers/test_worker.py to test_worker.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/workers/test_base.py to test_base.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/workers/test_virtual.py to test_virtual.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/workers/test_websocket_worker.py to test_websocket_worker.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/test_functions.py to test_functions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/pointers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/pointers/test_callable_pointer.py to test_callable_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/pointers/test_pointer_tensor.py to test_pointer_tensor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/differential_privacy/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/differential_privacy/test_pate.py to test_pate.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_logging.py to test_logging.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_gc.py to test_gc.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_large_precision.py to test_large_precision.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_autograd.py to test_autograd.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_polynomial.py to test_polynomial.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_tensor.py to test_tensor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_additive_shared.py to test_additive_shared.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_variable.py to test_variable.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_native.py to test_native.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_precision.py to test_precision.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_parameter.py to test_parameter.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_multi_pointer.py to test_multi_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/test_hook.py to test_hook.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/test_federated_learning.py to test_federated_learning.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/federated/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/federated/test_dataset.py to test_dataset.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/federated/test_dataloader.py to test_dataloader.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/federated/test_utils.py to test_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/crypto/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/crypto/test_snn.py to test_snn.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/generic/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/generic/test_id_provider.py to test_id_provider.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_dependency_check.py to test_dependency_check.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/federated/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/federated/test_plan.py to test_plan.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/federated/test_federated_client.py to test_federated_client.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/federated/test_train_config.py to test_train_config.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/keras/test_sequential.py to test_sequential.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_grid.py to test_grid.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_local_worker.py to test_local_worker.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_serde.py to test_serde.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid.py to grid.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers/callable_pointer.py to callable_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers/object_wrapper.py to object_wrapper.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers/pointer_tensor.py to pointer_tensor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers/object_pointer.py to object_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/differential_privacy/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/differential_privacy/pate.py to pate.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/overload_torch.py to overload_torch.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/build_gradients.py to build_gradients.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/large_precision.py to large_precision.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/autograd.py to autograd.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/gradients.py to gradients.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/additive_shared.py to additive_shared.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/gradients_core.py to gradients_core.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/polynomial.py to polynomial.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/native.py to native.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/precision.py to precision.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/multi_pointer.py to multi_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/plusisminus.py to plusisminus.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/abstract.py to abstract.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/decorators/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/decorators/logging.py to logging.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/functions.py to functions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/torch_attributes.py to torch_attributes.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated/dataloader.py to dataloader.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated/dataset.py to dataset.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated/utils.py to utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto/securenn.py to securenn.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto/spdz.py to spdz.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook/hook.py to hook.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook/hook_args.py to hook_args.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/model/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/model/sequential.py to sequential.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/hook.py to hook.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/layers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/layers/constructor.py to constructor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/serde/serde.py to serde.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/serde/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/serde/torch_serde.py to torch_serde.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/serde/native_serde.py to native_serde.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/codes.py to codes.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/virtual.py to virtual.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/websocket_client.py to websocket_client.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/tfe.py to tfe.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/websocket_server.py to websocket_server.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/abstract.py to abstract.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/base.py to base.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/exceptions.py to exceptions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/generic/id_provider.py to id_provider.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/generic/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/generic/object_storage.py to object_storage.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/federated_client.py to federated_client.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/train_config.py to train_config.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/plan.py to plan.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/dependency_check.py to dependency_check.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syft.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syft.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syft.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syft.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syft.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/syft-0.1.18-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing syft-0.1.18-py3.6.egg\n",
            "Copying syft-0.1.18-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding syft 0.1.18 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/syft-0.1.18-py3.6.egg\n",
            "Processing dependencies for syft==0.1.18\n",
            "Searching for zstd>=1.4.0.0\n",
            "Reading https://pypi.org/simple/zstd/\n",
            "Downloading https://files.pythonhosted.org/packages/8e/27/1ea8086d37424e83ab692015cc8dd7d5e37cf791e339633a40dc828dfb74/zstd-1.4.0.0.tar.gz#sha256=73c90990e0878c4f45b0173135dc43fab774b8304148dba220f085cf73c2f906\n",
            "Best match: zstd 1.4.0.0\n",
            "Processing zstd-1.4.0.0.tar.gz\n",
            "Writing /tmp/easy_install-xz3w883c/zstd-1.4.0.0/setup.cfg\n",
            "Running zstd-1.4.0.0/setup.py -q bdist_egg --dist-dir /tmp/easy_install-xz3w883c/zstd-1.4.0.0/egg-dist-tmp-8fpdtn_n\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.zstd.cpython-36: module references __file__\n",
            "creating /usr/local/lib/python3.6/dist-packages/zstd-1.4.0.0-py3.6-linux-x86_64.egg\n",
            "Extracting zstd-1.4.0.0-py3.6-linux-x86_64.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding zstd 1.4.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/zstd-1.4.0.0-py3.6-linux-x86_64.egg\n",
            "Searching for websockets>=7.0\n",
            "Reading https://pypi.org/simple/websockets/\n",
            "Downloading https://files.pythonhosted.org/packages/43/71/8bfa882b9c502c36e5c9ef6732969533670d2b039cbf95a82ced8f762b80/websockets-7.0-cp36-cp36m-manylinux1_x86_64.whl#sha256=79691794288bc51e2a3b8de2bc0272ca8355d0b8503077ea57c0716e840ebaef\n",
            "Best match: websockets 7.0\n",
            "Processing websockets-7.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Installing websockets-7.0-cp36-cp36m-manylinux1_x86_64.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding websockets 7.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/websockets-7.0-py3.6-linux-x86_64.egg\n",
            "Searching for websocket_client>=0.56.0\n",
            "Reading https://pypi.org/simple/websocket_client/\n",
            "Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl#sha256=1151d5fb3a62dc129164292e1227655e4bbc5dd5340a5165dfae61128ec50aa9\n",
            "Best match: websocket-client 0.56.0\n",
            "Processing websocket_client-0.56.0-py2.py3-none-any.whl\n",
            "Installing websocket_client-0.56.0-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "writing requirements to /usr/local/lib/python3.6/dist-packages/websocket_client-0.56.0-py3.6.egg/EGG-INFO/requires.txt\n",
            "Adding websocket-client 0.56.0 to easy-install.pth file\n",
            "Installing wsdump.py script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/websocket_client-0.56.0-py3.6.egg\n",
            "Searching for tf_encrypted>=0.5.4\n",
            "Reading https://pypi.org/simple/tf_encrypted/\n",
            "Downloading https://files.pythonhosted.org/packages/07/ce/da9916e7e78f736894b15538b702c0b213fd5d60a7fd6e481d74033a90c0/tf_encrypted-0.5.6-py3-none-manylinux1_x86_64.whl#sha256=4b230475ca37e0cbb1b3c48ffb6785436e7d35e4ff1d87edfcd3668532f2cc1a\n",
            "Best match: tf-encrypted 0.5.6\n",
            "Processing tf_encrypted-0.5.6-py3-none-manylinux1_x86_64.whl\n",
            "Installing tf_encrypted-0.5.6-py3-none-manylinux1_x86_64.whl to /usr/local/lib/python3.6/dist-packages\n",
            "writing requirements to /usr/local/lib/python3.6/dist-packages/tf_encrypted-0.5.6-py3.6-linux-x86_64.egg/EGG-INFO/requires.txt\n",
            "Adding tf-encrypted 0.5.6 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/tf_encrypted-0.5.6-py3.6-linux-x86_64.egg\n",
            "Searching for msgpack>=0.6.1\n",
            "Reading https://pypi.org/simple/msgpack/\n",
            "Downloading https://files.pythonhosted.org/packages/92/7e/ae9e91c1bb8d846efafd1f353476e3fd7309778b582d2fb4cea4cc15b9a2/msgpack-0.6.1-cp36-cp36m-manylinux1_x86_64.whl#sha256=62bd8e43d204580308d477a157b78d3fee2fb4c15d32578108dc5d89866036c8\n",
            "Best match: msgpack 0.6.1\n",
            "Processing msgpack-0.6.1-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Installing msgpack-0.6.1-cp36-cp36m-manylinux1_x86_64.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding msgpack 0.6.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/msgpack-0.6.1-py3.6-linux-x86_64.egg\n",
            "Searching for lz4>=2.1.6\n",
            "Reading https://pypi.org/simple/lz4/\n",
            "Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl#sha256=b2b7f0902a6740ea0acac3d59ffd8ee7120cf058e3ef5bdebd0685763b99a5ae\n",
            "Best match: lz4 2.1.10\n",
            "Processing lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Installing lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl to /usr/local/lib/python3.6/dist-packages\n",
            "writing requirements to /usr/local/lib/python3.6/dist-packages/lz4-2.1.10-py3.6-linux-x86_64.egg/EGG-INFO/requires.txt\n",
            "Adding lz4 2.1.10 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/lz4-2.1.10-py3.6-linux-x86_64.egg\n",
            "Searching for flask_socketio>=3.3.2\n",
            "Reading https://pypi.org/simple/flask_socketio/\n",
            "Downloading https://files.pythonhosted.org/packages/4b/68/fe4806d3a0a5909d274367eb9b3b87262906c1515024f46c2443a36a0c82/Flask_SocketIO-4.1.0-py2.py3-none-any.whl#sha256=f6f7e0205f0dd92d98a87e3f6d26d94ade29ca380ba383b505070674c804ae2e\n",
            "Best match: Flask-SocketIO 4.1.0\n",
            "Processing Flask_SocketIO-4.1.0-py2.py3-none-any.whl\n",
            "Installing Flask_SocketIO-4.1.0-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "writing requirements to /usr/local/lib/python3.6/dist-packages/Flask_SocketIO-4.1.0-py3.6.egg/EGG-INFO/requires.txt\n",
            "Adding Flask-SocketIO 4.1.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/Flask_SocketIO-4.1.0-py3.6.egg\n",
            "Searching for pyyaml>=5.1\n",
            "Reading https://pypi.org/simple/pyyaml/\n",
            "Downloading https://files.pythonhosted.org/packages/a3/65/837fefac7475963d1eccf4aa684c23b95aa6c1d033a2c5965ccb11e22623/PyYAML-5.1.1.tar.gz#sha256=b4bb4d3f5e232425e25dda21c070ce05168a786ac9eda43768ab7f3ac2770955\n",
            "Best match: PyYAML 5.1.1\n",
            "Processing PyYAML-5.1.1.tar.gz\n",
            "Writing /tmp/easy_install-iw20iune/PyYAML-5.1.1/setup.cfg\n",
            "Running PyYAML-5.1.1/setup.py -q bdist_egg --dist-dir /tmp/easy_install-iw20iune/PyYAML-5.1.1/egg-dist-tmp-_gjmkila\n",
            "In file included from \u001b[01m\u001b[Kext/_yaml.c:596:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kext/_yaml.h:2:10:\u001b[m\u001b[K \u001b[01;31m\u001b[Kfatal error: \u001b[m\u001b[Kyaml.h: No such file or directory\n",
            " #include \u001b[01;31m\u001b[K<yaml.h>\u001b[m\u001b[K\n",
            "          \u001b[01;31m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "compilation terminated.\n",
            "Error compiling module, falling back to pure Python\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "Moving PyYAML-5.1.1-py3.6-linux-x86_64.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding PyYAML 5.1.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/PyYAML-5.1.1-py3.6-linux-x86_64.egg\n",
            "Searching for python-socketio>=2.1.0\n",
            "Reading https://pypi.org/simple/python-socketio/\n",
            "Downloading https://files.pythonhosted.org/packages/c8/e0/a875abbb0f9d70c6e2ec2019ca9e3893377cef5deca6225ead3497000152/python_socketio-4.1.0-py2.py3-none-any.whl#sha256=89a48591a8850c1f30d735f8e5a0294846da245a9b8940c39e1106e460c7a14e\n",
            "Best match: python-socketio 4.1.0\n",
            "Processing python_socketio-4.1.0-py2.py3-none-any.whl\n",
            "Installing python_socketio-4.1.0-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "writing requirements to /usr/local/lib/python3.6/dist-packages/python_socketio-4.1.0-py3.6.egg/EGG-INFO/requires.txt\n",
            "Adding python-socketio 4.1.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/python_socketio-4.1.0-py3.6.egg\n",
            "Searching for python-engineio>=3.8.0\n",
            "Reading https://pypi.org/simple/python-engineio/\n",
            "Downloading https://files.pythonhosted.org/packages/9c/d3/de0fa7ebebd054de308e6ac397bf9e11ea42924795a38005a21ea001b114/python_engineio-3.8.1-py2.py3-none-any.whl#sha256=d3315d3f972bd9bd32e0738d45801a912f522177ff75094762f31a8c341d1f41\n",
            "Best match: python-engineio 3.8.1\n",
            "Processing python_engineio-3.8.1-py2.py3-none-any.whl\n",
            "Installing python_engineio-3.8.1-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "writing requirements to /usr/local/lib/python3.6/dist-packages/python_engineio-3.8.1-py3.6.egg/EGG-INFO/requires.txt\n",
            "Adding python-engineio 3.8.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/python_engineio-3.8.1-py3.6.egg\n",
            "Searching for torchvision==0.3.0\n",
            "Best match: torchvision 0.3.0\n",
            "Adding torchvision 0.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for torch==1.1.0\n",
            "Best match: torch 1.1.0\n",
            "Adding torch 1.1.0 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tblib==1.4.0\n",
            "Best match: tblib 1.4.0\n",
            "Adding tblib 1.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scikit-learn==0.21.2\n",
            "Best match: scikit-learn 0.21.2\n",
            "Adding scikit-learn 0.21.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.16.4\n",
            "Best match: numpy 1.16.4\n",
            "Adding numpy 1.16.4 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Flask==1.0.3\n",
            "Best match: Flask 1.0.3\n",
            "Adding Flask 1.0.3 to easy-install.pth file\n",
            "Installing flask script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.12.0\n",
            "Best match: six 1.12.0\n",
            "Adding six 1.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Pillow==4.3.0\n",
            "Best match: Pillow 4.3.0\n",
            "Adding Pillow 4.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorflow==1.14.0rc1\n",
            "Best match: tensorflow 1.14.0rc1\n",
            "Adding tensorflow 1.14.0rc1 to easy-install.pth file\n",
            "Installing freeze_graph script to /usr/local/bin\n",
            "Installing saved_model_cli script to /usr/local/bin\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "Installing tf_upgrade_v2 script to /usr/local/bin\n",
            "Installing tflite_convert script to /usr/local/bin\n",
            "Installing toco script to /usr/local/bin\n",
            "Installing toco_from_protos script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for joblib==0.13.2\n",
            "Best match: joblib 0.13.2\n",
            "Adding joblib 0.13.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scipy==1.3.0\n",
            "Best match: scipy 1.3.0\n",
            "Adding scipy 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for itsdangerous==1.1.0\n",
            "Best match: itsdangerous 1.1.0\n",
            "Adding itsdangerous 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Click==7.0\n",
            "Best match: Click 7.0\n",
            "Adding Click 7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Werkzeug==0.15.4\n",
            "Best match: Werkzeug 0.15.4\n",
            "Adding Werkzeug 0.15.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Jinja2==2.10.1\n",
            "Best match: Jinja2 2.10.1\n",
            "Adding Jinja2 2.10.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for olefile==0.46\n",
            "Best match: olefile 0.46\n",
            "Adding olefile 0.46 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for astor==0.8.0\n",
            "Best match: astor 0.8.0\n",
            "Adding astor 0.8.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for gast==0.2.2\n",
            "Best match: gast 0.2.2\n",
            "Adding gast 0.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for google-pasta==0.1.7\n",
            "Best match: google-pasta 0.1.7\n",
            "Adding google-pasta 0.1.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for termcolor==1.1.0\n",
            "Best match: termcolor 1.1.0\n",
            "Adding termcolor 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for wheel==0.33.4\n",
            "Best match: wheel 0.33.4\n",
            "Adding wheel 0.33.4 to easy-install.pth file\n",
            "Installing wheel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for wrapt==1.11.1\n",
            "Best match: wrapt 1.11.1\n",
            "Adding wrapt 1.11.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorflow-estimator==1.14.0rc1\n",
            "Best match: tensorflow-estimator 1.14.0rc1\n",
            "Adding tensorflow-estimator 1.14.0rc1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorboard==1.13.1\n",
            "Best match: tensorboard 1.13.1\n",
            "Adding tensorboard 1.13.1 to easy-install.pth file\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for protobuf==3.7.1\n",
            "Best match: protobuf 3.7.1\n",
            "Adding protobuf 3.7.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for grpcio==1.15.0\n",
            "Best match: grpcio 1.15.0\n",
            "Adding grpcio 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Keras-Preprocessing==1.1.0\n",
            "Best match: Keras-Preprocessing 1.1.0\n",
            "Adding Keras-Preprocessing 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Keras-Applications==1.0.8\n",
            "Best match: Keras-Applications 1.0.8\n",
            "Adding Keras-Applications 1.0.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for absl-py==0.7.1\n",
            "Best match: absl-py 0.7.1\n",
            "Adding absl-py 0.7.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for MarkupSafe==1.1.1\n",
            "Best match: MarkupSafe 1.1.1\n",
            "Adding MarkupSafe 1.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Markdown==3.1.1\n",
            "Best match: Markdown 3.1.1\n",
            "Adding Markdown 3.1.1 to easy-install.pth file\n",
            "Installing markdown_py script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for setuptools==41.0.1\n",
            "Best match: setuptools 41.0.1\n",
            "Adding setuptools 41.0.1 to easy-install.pth file\n",
            "Installing easy_install script to /usr/local/bin\n",
            "Installing easy_install-3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for h5py==2.8.0\n",
            "Best match: h5py 2.8.0\n",
            "Adding h5py 2.8.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for syft==0.1.18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YcbmJmzxlIR",
        "colab_type": "code",
        "outputId": "96df12d9-21f4-49eb-85a4-6dd200ccdb3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1367
        }
      },
      "source": [
        "! python3 setup.py test"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running pytest\n",
            "Searching for msgpack>=0.6.1\n",
            "Best match: msgpack 0.6.1\n",
            "Processing msgpack-0.6.1-py3.6-linux-x86_64.egg\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages/msgpack-0.6.1-py3.6-linux-x86_64.egg\n",
            "Searching for pyyaml>=5.1\n",
            "Best match: PyYAML 5.1.1\n",
            "Processing PyYAML-5.1.1-py3.6-linux-x86_64.egg\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages/PyYAML-5.1.1-py3.6-linux-x86_64.egg\n",
            "Searching for pytest-flake8\n",
            "Reading https://pypi.org/simple/pytest-flake8/\n",
            "Downloading https://files.pythonhosted.org/packages/4b/99/a6e993c0927665522602058e1f2ea61ba1c8c51a60e3006f1eb1153b37e2/pytest_flake8-1.0.4-py2.py3-none-any.whl#sha256=d7e2b6b274a255b7ae35e9224c85294b471a83b76ecb6bd53c337ae977a499af\n",
            "Best match: pytest-flake8 1.0.4\n",
            "Processing pytest_flake8-1.0.4-py2.py3-none-any.whl\n",
            "Installing pytest_flake8-1.0.4-py2.py3-none-any.whl to /content/PySyft/.eggs\n",
            "writing requirements to /content/PySyft/.eggs/pytest_flake8-1.0.4-py3.6.egg/EGG-INFO/requires.txt\n",
            "\n",
            "Installed /content/PySyft/.eggs/pytest_flake8-1.0.4-py3.6.egg\n",
            "Searching for flake8>=3.5\n",
            "Reading https://pypi.org/simple/flake8/\n",
            "Downloading https://files.pythonhosted.org/packages/e9/76/b915bd28976068a9843bf836b789794aa4a8eb13338b23581005cd9177c0/flake8-3.7.7-py2.py3-none-any.whl#sha256=a796a115208f5c03b18f332f7c11729812c8c3ded6c46319c59b53efd3819da8\n",
            "Best match: flake8 3.7.7\n",
            "Processing flake8-3.7.7-py2.py3-none-any.whl\n",
            "Installing flake8-3.7.7-py2.py3-none-any.whl to /content/PySyft/.eggs\n",
            "writing requirements to /content/PySyft/.eggs/flake8-3.7.7-py3.6.egg/EGG-INFO/requires.txt\n",
            "\n",
            "Installed /content/PySyft/.eggs/flake8-3.7.7-py3.6.egg\n",
            "Searching for pyflakes<2.2.0,>=2.1.0\n",
            "Reading https://pypi.org/simple/pyflakes/\n",
            "Downloading https://files.pythonhosted.org/packages/84/f2/ed0ffb887f8138a8fe5a621b8c0bb9598bfb3989e029f6c6a85ee66628ee/pyflakes-2.1.1-py2.py3-none-any.whl#sha256=17dbeb2e3f4d772725c777fabc446d5634d1038f234e77343108ce445ea69ce0\n",
            "Best match: pyflakes 2.1.1\n",
            "Processing pyflakes-2.1.1-py2.py3-none-any.whl\n",
            "Installing pyflakes-2.1.1-py2.py3-none-any.whl to /content/PySyft/.eggs\n",
            "\n",
            "Installed /content/PySyft/.eggs/pyflakes-2.1.1-py3.6.egg\n",
            "Searching for pycodestyle<2.6.0,>=2.5.0\n",
            "Reading https://pypi.org/simple/pycodestyle/\n",
            "Downloading https://files.pythonhosted.org/packages/0e/0c/04a353e104d2f324f8ee5f4b32012618c1c86dd79e52a433b64fceed511b/pycodestyle-2.5.0-py2.py3-none-any.whl#sha256=95a2219d12372f05704562a14ec30bc76b05a5b297b21a5dfe3f6fac3491ae56\n",
            "Best match: pycodestyle 2.5.0\n",
            "Processing pycodestyle-2.5.0-py2.py3-none-any.whl\n",
            "Installing pycodestyle-2.5.0-py2.py3-none-any.whl to /content/PySyft/.eggs\n",
            "\n",
            "Installed /content/PySyft/.eggs/pycodestyle-2.5.0-py3.6.egg\n",
            "Searching for mccabe<0.7.0,>=0.6.0\n",
            "Reading https://pypi.org/simple/mccabe/\n",
            "Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl#sha256=ab8a6258860da4b6677da4bd2fe5dc2c659cff31b3ee4f7f5d64e79735b80d42\n",
            "Best match: mccabe 0.6.1\n",
            "Processing mccabe-0.6.1-py2.py3-none-any.whl\n",
            "Installing mccabe-0.6.1-py2.py3-none-any.whl to /content/PySyft/.eggs\n",
            "\n",
            "Installed /content/PySyft/.eggs/mccabe-0.6.1-py3.6.egg\n",
            "running egg_info\n",
            "writing syft.egg-info/PKG-INFO\n",
            "writing dependency_links to syft.egg-info/dependency_links.txt\n",
            "writing requirements to syft.egg-info/requires.txt\n",
            "writing top-level names to syft.egg-info/top_level.txt\n",
            "writing manifest file 'syft.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.6.8, pytest-3.6.4, py-1.8.0, pluggy-0.7.1 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/PySyft, inifile: setup.cfg\n",
            "plugins: flake8-1.0.4\n",
            "collected 300 items / 1 errors                                                 \u001b[0m\n",
            "\n",
            "==================================== ERRORS ====================================\n",
            "____________ ERROR collecting test/workers/test_websocket_worker.py ____________\n",
            "\u001b[31mImportError while importing test module '/content/PySyft/test/workers/test_websocket_worker.py'.\n",
            "Hint: make sure your test modules/packages have valid Python names.\n",
            "Traceback:\n",
            "test/workers/test_websocket_worker.py:5: in <module>\n",
            "    from OpenSSL import crypto, SSL\n",
            "E   ModuleNotFoundError: No module named 'OpenSSL'\u001b[0m\n",
            "!!!!!!!!!!!!!!!!!!! Interrupted: 1 errors during collection !!!!!!!!!!!!!!!!!!!!\n",
            "\u001b[31m\u001b[1m=========================== 1 error in 1.91 seconds ============================\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Bz8UEHYKhzR",
        "colab_type": "code",
        "outputId": "5e6ecdcb-2470-48c3-ab5d-1b54079369c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "! git clone https://github.com/tf-encrypted/tf-encrypted"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tf-encrypted'...\n",
            "remote: Enumerating objects: 182, done.\u001b[K\n",
            "remote: Counting objects: 100% (182/182), done.\u001b[K\n",
            "remote: Compressing objects: 100% (127/127), done.\u001b[K\n",
            "remote: Total 5496 (delta 112), reused 95 (delta 55), pack-reused 5314\u001b[K\n",
            "Receiving objects: 100% (5496/5496), 20.82 MiB | 27.65 MiB/s, done.\n",
            "Resolving deltas: 100% (3691/3691), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isQUzm9oaPKU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "0d8e2577-cd82-4a61-8654-533e4ada0011"
      },
      "source": [
        "! pip install --upgrade msgpack"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting msgpack\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/7e/ae9e91c1bb8d846efafd1f353476e3fd7309778b582d2fb4cea4cc15b9a2/msgpack-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 4.9MB/s \n",
            "\u001b[?25hInstalling collected packages: msgpack\n",
            "  Found existing installation: msgpack 0.5.6\n",
            "    Uninstalling msgpack-0.5.6:\n",
            "      Successfully uninstalled msgpack-0.5.6\n",
            "Successfully installed msgpack-0.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzF7Mv13KuYn",
        "colab_type": "code",
        "outputId": "eccfbb86-7b20-4951-c9da-0ae43bac1790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd tf-encrypted/"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/PySyft/tf-encrypted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqTgOd5ZhT3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! git checkout 22e4ae8f415926b8886a09f13279f905cec3443f ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOrZ4jEAedKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! git checkout 96ebb3984fc69b9067dc4eefcb6ed5bac1e2255d . "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idIpQ2oPKxsA",
        "colab_type": "code",
        "outputId": "77216fa7-8f2f-4a93-8533-5718a25eacd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        }
      },
      "source": [
        "! pip3 install -e ."
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/PySyft/tf-encrypted\n",
            "Requirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted==0.5.6) (1.14.0rc1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted==0.5.6) (1.16.4)\n",
            "Collecting pyyaml>=5.1 (from tf-encrypted==0.5.6)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/837fefac7475963d1eccf4aa684c23b95aa6c1d033a2c5965ccb11e22623/PyYAML-5.1.1.tar.gz (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (0.33.4)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.14.0rc1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (3.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (0.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (0.1.7)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.13.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.11.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (0.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (41.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (0.15.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (2.8.0)\n",
            "Building wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/27/a1/775c62ddea7bfa62324fd1f65847ed31c55dadb6051481ba3f\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml, tf-encrypted\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: tf-encrypted 0.5.6\n",
            "    Uninstalling tf-encrypted-0.5.6:\n",
            "      Successfully uninstalled tf-encrypted-0.5.6\n",
            "  Running setup.py develop for tf-encrypted\n",
            "Successfully installed pyyaml-5.1.1 tf-encrypted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5V_P4A-LYvt",
        "colab_type": "code",
        "outputId": "c7c5d217-6cce-44de-ef87-9927bf26c5a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "import tf_encrypted as tfe"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0626 12:09:52.773031 140462763644800 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/content/PySyft/tf-encrypted/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0-rc1.so'\n",
            "W0626 12:09:52.819259 140462763644800 deprecation_wrapper.py:119] From /content/PySyft/tf-encrypted/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eG6uk3tLYLH",
        "colab_type": "code",
        "outputId": "c8ad397c-3287-4bcb-fc74-fb7efbf40a2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd .."
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/PySyft\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qE06p18vvQyF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "6689fa3a-1472-4afb-a901-7b2bdef5db1f"
      },
      "source": [
        "! pip install websocket"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting websocket\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/6d/a60d620ea575c885510c574909d2e3ed62129b121fa2df00ca1c81024c87/websocket-0.2.1.tar.gz (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: gevent in /usr/local/lib/python3.6/dist-packages (from websocket) (1.4.0)\n",
            "Requirement already satisfied: greenlet in /usr/local/lib/python3.6/dist-packages (from websocket) (0.4.15)\n",
            "Building wheels for collected packages: websocket\n",
            "  Building wheel for websocket (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/f7/5c/9e8243838269ea93f05295708519a6e183fa6b515d9ce3b636\n",
            "Successfully built websocket\n",
            "Installing collected packages: websocket\n",
            "Successfully installed websocket-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfWmuSv9vY6Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "314d6df8-0762-41ab-aa45-f4b9d75df5af"
      },
      "source": [
        "! pip install websocket"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting websocket\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/6d/a60d620ea575c885510c574909d2e3ed62129b121fa2df00ca1c81024c87/websocket-0.2.1.tar.gz (195kB)\n",
            "\r\u001b[K     |█▊                              | 10kB 16.3MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 40kB 3.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 51kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 61kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 71kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 81kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 92kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 102kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 112kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 122kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 133kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 143kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 153kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 163kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 174kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 184kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 194kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 204kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: gevent in /usr/local/lib/python3.6/dist-packages (from websocket) (1.4.0)\n",
            "Requirement already satisfied: greenlet in /usr/local/lib/python3.6/dist-packages (from websocket) (0.4.15)\n",
            "Building wheels for collected packages: websocket\n",
            "  Building wheel for websocket (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/f7/5c/9e8243838269ea93f05295708519a6e183fa6b515d9ce3b636\n",
            "Successfully built websocket\n",
            "Installing collected packages: websocket\n",
            "Successfully installed websocket-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tAOAPPpauGW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "7a0fbfe2-daba-469b-c493-36b3036329ce"
      },
      "source": [
        "! pip install --upgrade websockets"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: websockets in /usr/local/lib/python3.6/dist-packages/websockets-7.0-py3.6-linux-x86_64.egg (7.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1tqqappjI2x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f198ce46-9c40-4076-9eb6-d56cd47e8ec6"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbgzhrWCjGcO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mv websocket_client.py PySyft/syft/workers/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vabIbymkjU5b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0c520b74-193b-46b9-a29d-cfd04f617fbd"
      },
      "source": [
        "cd PySyft/"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/PySyft\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdmOZjRvJwjk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "outputId": "5da4600a-2e39-4659-ac84-c69961ba532f"
      },
      "source": [
        "import syft as sy"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-281ee5c8ca5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msyft\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/PySyft/syft/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"Some syft imports...\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Major imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msyft\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mframeworks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msyft\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msyft\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"keras\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"torch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfederated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdifferential_privacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcrypto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpointers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/tensors/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Do not change the import sequence it can cause deadlock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minterpreters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecorators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"decorators\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"interpreters\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/tensors/interpreters/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mabstract\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAbstractTensor\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnative\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTorchTensor\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprecision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFixedPrecisionTensor\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0madditive_shared\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdditiveSharingTensor\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmulti_pointer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiPointerTensor\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInvalidTensorForRemoteGet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeworks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpreters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAbstractTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeworks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpointers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPointerTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseWorker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/pointers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeworks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpointers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallable_pointer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_callable_pointer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeworks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpointers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallable_pointer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallablePointer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeworks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpointers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpointer_tensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPointerTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeworks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpointers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mObjectWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/pointers/pointer_tensor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeworks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpointers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAbstractWorker\u001b[0m  \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/workers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvirtual\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVirtualWorker\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwebsocket_client\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWebsocketClientWorker\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwebsocket_server\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWebsocketServerWorker\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msyft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTFEWorker\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/workers/websocket_client.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwebsocket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'websocket'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F05eMKZdy8TB",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8aLBtlRby8TG",
        "colab": {}
      },
      "source": [
        "#import syft as sy  # <-- NEW: import the Pysyft library\n",
        "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")  # <-- NEW: define remote worker bob\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")  # <-- NEW: and alice"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wCl4Khdyugu",
        "colab_type": "text"
      },
      "source": [
        "### SPLIT LEARNING GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GZ6lP80ddBiV",
        "colab": {}
      },
      "source": [
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 64\n",
        "        self.test_batch_size = 1000\n",
        "        self.epochs = 10\n",
        "        self.lr = 0.01\n",
        "        self.momentum = 0.5\n",
        "        self.no_cuda = False\n",
        "        self.seed = 1\n",
        "        self.log_interval = 30\n",
        "        self.save_model = False\n",
        "\n",
        "args = Arguments()\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "if use_cuda:\n",
        "        # TODO Quickhack. Actually need to fix the problem moving the model to CUDA\\n\",\n",
        "        torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "#device = torch.device(\"cpu\")\n",
        "\n",
        "#kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "kwargs = {'num_workers': 0, 'pin_memory': False} if use_cuda else {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "da208f86-8baf-493e-c761-11b071559fa9",
        "id": "0P-qt7WRdBiZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n",
        "    .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
        "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=args.test_batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 16384/9912422 [00:00<01:09, 143250.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 32530584.69it/s]                           \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 439790.58it/s]\n",
            "  1%|          | 16384/1648877 [00:00<00:11, 146267.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 7574228.65it/s]                            \n",
            "8192it [00:00, 179979.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t0Ly9q7NdBif",
        "colab": {}
      },
      "source": [
        "class Net1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net1, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        return F.max_pool2d(x, 2, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTRCegEAfiBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net2, self).__init__()\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc_jVaQgf9qE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = [Net1().to(device), Net1().to(device)]\n",
        "models[0] = models[0].send(bob)\n",
        "models[1] = models[1].send(alice)\n",
        "\n",
        "\n",
        "\n",
        "opt1 = optim.SGD(params=models[0].parameters(),lr=0.1)\n",
        "opt2 = optim.SGD(params=models[1].parameters(),lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "feBHg_uKdBig",
        "colab": {}
      },
      "source": [
        "def train(args, model, device, federated_train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, targs) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
        "        #IF ON DATA LOCATION TO GET THE RIGHT MODEL\n",
        "        if data.location.id == 'bob':\n",
        "          mod_c,opt_c = models[0], opt1\n",
        "        else : \n",
        "          mod_c,opt_c = models[1], opt2\n",
        "          \n",
        "       # 1) erase previous gradients (if they exist)\n",
        "        optimizer.step()\n",
        "        opt_c.step()\n",
        "        opt_c.zero_grad()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        tg_copy = targs.copy()\n",
        "        target = tg_copy.get()\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        # 2) make a prediction until cut layer (client location)\n",
        "        pred_c = mod_c(data)\n",
        "        copy = pred_c.copy()\n",
        "        \n",
        "        # 3) get this to the server \n",
        "        inp = copy.get()\n",
        "\n",
        "        # 4) make prediction with second part of the model (server location)\n",
        "        pred = model(inp)\n",
        "\n",
        "        # 5) calculate how much we missed \n",
        "        loss = F.nll_loss(pred, target)\n",
        "        loss.backward()\n",
        "        \n",
        "        gradient = inp.grad\n",
        "        gradient = gradient.send(data.location)\n",
        "        #print(\"grad shape:\",gradient.shape)\n",
        "        #print(\"pred_c shape:\", pred_c.shape)\n",
        "        #gradient = gradient.view(pred_c.shape)\n",
        "        pred_c.backward(gradient)\n",
        "        \n",
        "        \n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            #loss = loss.get() # <-- NEW: get the loss back\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,\n",
        "                100. * batch_idx / len(federated_train_loader), loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0wCZFKeZdBim",
        "colab": {}
      },
      "source": [
        "def test(args, model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    M1 = models[0].copy()\n",
        "    M2 = models[1].copy()\n",
        "    M1 = M1.get()\n",
        "    M2 = M2.get()\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(M1(data))\n",
        "            #output2 = model(M2(data))\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b9f350d0-4f1a-4cef-f13e-c992aafa57d5",
        "id": "XOsYH8HTiW0n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2109
        }
      },
      "source": [
        "%%time\n",
        "model = Net2().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(args, model, device, federated_train_loader, optimizer, epoch)\n",
        "    test(args, model, device, test_loader)\n",
        "\n",
        "if (args.save_model):\n",
        "    torch.save(model.state_dict(), \"mnist_cnn.pt\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60032 (0%)]\tLoss: 2.253029\n",
            "Train Epoch: 1 [1920/60032 (3%)]\tLoss: 1.232375\n",
            "Train Epoch: 1 [3840/60032 (6%)]\tLoss: 0.757512\n",
            "Train Epoch: 1 [5760/60032 (10%)]\tLoss: 0.364047\n",
            "Train Epoch: 1 [7680/60032 (13%)]\tLoss: 0.513790\n",
            "Train Epoch: 1 [9600/60032 (16%)]\tLoss: 0.288561\n",
            "Train Epoch: 1 [11520/60032 (19%)]\tLoss: 0.373806\n",
            "Train Epoch: 1 [13440/60032 (22%)]\tLoss: 0.497560\n",
            "Train Epoch: 1 [15360/60032 (26%)]\tLoss: 0.155243\n",
            "Train Epoch: 1 [17280/60032 (29%)]\tLoss: 0.448969\n",
            "Train Epoch: 1 [19200/60032 (32%)]\tLoss: 0.192030\n",
            "Train Epoch: 1 [21120/60032 (35%)]\tLoss: 0.176506\n",
            "Train Epoch: 1 [23040/60032 (38%)]\tLoss: 0.181207\n",
            "Train Epoch: 1 [24960/60032 (42%)]\tLoss: 0.291539\n",
            "Train Epoch: 1 [26880/60032 (45%)]\tLoss: 0.281255\n",
            "Train Epoch: 1 [28800/60032 (48%)]\tLoss: 0.216463\n",
            "Train Epoch: 1 [30720/60032 (51%)]\tLoss: 0.452938\n",
            "Train Epoch: 1 [32640/60032 (54%)]\tLoss: 0.387530\n",
            "Train Epoch: 1 [34560/60032 (58%)]\tLoss: 0.239093\n",
            "Train Epoch: 1 [36480/60032 (61%)]\tLoss: 0.322200\n",
            "Train Epoch: 1 [38400/60032 (64%)]\tLoss: 0.149250\n",
            "Train Epoch: 1 [40320/60032 (67%)]\tLoss: 0.286039\n",
            "Train Epoch: 1 [42240/60032 (70%)]\tLoss: 0.109953\n",
            "Train Epoch: 1 [44160/60032 (74%)]\tLoss: 0.099975\n",
            "Train Epoch: 1 [46080/60032 (77%)]\tLoss: 0.184736\n",
            "Train Epoch: 1 [48000/60032 (80%)]\tLoss: 0.122621\n",
            "Train Epoch: 1 [49920/60032 (83%)]\tLoss: 0.144660\n",
            "Train Epoch: 1 [51840/60032 (86%)]\tLoss: 0.029555\n",
            "Train Epoch: 1 [53760/60032 (90%)]\tLoss: 0.272693\n",
            "Train Epoch: 1 [55680/60032 (93%)]\tLoss: 0.170877\n",
            "Train Epoch: 1 [57600/60032 (96%)]\tLoss: 0.076190\n",
            "Train Epoch: 1 [59520/60032 (99%)]\tLoss: 0.070564\n",
            "\n",
            "Test set: Average loss: 0.1253, Accuracy: 9604/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60032 (0%)]\tLoss: 0.064309\n",
            "Train Epoch: 2 [1920/60032 (3%)]\tLoss: 0.059504\n",
            "Train Epoch: 2 [3840/60032 (6%)]\tLoss: 0.170232\n",
            "Train Epoch: 2 [5760/60032 (10%)]\tLoss: 0.050915\n",
            "Train Epoch: 2 [7680/60032 (13%)]\tLoss: 0.039312\n",
            "Train Epoch: 2 [9600/60032 (16%)]\tLoss: 0.169014\n",
            "Train Epoch: 2 [11520/60032 (19%)]\tLoss: 0.048337\n",
            "Train Epoch: 2 [13440/60032 (22%)]\tLoss: 0.177421\n",
            "Train Epoch: 2 [15360/60032 (26%)]\tLoss: 0.020883\n",
            "Train Epoch: 2 [17280/60032 (29%)]\tLoss: 0.092050\n",
            "Train Epoch: 2 [19200/60032 (32%)]\tLoss: 0.132664\n",
            "Train Epoch: 2 [21120/60032 (35%)]\tLoss: 0.067174\n",
            "Train Epoch: 2 [23040/60032 (38%)]\tLoss: 0.185464\n",
            "Train Epoch: 2 [24960/60032 (42%)]\tLoss: 0.062636\n",
            "Train Epoch: 2 [26880/60032 (45%)]\tLoss: 0.089147\n",
            "Train Epoch: 2 [28800/60032 (48%)]\tLoss: 0.091625\n",
            "Train Epoch: 2 [30720/60032 (51%)]\tLoss: 0.180251\n",
            "Train Epoch: 2 [32640/60032 (54%)]\tLoss: 0.171684\n",
            "Train Epoch: 2 [34560/60032 (58%)]\tLoss: 0.099416\n",
            "Train Epoch: 2 [36480/60032 (61%)]\tLoss: 0.141496\n",
            "Train Epoch: 2 [38400/60032 (64%)]\tLoss: 0.069605\n",
            "Train Epoch: 2 [40320/60032 (67%)]\tLoss: 0.116553\n",
            "Train Epoch: 2 [42240/60032 (70%)]\tLoss: 0.030538\n",
            "Train Epoch: 2 [44160/60032 (74%)]\tLoss: 0.055049\n",
            "Train Epoch: 2 [46080/60032 (77%)]\tLoss: 0.021086\n",
            "Train Epoch: 2 [48000/60032 (80%)]\tLoss: 0.150247\n",
            "Train Epoch: 2 [49920/60032 (83%)]\tLoss: 0.051076\n",
            "Train Epoch: 2 [51840/60032 (86%)]\tLoss: 0.041261\n",
            "Train Epoch: 2 [53760/60032 (90%)]\tLoss: 0.193274\n",
            "Train Epoch: 2 [55680/60032 (93%)]\tLoss: 0.108142\n",
            "Train Epoch: 2 [57600/60032 (96%)]\tLoss: 0.124839\n",
            "Train Epoch: 2 [59520/60032 (99%)]\tLoss: 0.045661\n",
            "\n",
            "Test set: Average loss: 0.0958, Accuracy: 9697/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60032 (0%)]\tLoss: 0.146108\n",
            "Train Epoch: 3 [1920/60032 (3%)]\tLoss: 0.089724\n",
            "Train Epoch: 3 [3840/60032 (6%)]\tLoss: 0.062068\n",
            "Train Epoch: 3 [5760/60032 (10%)]\tLoss: 0.027066\n",
            "Train Epoch: 3 [7680/60032 (13%)]\tLoss: 0.063330\n",
            "Train Epoch: 3 [9600/60032 (16%)]\tLoss: 0.084789\n",
            "Train Epoch: 3 [11520/60032 (19%)]\tLoss: 0.019617\n",
            "Train Epoch: 3 [13440/60032 (22%)]\tLoss: 0.034115\n",
            "Train Epoch: 3 [15360/60032 (26%)]\tLoss: 0.111855\n",
            "Train Epoch: 3 [17280/60032 (29%)]\tLoss: 0.100362\n",
            "Train Epoch: 3 [19200/60032 (32%)]\tLoss: 0.089903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method ObjectPointer.__del__ of [PointerTensor | me:82616332252 -> bob:86147758533]>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/pointers/object_pointer.py\", line 213, in __del__\n",
            "    self.owner.send_msg(MSGTYPE.FORCE_OBJ_DEL, self.id_at_location, self.location)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/syft/workers/base.py\", line 223, in send_msg\n",
            "    bin_response = self._send_msg(bin_message, location)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/syft/workers/virtual.py\", line 7, in _send_msg\n",
            "    return location._recv_msg(message)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/syft/workers/virtual.py\", line 10, in _recv_msg\n",
            "    return self.recv_msg(message)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/syft/workers/base.py\", line 257, in recv_msg\n",
            "    bin_response = sy.serde.serialize(response)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/syft/serde.py\", line 133, in serialize\n",
            "    binary = msgpack.dumps(simple_objects)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/msgpack/__init__.py\", line 47, in packb\n",
            "    return Packer(**kwargs).pack(o)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 3 [21120/60032 (35%)]\tLoss: 0.002352\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-0325af6d78a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model = Net2().to(device)\\noptimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\\n\\nfor epoch in range(1, args.epochs + 1):\\n    train(args, model, device, federated_train_loader, optimizer, epoch)\\n    test(args, model, device, test_loader)\\n\\nif (args.save_model):\\n    torch.save(model.state_dict(), \"mnist_cnn.pt\")'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-78489ef62a03>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, device, federated_train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfederated_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfederated_train_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# <-- now it is a distributed dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;31m#IF ON DATA LOCATION TO GET THE RIGHT MODEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'bob'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/federated/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/federated/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/federated/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfederated_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# All the data for this worker has been used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/federated/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfederated_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# All the data for this worker has been used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/federated/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \"\"\"\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m         \"\"\"\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0moverloaded_native_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \"\"\"\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b9f350d0-4f1a-4cef-f13e-c992aafa57d5",
        "id": "Q-YKdNQcdBir",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2109
        }
      },
      "source": [
        "%%time\n",
        "model = Net2().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(args, model, device, federated_train_loader, optimizer, epoch)\n",
        "    test(args, model, device, test_loader)\n",
        "\n",
        "if (args.save_model):\n",
        "    torch.save(model.state_dict(), \"mnist_cnn.pt\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60032 (0%)]\tLoss: 2.253029\n",
            "Train Epoch: 1 [1920/60032 (3%)]\tLoss: 1.232375\n",
            "Train Epoch: 1 [3840/60032 (6%)]\tLoss: 0.757512\n",
            "Train Epoch: 1 [5760/60032 (10%)]\tLoss: 0.364047\n",
            "Train Epoch: 1 [7680/60032 (13%)]\tLoss: 0.513790\n",
            "Train Epoch: 1 [9600/60032 (16%)]\tLoss: 0.288561\n",
            "Train Epoch: 1 [11520/60032 (19%)]\tLoss: 0.373806\n",
            "Train Epoch: 1 [13440/60032 (22%)]\tLoss: 0.497560\n",
            "Train Epoch: 1 [15360/60032 (26%)]\tLoss: 0.155243\n",
            "Train Epoch: 1 [17280/60032 (29%)]\tLoss: 0.448969\n",
            "Train Epoch: 1 [19200/60032 (32%)]\tLoss: 0.192030\n",
            "Train Epoch: 1 [21120/60032 (35%)]\tLoss: 0.176506\n",
            "Train Epoch: 1 [23040/60032 (38%)]\tLoss: 0.181207\n",
            "Train Epoch: 1 [24960/60032 (42%)]\tLoss: 0.291539\n",
            "Train Epoch: 1 [26880/60032 (45%)]\tLoss: 0.281255\n",
            "Train Epoch: 1 [28800/60032 (48%)]\tLoss: 0.216463\n",
            "Train Epoch: 1 [30720/60032 (51%)]\tLoss: 0.452938\n",
            "Train Epoch: 1 [32640/60032 (54%)]\tLoss: 0.387530\n",
            "Train Epoch: 1 [34560/60032 (58%)]\tLoss: 0.239093\n",
            "Train Epoch: 1 [36480/60032 (61%)]\tLoss: 0.322200\n",
            "Train Epoch: 1 [38400/60032 (64%)]\tLoss: 0.149250\n",
            "Train Epoch: 1 [40320/60032 (67%)]\tLoss: 0.286039\n",
            "Train Epoch: 1 [42240/60032 (70%)]\tLoss: 0.109953\n",
            "Train Epoch: 1 [44160/60032 (74%)]\tLoss: 0.099975\n",
            "Train Epoch: 1 [46080/60032 (77%)]\tLoss: 0.184736\n",
            "Train Epoch: 1 [48000/60032 (80%)]\tLoss: 0.122621\n",
            "Train Epoch: 1 [49920/60032 (83%)]\tLoss: 0.144660\n",
            "Train Epoch: 1 [51840/60032 (86%)]\tLoss: 0.029555\n",
            "Train Epoch: 1 [53760/60032 (90%)]\tLoss: 0.272693\n",
            "Train Epoch: 1 [55680/60032 (93%)]\tLoss: 0.170877\n",
            "Train Epoch: 1 [57600/60032 (96%)]\tLoss: 0.076190\n",
            "Train Epoch: 1 [59520/60032 (99%)]\tLoss: 0.070564\n",
            "\n",
            "Test set: Average loss: 0.1253, Accuracy: 9604/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60032 (0%)]\tLoss: 0.064309\n",
            "Train Epoch: 2 [1920/60032 (3%)]\tLoss: 0.059504\n",
            "Train Epoch: 2 [3840/60032 (6%)]\tLoss: 0.170232\n",
            "Train Epoch: 2 [5760/60032 (10%)]\tLoss: 0.050915\n",
            "Train Epoch: 2 [7680/60032 (13%)]\tLoss: 0.039312\n",
            "Train Epoch: 2 [9600/60032 (16%)]\tLoss: 0.169014\n",
            "Train Epoch: 2 [11520/60032 (19%)]\tLoss: 0.048337\n",
            "Train Epoch: 2 [13440/60032 (22%)]\tLoss: 0.177421\n",
            "Train Epoch: 2 [15360/60032 (26%)]\tLoss: 0.020883\n",
            "Train Epoch: 2 [17280/60032 (29%)]\tLoss: 0.092050\n",
            "Train Epoch: 2 [19200/60032 (32%)]\tLoss: 0.132664\n",
            "Train Epoch: 2 [21120/60032 (35%)]\tLoss: 0.067174\n",
            "Train Epoch: 2 [23040/60032 (38%)]\tLoss: 0.185464\n",
            "Train Epoch: 2 [24960/60032 (42%)]\tLoss: 0.062636\n",
            "Train Epoch: 2 [26880/60032 (45%)]\tLoss: 0.089147\n",
            "Train Epoch: 2 [28800/60032 (48%)]\tLoss: 0.091625\n",
            "Train Epoch: 2 [30720/60032 (51%)]\tLoss: 0.180251\n",
            "Train Epoch: 2 [32640/60032 (54%)]\tLoss: 0.171684\n",
            "Train Epoch: 2 [34560/60032 (58%)]\tLoss: 0.099416\n",
            "Train Epoch: 2 [36480/60032 (61%)]\tLoss: 0.141496\n",
            "Train Epoch: 2 [38400/60032 (64%)]\tLoss: 0.069605\n",
            "Train Epoch: 2 [40320/60032 (67%)]\tLoss: 0.116553\n",
            "Train Epoch: 2 [42240/60032 (70%)]\tLoss: 0.030538\n",
            "Train Epoch: 2 [44160/60032 (74%)]\tLoss: 0.055049\n",
            "Train Epoch: 2 [46080/60032 (77%)]\tLoss: 0.021086\n",
            "Train Epoch: 2 [48000/60032 (80%)]\tLoss: 0.150247\n",
            "Train Epoch: 2 [49920/60032 (83%)]\tLoss: 0.051076\n",
            "Train Epoch: 2 [51840/60032 (86%)]\tLoss: 0.041261\n",
            "Train Epoch: 2 [53760/60032 (90%)]\tLoss: 0.193274\n",
            "Train Epoch: 2 [55680/60032 (93%)]\tLoss: 0.108142\n",
            "Train Epoch: 2 [57600/60032 (96%)]\tLoss: 0.124839\n",
            "Train Epoch: 2 [59520/60032 (99%)]\tLoss: 0.045661\n",
            "\n",
            "Test set: Average loss: 0.0958, Accuracy: 9697/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60032 (0%)]\tLoss: 0.146108\n",
            "Train Epoch: 3 [1920/60032 (3%)]\tLoss: 0.089724\n",
            "Train Epoch: 3 [3840/60032 (6%)]\tLoss: 0.062068\n",
            "Train Epoch: 3 [5760/60032 (10%)]\tLoss: 0.027066\n",
            "Train Epoch: 3 [7680/60032 (13%)]\tLoss: 0.063330\n",
            "Train Epoch: 3 [9600/60032 (16%)]\tLoss: 0.084789\n",
            "Train Epoch: 3 [11520/60032 (19%)]\tLoss: 0.019617\n",
            "Train Epoch: 3 [13440/60032 (22%)]\tLoss: 0.034115\n",
            "Train Epoch: 3 [15360/60032 (26%)]\tLoss: 0.111855\n",
            "Train Epoch: 3 [17280/60032 (29%)]\tLoss: 0.100362\n",
            "Train Epoch: 3 [19200/60032 (32%)]\tLoss: 0.089903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method ObjectPointer.__del__ of [PointerTensor | me:82616332252 -> bob:86147758533]>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/pointers/object_pointer.py\", line 213, in __del__\n",
            "    self.owner.send_msg(MSGTYPE.FORCE_OBJ_DEL, self.id_at_location, self.location)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/syft/workers/base.py\", line 223, in send_msg\n",
            "    bin_response = self._send_msg(bin_message, location)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/syft/workers/virtual.py\", line 7, in _send_msg\n",
            "    return location._recv_msg(message)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/syft/workers/virtual.py\", line 10, in _recv_msg\n",
            "    return self.recv_msg(message)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/syft/workers/base.py\", line 257, in recv_msg\n",
            "    bin_response = sy.serde.serialize(response)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/syft/serde.py\", line 133, in serialize\n",
            "    binary = msgpack.dumps(simple_objects)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/msgpack/__init__.py\", line 47, in packb\n",
            "    return Packer(**kwargs).pack(o)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 3 [21120/60032 (35%)]\tLoss: 0.002352\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-0325af6d78a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model = Net2().to(device)\\noptimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\\n\\nfor epoch in range(1, args.epochs + 1):\\n    train(args, model, device, federated_train_loader, optimizer, epoch)\\n    test(args, model, device, test_loader)\\n\\nif (args.save_model):\\n    torch.save(model.state_dict(), \"mnist_cnn.pt\")'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-78489ef62a03>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, device, federated_train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfederated_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfederated_train_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# <-- now it is a distributed dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;31m#IF ON DATA LOCATION TO GET THE RIGHT MODEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'bob'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/federated/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/federated/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/federated/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfederated_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# All the data for this worker has been used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/federated/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfederated_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# All the data for this worker has been used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/federated/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \"\"\"\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m         \"\"\"\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0moverloaded_native_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \"\"\"\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpRkPDBkqHbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaL6Ce8TPKmh",
        "colab_type": "text"
      },
      "source": [
        "## TEST3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "88d742ca-f0de-4c13-b4bf-47a2c4594f6a",
        "id": "5UssP19GPkBi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1402
        }
      },
      "source": [
        "! pip install syft"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting syft\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/e0/7466833685e21917a78b3e26503e675c9bc82bd81c0d9a6a90c30adf9938/syft-0.1.20a1-py3-none-any.whl (213kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 13.3MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 4.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 30kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 40kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 51kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 61kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 71kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 81kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 92kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 102kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 112kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 122kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 133kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 143kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 153kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 163kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 174kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 184kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 194kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 204kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 215kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft) (1.0.3)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Collecting tf-encrypted>=0.5.4 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/ce/da9916e7e78f736894b15538b702c0b213fd5d60a7fd6e481d74033a90c0/tf_encrypted-0.5.6-py3-none-manylinux1_x86_64.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 43.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.21.2)\n",
            "Collecting websockets>=7.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/5e/2fe6afbb796c6ac5c006460b5503cd674d33706660337f2dbff10d4aa12d/websockets-8.0-cp36-cp36m-manylinux1_x86_64.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 27.4MB/s \n",
            "\u001b[?25hCollecting lz4>=2.1.6 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 46.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Collecting zstd>=1.4.0.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/27/1ea8086d37424e83ab692015cc8dd7d5e37cf791e339633a40dc828dfb74/zstd-1.4.0.0.tar.gz (450kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 21.4MB/s \n",
            "\u001b[?25hCollecting flask-socketio>=3.3.2 (from syft)\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/68/fe4806d3a0a5909d274367eb9b3b87262906c1515024f46c2443a36a0c82/Flask_SocketIO-4.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Collecting msgpack>=0.6.1 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/7e/ae9e91c1bb8d846efafd1f353476e3fd7309778b582d2fb4cea4cc15b9a2/msgpack-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 43.6MB/s \n",
            "\u001b[?25hCollecting websocket-client>=0.56.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 45.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.16.4)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (2.10.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (7.0)\n",
            "Requirement already satisfied: Werkzeug>=0.14 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (0.15.4)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (1.1.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (1.12.0)\n",
            "Requirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Collecting pyyaml>=5.1 (from tf-encrypted>=0.5.4->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/837fefac7475963d1eccf4aa684c23b95aa6c1d033a2c5965ccb11e22623/PyYAML-5.1.1.tar.gz (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 44.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (0.13.2)\n",
            "Collecting python-socketio>=2.1.0 (from flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/1b/57e860a86f2a01be86ae1dacfa0cd8c4dfbfcd4593322268b61b5a07b564/python_socketio-4.2.0-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 19.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10->Flask>=1.0.2->syft) (1.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->syft) (0.46)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.11.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.1.7)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.7.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.15.0)\n",
            "Collecting python-engineio>=3.8.0 (from python-socketio>=2.1.0->flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/b8/0fc389ca5c445051b37b17802f80bbf1b51c1e3b48b772ee608efbb90583/python_engineio-3.8.2.post1-py2.py3-none-any.whl (119kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 46.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (2.8.0)\n",
            "Building wheels for collected packages: zstd, pyyaml\n",
            "  Building wheel for zstd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/9a/f4/3105b5209674ac77fcca7fede95184c62a95df0196888e0e76\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/27/a1/775c62ddea7bfa62324fd1f65847ed31c55dadb6051481ba3f\n",
            "Successfully built zstd pyyaml\n",
            "Installing collected packages: pyyaml, tf-encrypted, websockets, lz4, zstd, python-engineio, python-socketio, flask-socketio, msgpack, websocket-client, syft\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: msgpack 0.5.6\n",
            "    Uninstalling msgpack-0.5.6:\n",
            "      Successfully uninstalled msgpack-0.5.6\n",
            "Successfully installed flask-socketio-4.1.0 lz4-2.1.10 msgpack-0.6.1 python-engineio-3.8.2.post1 python-socketio-4.2.0 pyyaml-5.1.1 syft-0.1.20a1 tf-encrypted-0.5.6 websocket-client-0.56.0 websockets-8.0 zstd-1.4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E4KT_Zj5PkBo",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "#torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "#torch.set_default_tensor_type(torch.cuda.FloatTensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "675d27a8-9bf4-4163-e88b-32ca1f3f1e0b",
        "id": "uJd-NPn0PkBs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "import syft as sy  # <-- NEW: import the Pysyft library\n",
        "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")  # <-- NEW: define remote worker bob\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")  # <-- NEW: and alice"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0709 13:34:53.276232 140104410445696 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0709 13:34:53.301369 140104410445696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hKXOq4SNFidl"
      },
      "source": [
        "### Split NN config 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CZnhNmfBFidp",
        "colab": {}
      },
      "source": [
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 64\n",
        "        self.test_batch_size = 1000\n",
        "        self.epochs = 10\n",
        "        self.lr = 0.01\n",
        "        self.momentum = 0.5\n",
        "        self.no_cuda = True\n",
        "        self.seed = 1\n",
        "        self.log_interval = 30\n",
        "        self.save_model = False\n",
        "\n",
        "args = Arguments()\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "        # TODO Quickhack. Actually need to fix the problem moving the model to CUDA\\n\",\n",
        "        torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "#device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pZ0u7gH8Fids",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "916cb43c-9ba6-46da-f5f9-70c122efac09"
      },
      "source": [
        "federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n",
        "    .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
        "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=args.test_batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 8832637.00it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 134079.59it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2203467.54it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 49126.33it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T-1N5zd7Fidx",
        "colab": {}
      },
      "source": [
        "class Net1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net1, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        return F.max_pool2d(x, 2, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O3MflnxjFidy",
        "colab": {}
      },
      "source": [
        "class Net2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net2, self).__init__()\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZTdEuHWCFid1",
        "colab": {}
      },
      "source": [
        "models = [Net1(),Net1()]\n",
        "models[0] = models[0].send(bob)\n",
        "models[1] = models[1].send(alice)\n",
        "\n",
        "\n",
        "opt1 = optim.SGD(params=models[0].parameters(),lr=0.1)\n",
        "opt2 = optim.SGD(params=models[1].parameters(),lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRbSxyVhCcH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_grad_flow(named_parameters):\n",
        "    '''Plots the gradients flowing through different layers in the net during training.\n",
        "    Can be used for checking for possible gradient vanishing / exploding problems.\n",
        "    \n",
        "    Usage: Plug this function in Trainer class after loss.backwards() as \n",
        "    \"plot_grad_flow(self.model.named_parameters())\" to visualize the gradient flow'''\n",
        "    ave_grads = []\n",
        "    max_grads= []\n",
        "    layers = []\n",
        "    for n, p in named_parameters:\n",
        "        if(p.requires_grad) and (\"bias\" not in n):\n",
        "            layers.append(n)\n",
        "            ave_grads.append(p.grad.abs().mean())\n",
        "            max_grads.append(p.grad.abs().max())\n",
        "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n",
        "    plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n",
        "    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
        "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
        "    plt.xlim(left=0, right=len(ave_grads))\n",
        "    plt.ylim(bottom = -0.001, top=0.02) # zoom in on the lower gradient regions\n",
        "    plt.xlabel(\"Layers\")\n",
        "    plt.ylabel(\"average gradient\")\n",
        "    plt.title(\"Gradient flow\")\n",
        "    plt.grid(True)\n",
        "    plt.legend([Line2D([0], [0], color=\"c\", lw=4),\n",
        "                Line2D([0], [0], color=\"b\", lw=4),\n",
        "                Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U8iPK7BEFid3",
        "colab": {}
      },
      "source": [
        "def train(args, model, device, federated_train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, targs) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
        "        #IF ON DATA LOCATION TO GET THE RIGHT MODEL\n",
        "        if data.location.id == 'bob':\n",
        "          mod_c,opt_c = models[0], opt1\n",
        "        else : \n",
        "          mod_c,opt_c = models[1], opt2\n",
        "          \n",
        "       # 1) erase previous gradients (if they exist)\n",
        "        optimizer.step()\n",
        "        opt_c.step()\n",
        "        opt_c.zero_grad()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        \n",
        "        #model.send(data.location) # <-- NEW: send the model to the right location\n",
        "        #target= tar.get()\n",
        "        #tg_copy = targs.copy()\n",
        "        #target = tg_copy.get()\n",
        "        \n",
        "        data, target = data.to(device), targs.to(device)\n",
        "        #optimizer.zero_grad()\n",
        "        # 2) make a prediction until cut layer (client location)\n",
        "        pred_c = mod_c(data)\n",
        "        inp = pred_c.copy()\n",
        "        \n",
        "        # 3) get this to the server \n",
        "        inp = inp.get()\n",
        "\n",
        "        # 4) make prediction with second part of the model (server location)\n",
        "        pred = model(inp)\n",
        "        out = pred.copy()\n",
        "        out = out.send(data.location)\n",
        "        # 5) calculate how much we missed \n",
        "        #print(pred.size(),target.size())\n",
        "        loss = F.nll_loss(out, target)\n",
        "        \n",
        "        loss.backward()\n",
        "        grad = out.grad\n",
        "        #print(grad)\n",
        "        loss = loss.get()\n",
        "        #grad = grad.clone().get()\n",
        "        #opt_c.zero_grad()\n",
        "        grad1 = grad.copy()\n",
        "        grad1 = grad1.get()\n",
        "        #print(grad2)\n",
        "        pred.backward(grad1)\n",
        "        \n",
        "        \"\"\"\n",
        "        gradient = inp.grad\n",
        "        #print('inp',inp.shape)\n",
        "        #print('gradient',gradient.shape)\n",
        "        gradient = gradient.view(inp.shape)\n",
        "        G = gradient.send(data.location)\n",
        "        #print(\"pred_c\",pred_c.shape)\n",
        "        #print('gradient',gradient.shape)\n",
        "        pred_c.backward(G)\"\"\"\n",
        "        \n",
        "        gradient = inp.grad\n",
        "        #gradient = gradient.view(inp.shape)\n",
        "        gradient = gradient.send(data.location)\n",
        "        print(gradient.size())\n",
        "        print(pred_c.size())\n",
        "        #print(gradient.clone().get())\n",
        "        #print(pred_c.clone().get())\n",
        "        pred_c.backward(gradient)\n",
        "        \n",
        "       #target = target.send(data.location)\n",
        "        #optimizer.step()\n",
        "        #model.get() # <-- NEW: get the model back\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            #loss = loss.get() # <-- NEW: get the loss back\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,\n",
        "                100. * batch_idx / len(federated_train_loader), loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZxDkrCqPFid5",
        "colab": {}
      },
      "source": [
        "def test(args, model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    M1 = models[0].copy()\n",
        "    M2 = models[1].copy()\n",
        "    M1 = M1.get()\n",
        "    M2 = M2.get()\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(M1(data))\n",
        "            #output2 = model(M2(data))\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "74cbe8d3-93af-4e19-d886-cc9cc841b68a",
        "id": "L4V0rfOTFid6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2247
        }
      },
      "source": [
        "%%time\n",
        "model = Net2().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(args, model, device, federated_train_loader, optimizer, epoch)\n",
        "    test(args, model, device, test_loader)\n",
        "\n",
        "if (args.save_model):\n",
        "    torch.save(model.state_dict(), \"mnist_cnn.pt\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([0])\n",
            "torch.Size([0])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-0325af6d78a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model = Net2().to(device)\\noptimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\\n\\nfor epoch in range(1, args.epochs + 1):\\n    train(args, model, device, federated_train_loader, optimizer, epoch)\\n    test(args, model, device, test_loader)\\n\\nif (args.save_model):\\n    torch.save(model.state_dict(), \"mnist_cnn.pt\")'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-ac2759030543>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, device, federated_train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m#print(gradient.clone().get())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m#print(pred_c.clone().get())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mpred_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m        \u001b[0;31m#target = target.send(data.location)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m                 \u001b[0;31m# Send the new command to the appropriate class and get the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m                 \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m                 \u001b[0;31m# For inplace methods, just directly return self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_pointer_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/workers/base.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, recipient, message, return_ids)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSGTYPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCMD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecipient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mResponseSignatureError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/workers/base.py\u001b[0m in \u001b[0;36msend_msg\u001b[0;34m(self, msg_type, message, location)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Step 2: send the message and wait for a response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mbin_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Step 3: deserialize the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/workers/virtual.py\u001b[0m in \u001b[0;36m_send_msg\u001b[0;34m(self, message, location)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mVirtualWorker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseWorker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFederatedClient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBaseWorker\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/workers/virtual.py\u001b[0m in \u001b[0;36m_recv_msg\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/workers/base.py\u001b[0m in \u001b[0;36mrecv_msg\u001b[0;34m(self, bin_message)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"worker {self} received {sy.codes.code2MSGTYPE[msg_type]} {contents}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# Step 1: route message to appropriate function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message_router\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmsg_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m# Step 2: Serialize the message to simple python objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/workers/base.py\u001b[0m in \u001b[0;36mexecute_command\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                     \u001b[0;31m# TODO Andrew thinks this is gross, please fix. Instead need to properly deserialize strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                     \u001b[0;31m# we can make some errors more descriptive with this method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mroute_method_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# means that there is a wrapper to remove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    652\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m                         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m                         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: invalid gradient at index 0 - got [0] but expected shape compatible with [64, 20, 12, 12]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6U0ejL9Frii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtIUdMxh07km",
        "colab_type": "text"
      },
      "source": [
        "## EXPERIMENT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzYbYBNQ09RD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 13925
        },
        "outputId": "ab070385-15bb-4960-efc1-2d3d8445472f"
      },
      "source": [
        "# Installation + Imports \n",
        "! git clone https://github.com/OpenMined/PySyft.git \n",
        "% cd PySyft\n",
        "#! git checkout @{30.days.ago} # 30 days when 26th June\n",
        "#! git checkout d126b3110a3970bef8932ffaf8987ba77d32deb1 .\n",
        "! git checkout 7b6f9fb\n",
        "! pip install -r requirements.txt\n",
        "% cd .. \n",
        "! mv native.py PySyft/syft/frameworks/torch/tensors/interpreters/ \n",
        "% cd PySyft\n",
        "! python3 setup.py install \n",
        "! git clone https://github.com/tf-encrypted/tf-encrypted\n",
        "% cd tf-encrypted  \n",
        "! pip3 install -e .\n",
        "import tf_encrypted as tfe\n",
        "% cd .. \n",
        "\n",
        "\n",
        "import syft as sy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PySyft'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 28321 (delta 0), reused 0 (delta 0), pack-reused 28317\u001b[K\n",
            "Receiving objects: 100% (28321/28321), 31.91 MiB | 18.90 MiB/s, done.\n",
            "Resolving deltas: 100% (18686/18686), done.\n",
            "/content/PySyft\n",
            "Note: checking out '7b6f9fb'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at 7b6f9fb2 Merge pull request #2303 from amit-rastogi/dev\n",
            "Requirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.0.3)\n",
            "Collecting flask_socketio>=3.3.2 (from -r requirements.txt (line 2))\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/68/fe4806d3a0a5909d274367eb9b3b87262906c1515024f46c2443a36a0c82/Flask_SocketIO-4.1.0-py2.py3-none-any.whl\n",
            "Collecting lz4>=2.1.6 (from -r requirements.txt (line 3))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 13.1MB/s \n",
            "\u001b[?25hCollecting msgpack>=0.6.1 (from -r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/7e/ae9e91c1bb8d846efafd1f353476e3fd7309778b582d2fb4cea4cc15b9a2/msgpack-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 54.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (1.16.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.21.2)\n",
            "Requirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (1.4.0)\n",
            "Collecting tf_encrypted>=0.5.4 (from -r requirements.txt (line 8))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/ce/da9916e7e78f736894b15538b702c0b213fd5d60a7fd6e481d74033a90c0/tf_encrypted-0.5.6-py3-none-manylinux1_x86_64.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 52.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (1.1.0)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (0.3.0)\n",
            "Collecting websocket_client>=0.56.0 (from -r requirements.txt (line 11))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 54.0MB/s \n",
            "\u001b[?25hCollecting websockets>=7.0 (from -r requirements.txt (line 12))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/71/8bfa882b9c502c36e5c9ef6732969533670d2b039cbf95a82ced8f762b80/websockets-7.0-cp36-cp36m-manylinux1_x86_64.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 30.1MB/s \n",
            "\u001b[?25hCollecting zstd>=1.4.0.0 (from -r requirements.txt (line 13))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/27/1ea8086d37424e83ab692015cc8dd7d5e37cf791e339633a40dc828dfb74/zstd-1.4.0.0.tar.gz (450kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 41.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: Werkzeug>=0.14 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->-r requirements.txt (line 1)) (0.15.4)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->-r requirements.txt (line 1)) (2.10.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->-r requirements.txt (line 1)) (7.0)\n",
            "Collecting python-socketio>=2.1.0 (from flask_socketio>=3.3.2->-r requirements.txt (line 2))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/1b/57e860a86f2a01be86ae1dacfa0cd8c4dfbfcd4593322268b61b5a07b564/python_socketio-4.2.0-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 1.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->-r requirements.txt (line 6)) (0.13.2)\n",
            "Collecting pyyaml>=5.1 (from tf_encrypted>=0.5.4->-r requirements.txt (line 8))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/837fefac7475963d1eccf4aa684c23b95aa6c1d033a2c5965ccb11e22623/PyYAML-5.1.1.tar.gz (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 51.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.14.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->-r requirements.txt (line 10)) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->-r requirements.txt (line 10)) (4.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10->Flask>=1.0.2->-r requirements.txt (line 1)) (1.1.1)\n",
            "Collecting python-engineio>=3.8.0 (from python-socketio>=2.1.0->flask_socketio>=3.3.2->-r requirements.txt (line 2))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/1c/601f8ad22681ec9b86acafabc145b6bd02ca62aeac6aae4045d262a94a56/python_engineio-3.8.2-py2.py3-none-any.whl (119kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 27.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.14.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (0.1.7)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (0.7.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (0.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (0.33.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.0.8)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.14.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (3.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.11.2)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->-r requirements.txt (line 10)) (0.46)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (41.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (2.8.0)\n",
            "Building wheels for collected packages: zstd, pyyaml\n",
            "  Building wheel for zstd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/9a/f4/3105b5209674ac77fcca7fede95184c62a95df0196888e0e76\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/27/a1/775c62ddea7bfa62324fd1f65847ed31c55dadb6051481ba3f\n",
            "Successfully built zstd pyyaml\n",
            "Installing collected packages: python-engineio, python-socketio, flask-socketio, lz4, msgpack, pyyaml, tf-encrypted, websocket-client, websockets, zstd\n",
            "  Found existing installation: msgpack 0.5.6\n",
            "    Uninstalling msgpack-0.5.6:\n",
            "      Successfully uninstalled msgpack-0.5.6\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed flask-socketio-4.1.0 lz4-2.1.10 msgpack-0.6.1 python-engineio-3.8.2 python-socketio-4.2.0 pyyaml-5.1.1 tf-encrypted-0.5.6 websocket-client-0.56.0 websockets-7.0 zstd-1.4.0.0\n",
            "/content\n",
            "/content/PySyft\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating syft.egg-info\n",
            "writing syft.egg-info/PKG-INFO\n",
            "writing dependency_links to syft.egg-info/dependency_links.txt\n",
            "writing requirements to syft.egg-info/requires.txt\n",
            "writing top-level names to syft.egg-info/top_level.txt\n",
            "writing manifest file 'syft.egg-info/SOURCES.txt'\n",
            "writing manifest file 'syft.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/syft\n",
            "copying syft/grid.py -> build/lib/syft\n",
            "copying syft/codes.py -> build/lib/syft\n",
            "copying syft/__init__.py -> build/lib/syft\n",
            "copying syft/exceptions.py -> build/lib/syft\n",
            "creating build/lib/test\n",
            "copying test/test_grid.py -> build/lib/test\n",
            "copying test/test_local_worker.py -> build/lib/test\n",
            "copying test/test_serde.py -> build/lib/test\n",
            "copying test/test_udacity.py -> build/lib/test\n",
            "copying test/__init__.py -> build/lib/test\n",
            "copying test/conftest.py -> build/lib/test\n",
            "copying test/test_exceptions.py -> build/lib/test\n",
            "copying test/test_sandbox.py -> build/lib/test\n",
            "creating build/lib/syft/workers\n",
            "copying syft/workers/base.py -> build/lib/syft/workers\n",
            "copying syft/workers/__init__.py -> build/lib/syft/workers\n",
            "copying syft/workers/abstract.py -> build/lib/syft/workers\n",
            "copying syft/workers/websocket_client.py -> build/lib/syft/workers\n",
            "copying syft/workers/websocket_server.py -> build/lib/syft/workers\n",
            "copying syft/workers/virtual.py -> build/lib/syft/workers\n",
            "copying syft/workers/tfe.py -> build/lib/syft/workers\n",
            "creating build/lib/syft/generic\n",
            "copying syft/generic/__init__.py -> build/lib/syft/generic\n",
            "copying syft/generic/id_provider.py -> build/lib/syft/generic\n",
            "copying syft/generic/object_storage.py -> build/lib/syft/generic\n",
            "creating build/lib/syft/frameworks\n",
            "copying syft/frameworks/__init__.py -> build/lib/syft/frameworks\n",
            "creating build/lib/syft/serde\n",
            "copying syft/serde/serde.py -> build/lib/syft/serde\n",
            "copying syft/serde/torch_serde.py -> build/lib/syft/serde\n",
            "copying syft/serde/__init__.py -> build/lib/syft/serde\n",
            "copying syft/serde/native_serde.py -> build/lib/syft/serde\n",
            "creating build/lib/syft/federated\n",
            "copying syft/federated/__init__.py -> build/lib/syft/federated\n",
            "copying syft/federated/train_config.py -> build/lib/syft/federated\n",
            "copying syft/federated/plan.py -> build/lib/syft/federated\n",
            "copying syft/federated/federated_client.py -> build/lib/syft/federated\n",
            "creating build/lib/syft/frameworks/keras\n",
            "copying syft/frameworks/keras/__init__.py -> build/lib/syft/frameworks/keras\n",
            "copying syft/frameworks/keras/hook.py -> build/lib/syft/frameworks/keras\n",
            "creating build/lib/syft/frameworks/torch\n",
            "copying syft/frameworks/torch/overload_torch.py -> build/lib/syft/frameworks/torch\n",
            "copying syft/frameworks/torch/torch_attributes.py -> build/lib/syft/frameworks/torch\n",
            "copying syft/frameworks/torch/functions.py -> build/lib/syft/frameworks/torch\n",
            "copying syft/frameworks/torch/__init__.py -> build/lib/syft/frameworks/torch\n",
            "creating build/lib/syft/frameworks/keras/model\n",
            "copying syft/frameworks/keras/model/sequential.py -> build/lib/syft/frameworks/keras/model\n",
            "copying syft/frameworks/keras/model/__init__.py -> build/lib/syft/frameworks/keras/model\n",
            "creating build/lib/syft/frameworks/keras/layers\n",
            "copying syft/frameworks/keras/layers/constructor.py -> build/lib/syft/frameworks/keras/layers\n",
            "copying syft/frameworks/keras/layers/__init__.py -> build/lib/syft/frameworks/keras/layers\n",
            "creating build/lib/syft/frameworks/torch/crypto\n",
            "copying syft/frameworks/torch/crypto/__init__.py -> build/lib/syft/frameworks/torch/crypto\n",
            "copying syft/frameworks/torch/crypto/spdz.py -> build/lib/syft/frameworks/torch/crypto\n",
            "copying syft/frameworks/torch/crypto/securenn.py -> build/lib/syft/frameworks/torch/crypto\n",
            "creating build/lib/syft/frameworks/torch/pointers\n",
            "copying syft/frameworks/torch/pointers/object_wrapper.py -> build/lib/syft/frameworks/torch/pointers\n",
            "copying syft/frameworks/torch/pointers/pointer_tensor.py -> build/lib/syft/frameworks/torch/pointers\n",
            "copying syft/frameworks/torch/pointers/__init__.py -> build/lib/syft/frameworks/torch/pointers\n",
            "copying syft/frameworks/torch/pointers/object_pointer.py -> build/lib/syft/frameworks/torch/pointers\n",
            "copying syft/frameworks/torch/pointers/callable_pointer.py -> build/lib/syft/frameworks/torch/pointers\n",
            "creating build/lib/syft/frameworks/torch/hook\n",
            "copying syft/frameworks/torch/hook/__init__.py -> build/lib/syft/frameworks/torch/hook\n",
            "copying syft/frameworks/torch/hook/hook.py -> build/lib/syft/frameworks/torch/hook\n",
            "copying syft/frameworks/torch/hook/hook_args.py -> build/lib/syft/frameworks/torch/hook\n",
            "creating build/lib/syft/frameworks/torch/tensors\n",
            "copying syft/frameworks/torch/tensors/__init__.py -> build/lib/syft/frameworks/torch/tensors\n",
            "creating build/lib/syft/frameworks/torch/federated\n",
            "copying syft/frameworks/torch/federated/__init__.py -> build/lib/syft/frameworks/torch/federated\n",
            "copying syft/frameworks/torch/federated/utils.py -> build/lib/syft/frameworks/torch/federated\n",
            "copying syft/frameworks/torch/federated/dataloader.py -> build/lib/syft/frameworks/torch/federated\n",
            "copying syft/frameworks/torch/federated/dataset.py -> build/lib/syft/frameworks/torch/federated\n",
            "creating build/lib/syft/frameworks/torch/differential_privacy\n",
            "copying syft/frameworks/torch/differential_privacy/__init__.py -> build/lib/syft/frameworks/torch/differential_privacy\n",
            "copying syft/frameworks/torch/differential_privacy/pate.py -> build/lib/syft/frameworks/torch/differential_privacy\n",
            "creating build/lib/syft/frameworks/torch/tensors/decorators\n",
            "copying syft/frameworks/torch/tensors/decorators/__init__.py -> build/lib/syft/frameworks/torch/tensors/decorators\n",
            "copying syft/frameworks/torch/tensors/decorators/logging.py -> build/lib/syft/frameworks/torch/tensors/decorators\n",
            "creating build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/gradients.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/native.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/additive_shared.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/__init__.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/polynomial.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/multi_pointer.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/abstract.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/gradients_core.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/build_gradients.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/autograd.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/plusisminus.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/precision.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "creating build/lib/test/workers\n",
            "copying test/workers/__init__.py -> build/lib/test/workers\n",
            "copying test/workers/test_websocket_worker.py -> build/lib/test/workers\n",
            "copying test/workers/test_base.py -> build/lib/test/workers\n",
            "copying test/workers/test_worker.py -> build/lib/test/workers\n",
            "copying test/workers/test_virtual.py -> build/lib/test/workers\n",
            "creating build/lib/test/torch\n",
            "copying test/torch/__init__.py -> build/lib/test/torch\n",
            "copying test/torch/test_functions.py -> build/lib/test/torch\n",
            "copying test/torch/test_hook.py -> build/lib/test/torch\n",
            "copying test/torch/test_federated_learning.py -> build/lib/test/torch\n",
            "creating build/lib/test/generic\n",
            "copying test/generic/__init__.py -> build/lib/test/generic\n",
            "copying test/generic/test_id_provider.py -> build/lib/test/generic\n",
            "creating build/lib/test/federated\n",
            "copying test/federated/test_train_config.py -> build/lib/test/federated\n",
            "copying test/federated/test_federated_client.py -> build/lib/test/federated\n",
            "copying test/federated/__init__.py -> build/lib/test/federated\n",
            "copying test/federated/test_plan.py -> build/lib/test/federated\n",
            "creating build/lib/test/torch/crypto\n",
            "copying test/torch/crypto/__init__.py -> build/lib/test/torch/crypto\n",
            "copying test/torch/crypto/test_snn.py -> build/lib/test/torch/crypto\n",
            "creating build/lib/test/torch/pointers\n",
            "copying test/torch/pointers/test_callable_pointer.py -> build/lib/test/torch/pointers\n",
            "copying test/torch/pointers/test_pointer_tensor.py -> build/lib/test/torch/pointers\n",
            "copying test/torch/pointers/__init__.py -> build/lib/test/torch/pointers\n",
            "creating build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_logging.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_gc.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_multi_pointer.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/__init__.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_autograd.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_parameter.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_additive_shared.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_polynomial.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_native.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_precision.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_tensor.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_variable.py -> build/lib/test/torch/tensors\n",
            "creating build/lib/test/torch/federated\n",
            "copying test/torch/federated/__init__.py -> build/lib/test/torch/federated\n",
            "copying test/torch/federated/test_dataset.py -> build/lib/test/torch/federated\n",
            "copying test/torch/federated/test_dataloader.py -> build/lib/test/torch/federated\n",
            "copying test/torch/federated/test_utils.py -> build/lib/test/torch/federated\n",
            "creating build/lib/test/torch/differential_privacy\n",
            "copying test/torch/differential_privacy/__init__.py -> build/lib/test/torch/differential_privacy\n",
            "copying test/torch/differential_privacy/test_pate.py -> build/lib/test/torch/differential_privacy\n",
            "creating build/lib/test/keras\n",
            "copying test/keras/test_sequential.py -> build/lib/test/keras\n",
            "copying syft/frameworks/keras/README.md -> build/lib/syft/frameworks/keras\n",
            "copying syft/frameworks/torch/tensors/interpreters/derivatives.yaml -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/syft\n",
            "copying build/lib/syft/grid.py -> build/bdist.linux-x86_64/egg/syft\n",
            "copying build/lib/syft/codes.py -> build/bdist.linux-x86_64/egg/syft\n",
            "creating build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/base.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/__init__.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/abstract.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/websocket_client.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/websocket_server.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/virtual.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/tfe.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/__init__.py -> build/bdist.linux-x86_64/egg/syft\n",
            "copying build/lib/syft/exceptions.py -> build/bdist.linux-x86_64/egg/syft\n",
            "creating build/bdist.linux-x86_64/egg/syft/generic\n",
            "copying build/lib/syft/generic/__init__.py -> build/bdist.linux-x86_64/egg/syft/generic\n",
            "copying build/lib/syft/generic/id_provider.py -> build/bdist.linux-x86_64/egg/syft/generic\n",
            "copying build/lib/syft/generic/object_storage.py -> build/bdist.linux-x86_64/egg/syft/generic\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/keras\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/keras/model\n",
            "copying build/lib/syft/frameworks/keras/model/sequential.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras/model\n",
            "copying build/lib/syft/frameworks/keras/model/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras/model\n",
            "copying build/lib/syft/frameworks/keras/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras\n",
            "copying build/lib/syft/frameworks/keras/hook.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras\n",
            "copying build/lib/syft/frameworks/keras/README.md -> build/bdist.linux-x86_64/egg/syft/frameworks/keras\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/keras/layers\n",
            "copying build/lib/syft/frameworks/keras/layers/constructor.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras/layers\n",
            "copying build/lib/syft/frameworks/keras/layers/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras/layers\n",
            "copying build/lib/syft/frameworks/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch\n",
            "copying build/lib/syft/frameworks/torch/overload_torch.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch\n",
            "copying build/lib/syft/frameworks/torch/torch_attributes.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch\n",
            "copying build/lib/syft/frameworks/torch/functions.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch\n",
            "copying build/lib/syft/frameworks/torch/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto\n",
            "copying build/lib/syft/frameworks/torch/crypto/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto\n",
            "copying build/lib/syft/frameworks/torch/crypto/spdz.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto\n",
            "copying build/lib/syft/frameworks/torch/crypto/securenn.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/pointers/object_wrapper.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/pointers/pointer_tensor.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/pointers/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/pointers/object_pointer.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/pointers/callable_pointer.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook\n",
            "copying build/lib/syft/frameworks/torch/hook/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook\n",
            "copying build/lib/syft/frameworks/torch/hook/hook.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook\n",
            "copying build/lib/syft/frameworks/torch/hook/hook_args.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/decorators\n",
            "copying build/lib/syft/frameworks/torch/tensors/decorators/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/decorators\n",
            "copying build/lib/syft/frameworks/torch/tensors/decorators/logging.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/decorators\n",
            "copying build/lib/syft/frameworks/torch/tensors/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/gradients.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/native.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/additive_shared.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/polynomial.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/multi_pointer.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/abstract.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/gradients_core.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/derivatives.yaml -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/build_gradients.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/autograd.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/plusisminus.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/precision.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated\n",
            "copying build/lib/syft/frameworks/torch/federated/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated\n",
            "copying build/lib/syft/frameworks/torch/federated/utils.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated\n",
            "copying build/lib/syft/frameworks/torch/federated/dataloader.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated\n",
            "copying build/lib/syft/frameworks/torch/federated/dataset.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/differential_privacy\n",
            "copying build/lib/syft/frameworks/torch/differential_privacy/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/differential_privacy\n",
            "copying build/lib/syft/frameworks/torch/differential_privacy/pate.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/differential_privacy\n",
            "creating build/bdist.linux-x86_64/egg/syft/serde\n",
            "copying build/lib/syft/serde/serde.py -> build/bdist.linux-x86_64/egg/syft/serde\n",
            "copying build/lib/syft/serde/torch_serde.py -> build/bdist.linux-x86_64/egg/syft/serde\n",
            "copying build/lib/syft/serde/__init__.py -> build/bdist.linux-x86_64/egg/syft/serde\n",
            "copying build/lib/syft/serde/native_serde.py -> build/bdist.linux-x86_64/egg/syft/serde\n",
            "creating build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/federated/__init__.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/federated/train_config.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/federated/plan.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/federated/federated_client.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "creating build/bdist.linux-x86_64/egg/test\n",
            "creating build/bdist.linux-x86_64/egg/test/keras\n",
            "copying build/lib/test/keras/test_sequential.py -> build/bdist.linux-x86_64/egg/test/keras\n",
            "copying build/lib/test/test_grid.py -> build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/test_local_worker.py -> build/bdist.linux-x86_64/egg/test\n",
            "creating build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/workers/__init__.py -> build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/workers/test_websocket_worker.py -> build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/workers/test_base.py -> build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/workers/test_worker.py -> build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/workers/test_virtual.py -> build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/test_serde.py -> build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/test_udacity.py -> build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/__init__.py -> build/bdist.linux-x86_64/egg/test\n",
            "creating build/bdist.linux-x86_64/egg/test/torch\n",
            "copying build/lib/test/torch/__init__.py -> build/bdist.linux-x86_64/egg/test/torch\n",
            "creating build/bdist.linux-x86_64/egg/test/torch/crypto\n",
            "copying build/lib/test/torch/crypto/__init__.py -> build/bdist.linux-x86_64/egg/test/torch/crypto\n",
            "copying build/lib/test/torch/crypto/test_snn.py -> build/bdist.linux-x86_64/egg/test/torch/crypto\n",
            "creating build/bdist.linux-x86_64/egg/test/torch/pointers\n",
            "copying build/lib/test/torch/pointers/test_callable_pointer.py -> build/bdist.linux-x86_64/egg/test/torch/pointers\n",
            "copying build/lib/test/torch/pointers/test_pointer_tensor.py -> build/bdist.linux-x86_64/egg/test/torch/pointers\n",
            "copying build/lib/test/torch/pointers/__init__.py -> build/bdist.linux-x86_64/egg/test/torch/pointers\n",
            "copying build/lib/test/torch/test_functions.py -> build/bdist.linux-x86_64/egg/test/torch\n",
            "copying build/lib/test/torch/test_hook.py -> build/bdist.linux-x86_64/egg/test/torch\n",
            "creating build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_logging.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_gc.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_multi_pointer.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/__init__.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_autograd.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_parameter.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_additive_shared.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_polynomial.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_native.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_precision.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_tensor.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_variable.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/test_federated_learning.py -> build/bdist.linux-x86_64/egg/test/torch\n",
            "creating build/bdist.linux-x86_64/egg/test/torch/federated\n",
            "copying build/lib/test/torch/federated/__init__.py -> build/bdist.linux-x86_64/egg/test/torch/federated\n",
            "copying build/lib/test/torch/federated/test_dataset.py -> build/bdist.linux-x86_64/egg/test/torch/federated\n",
            "copying build/lib/test/torch/federated/test_dataloader.py -> build/bdist.linux-x86_64/egg/test/torch/federated\n",
            "copying build/lib/test/torch/federated/test_utils.py -> build/bdist.linux-x86_64/egg/test/torch/federated\n",
            "creating build/bdist.linux-x86_64/egg/test/torch/differential_privacy\n",
            "copying build/lib/test/torch/differential_privacy/__init__.py -> build/bdist.linux-x86_64/egg/test/torch/differential_privacy\n",
            "copying build/lib/test/torch/differential_privacy/test_pate.py -> build/bdist.linux-x86_64/egg/test/torch/differential_privacy\n",
            "copying build/lib/test/conftest.py -> build/bdist.linux-x86_64/egg/test\n",
            "creating build/bdist.linux-x86_64/egg/test/generic\n",
            "copying build/lib/test/generic/__init__.py -> build/bdist.linux-x86_64/egg/test/generic\n",
            "copying build/lib/test/generic/test_id_provider.py -> build/bdist.linux-x86_64/egg/test/generic\n",
            "copying build/lib/test/test_exceptions.py -> build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/test_sandbox.py -> build/bdist.linux-x86_64/egg/test\n",
            "creating build/bdist.linux-x86_64/egg/test/federated\n",
            "copying build/lib/test/federated/test_train_config.py -> build/bdist.linux-x86_64/egg/test/federated\n",
            "copying build/lib/test/federated/test_federated_client.py -> build/bdist.linux-x86_64/egg/test/federated\n",
            "copying build/lib/test/federated/__init__.py -> build/bdist.linux-x86_64/egg/test/federated\n",
            "copying build/lib/test/federated/test_plan.py -> build/bdist.linux-x86_64/egg/test/federated\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid.py to grid.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/codes.py to codes.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/base.py to base.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/abstract.py to abstract.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/websocket_client.py to websocket_client.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/websocket_server.py to websocket_server.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/virtual.py to virtual.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/tfe.py to tfe.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/exceptions.py to exceptions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/generic/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/generic/id_provider.py to id_provider.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/generic/object_storage.py to object_storage.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/model/sequential.py to sequential.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/model/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/hook.py to hook.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/layers/constructor.py to constructor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/layers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/overload_torch.py to overload_torch.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/torch_attributes.py to torch_attributes.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/functions.py to functions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto/spdz.py to spdz.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto/securenn.py to securenn.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers/object_wrapper.py to object_wrapper.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers/pointer_tensor.py to pointer_tensor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers/object_pointer.py to object_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers/callable_pointer.py to callable_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook/hook.py to hook.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook/hook_args.py to hook_args.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/decorators/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/decorators/logging.py to logging.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/gradients.py to gradients.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/native.py to native.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/additive_shared.py to additive_shared.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/polynomial.py to polynomial.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/multi_pointer.py to multi_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/abstract.py to abstract.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/gradients_core.py to gradients_core.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/build_gradients.py to build_gradients.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/autograd.py to autograd.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/plusisminus.py to plusisminus.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/precision.py to precision.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated/utils.py to utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated/dataloader.py to dataloader.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated/dataset.py to dataset.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/differential_privacy/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/differential_privacy/pate.py to pate.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/serde/serde.py to serde.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/serde/torch_serde.py to torch_serde.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/serde/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/serde/native_serde.py to native_serde.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/train_config.py to train_config.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/plan.py to plan.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/federated_client.py to federated_client.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/keras/test_sequential.py to test_sequential.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_grid.py to test_grid.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_local_worker.py to test_local_worker.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/workers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/workers/test_websocket_worker.py to test_websocket_worker.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/workers/test_base.py to test_base.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/workers/test_worker.py to test_worker.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/workers/test_virtual.py to test_virtual.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_serde.py to test_serde.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_udacity.py to test_udacity.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/crypto/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/crypto/test_snn.py to test_snn.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/pointers/test_callable_pointer.py to test_callable_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/pointers/test_pointer_tensor.py to test_pointer_tensor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/pointers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/test_functions.py to test_functions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/test_hook.py to test_hook.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_logging.py to test_logging.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_gc.py to test_gc.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_multi_pointer.py to test_multi_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_autograd.py to test_autograd.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_parameter.py to test_parameter.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_additive_shared.py to test_additive_shared.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_polynomial.py to test_polynomial.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_native.py to test_native.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_precision.py to test_precision.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_tensor.py to test_tensor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_variable.py to test_variable.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/test_federated_learning.py to test_federated_learning.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/federated/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/federated/test_dataset.py to test_dataset.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/federated/test_dataloader.py to test_dataloader.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/federated/test_utils.py to test_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/differential_privacy/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/differential_privacy/test_pate.py to test_pate.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/conftest.py to conftest.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/generic/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/generic/test_id_provider.py to test_id_provider.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_exceptions.py to test_exceptions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_sandbox.py to test_sandbox.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/federated/test_train_config.py to test_train_config.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/federated/test_federated_client.py to test_federated_client.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/federated/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/federated/test_plan.py to test_plan.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syft.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syft.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syft.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syft.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syft.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/syft-0.1.19a1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing syft-0.1.19a1-py3.6.egg\n",
            "Copying syft-0.1.19a1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding syft 0.1.19a1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/syft-0.1.19a1-py3.6.egg\n",
            "Processing dependencies for syft==0.1.19a1\n",
            "Searching for zstd==1.4.0.0\n",
            "Best match: zstd 1.4.0.0\n",
            "Adding zstd 1.4.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for websockets==7.0\n",
            "Best match: websockets 7.0\n",
            "Adding websockets 7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for websocket-client==0.56.0\n",
            "Best match: websocket-client 0.56.0\n",
            "Adding websocket-client 0.56.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for torchvision==0.3.0\n",
            "Best match: torchvision 0.3.0\n",
            "Adding torchvision 0.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for torch==1.1.0\n",
            "Best match: torch 1.1.0\n",
            "Adding torch 1.1.0 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tf-encrypted==0.5.6\n",
            "Best match: tf-encrypted 0.5.6\n",
            "Adding tf-encrypted 0.5.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tblib==1.4.0\n",
            "Best match: tblib 1.4.0\n",
            "Adding tblib 1.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scikit-learn==0.21.2\n",
            "Best match: scikit-learn 0.21.2\n",
            "Adding scikit-learn 0.21.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.16.4\n",
            "Best match: numpy 1.16.4\n",
            "Adding numpy 1.16.4 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for msgpack==0.6.1\n",
            "Best match: msgpack 0.6.1\n",
            "Adding msgpack 0.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for lz4==2.1.10\n",
            "Best match: lz4 2.1.10\n",
            "Adding lz4 2.1.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Flask-SocketIO==4.1.0\n",
            "Best match: Flask-SocketIO 4.1.0\n",
            "Adding Flask-SocketIO 4.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Flask==1.0.3\n",
            "Best match: Flask 1.0.3\n",
            "Adding Flask 1.0.3 to easy-install.pth file\n",
            "Installing flask script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.12.0\n",
            "Best match: six 1.12.0\n",
            "Adding six 1.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Pillow==4.3.0\n",
            "Best match: Pillow 4.3.0\n",
            "Adding Pillow 4.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorflow==1.14.0\n",
            "Best match: tensorflow 1.14.0\n",
            "Adding tensorflow 1.14.0 to easy-install.pth file\n",
            "Installing freeze_graph script to /usr/local/bin\n",
            "Installing saved_model_cli script to /usr/local/bin\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "Installing tf_upgrade_v2 script to /usr/local/bin\n",
            "Installing tflite_convert script to /usr/local/bin\n",
            "Installing toco script to /usr/local/bin\n",
            "Installing toco_from_protos script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for PyYAML==5.1.1\n",
            "Best match: PyYAML 5.1.1\n",
            "Adding PyYAML 5.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for joblib==0.13.2\n",
            "Best match: joblib 0.13.2\n",
            "Adding joblib 0.13.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scipy==1.3.0\n",
            "Best match: scipy 1.3.0\n",
            "Adding scipy 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for python-socketio==4.2.0\n",
            "Best match: python-socketio 4.2.0\n",
            "Adding python-socketio 4.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for itsdangerous==1.1.0\n",
            "Best match: itsdangerous 1.1.0\n",
            "Adding itsdangerous 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Click==7.0\n",
            "Best match: Click 7.0\n",
            "Adding Click 7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Werkzeug==0.15.4\n",
            "Best match: Werkzeug 0.15.4\n",
            "Adding Werkzeug 0.15.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Jinja2==2.10.1\n",
            "Best match: Jinja2 2.10.1\n",
            "Adding Jinja2 2.10.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for olefile==0.46\n",
            "Best match: olefile 0.46\n",
            "Adding olefile 0.46 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorboard==1.14.0\n",
            "Best match: tensorboard 1.14.0\n",
            "Adding tensorboard 1.14.0 to easy-install.pth file\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorflow-estimator==1.14.0\n",
            "Best match: tensorflow-estimator 1.14.0\n",
            "Adding tensorflow-estimator 1.14.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for protobuf==3.7.1\n",
            "Best match: protobuf 3.7.1\n",
            "Adding protobuf 3.7.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Keras-Applications==1.0.8\n",
            "Best match: Keras-Applications 1.0.8\n",
            "Adding Keras-Applications 1.0.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for astor==0.8.0\n",
            "Best match: astor 0.8.0\n",
            "Adding astor 0.8.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for wheel==0.33.4\n",
            "Best match: wheel 0.33.4\n",
            "Adding wheel 0.33.4 to easy-install.pth file\n",
            "Installing wheel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Keras-Preprocessing==1.1.0\n",
            "Best match: Keras-Preprocessing 1.1.0\n",
            "Adding Keras-Preprocessing 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for grpcio==1.15.0\n",
            "Best match: grpcio 1.15.0\n",
            "Adding grpcio 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for termcolor==1.1.0\n",
            "Best match: termcolor 1.1.0\n",
            "Adding termcolor 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for google-pasta==0.1.7\n",
            "Best match: google-pasta 0.1.7\n",
            "Adding google-pasta 0.1.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for absl-py==0.7.1\n",
            "Best match: absl-py 0.7.1\n",
            "Adding absl-py 0.7.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for gast==0.2.2\n",
            "Best match: gast 0.2.2\n",
            "Adding gast 0.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for wrapt==1.11.2\n",
            "Best match: wrapt 1.11.2\n",
            "Adding wrapt 1.11.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for python-engineio==3.8.2\n",
            "Best match: python-engineio 3.8.2\n",
            "Adding python-engineio 3.8.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for MarkupSafe==1.1.1\n",
            "Best match: MarkupSafe 1.1.1\n",
            "Adding MarkupSafe 1.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for setuptools==41.0.1\n",
            "Best match: setuptools 41.0.1\n",
            "Adding setuptools 41.0.1 to easy-install.pth file\n",
            "Installing easy_install script to /usr/local/bin\n",
            "Installing easy_install-3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Markdown==3.1.1\n",
            "Best match: Markdown 3.1.1\n",
            "Adding Markdown 3.1.1 to easy-install.pth file\n",
            "Installing markdown_py script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for h5py==2.8.0\n",
            "Best match: h5py 2.8.0\n",
            "Adding h5py 2.8.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for syft==0.1.19a1\n",
            "Cloning into 'tf-encrypted'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 5586 (delta 34), reused 35 (delta 21), pack-reused 5526\n",
            "Receiving objects: 100% (5586/5586), 20.82 MiB | 18.95 MiB/s, done.\n",
            "Resolving deltas: 100% (3778/3778), done.\n",
            "/content/PySyft/tf-encrypted\n",
            "Obtaining file:///content/PySyft/tf-encrypted\n",
            "Requirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted==0.5.6) (1.14.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted==0.5.6) (1.16.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted==0.5.6) (5.1.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.14.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (0.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (0.1.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (3.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.11.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (0.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (0.33.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (2.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (0.15.4)\n",
            "Installing collected packages: tf-encrypted\n",
            "  Found existing installation: tf-encrypted 0.5.6\n",
            "    Uninstalling tf-encrypted-0.5.6:\n",
            "      Successfully uninstalled tf-encrypted-0.5.6\n",
            "  Running setup.py develop for tf-encrypted\n",
            "Successfully installed tf-encrypted\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0701 14:32:24.289454 140281323091840 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/content/PySyft/tf-encrypted/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0701 14:32:24.342205 140281323091840 deprecation_wrapper.py:119] From /content/PySyft/tf-encrypted/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/PySyft\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKG45I8k1qg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def experiment(num_workers,no_cuda):\n",
        "  \n",
        "  # Creating num_workers clients \n",
        "  clients = []\n",
        "  hook = sy.TorchHook(torch)\n",
        "  clients_mem = torch.zeros(num_workers)\n",
        "  for i in range(num_workers):\n",
        "    clients.append(sy.VirtualWorker(hook, id=\"c \"+str(i)))\n",
        "     \n",
        "  class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 64\n",
        "        self.test_batch_size = 1000\n",
        "        self.epochs = 10\n",
        "        self.lr = 0.01\n",
        "        self.momentum = 0.5\n",
        "        self.no_cuda = no_cuda\n",
        "        self.seed = 1\n",
        "        self.log_interval = 30\n",
        "        self.save_model = False\n",
        "\n",
        "  # Initializing arguments, with GPU usage or not\n",
        "  args = Arguments()\n",
        "\n",
        "  use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "  if use_cuda:\n",
        "        # TODO Quickhack. Actually need to fix the problem moving the model to CUDA\\n\",\n",
        "        torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "  \n",
        "  torch.manual_seed(args.seed)\n",
        "\n",
        "  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "  kwargs = {'num_workers': 0, 'pin_memory': False} if use_cuda else {}  \n",
        "  \n",
        "  \n",
        "  # Federated data loader\n",
        "  federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
        "      datasets.MNIST('../data', train=True, download=True,\n",
        "                     transform=transforms.Compose([\n",
        "                         transforms.ToTensor(),\n",
        "                         transforms.Normalize((0.1307,), (0.3081,))\n",
        "                     ]))\n",
        "      .federate(clients), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
        "      batch_size=args.batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "  test_loader = torch.utils.data.DataLoader(\n",
        "      datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                         transforms.ToTensor(),\n",
        "                         transforms.Normalize((0.1307,), (0.3081,))\n",
        "                     ])),\n",
        "      batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
        "  \n",
        "  # SplitNN classes \n",
        "  class Net1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net1, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        return F.max_pool2d(x, 2, 2)\n",
        "      \n",
        "  class Net2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net2, self).__init__()\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "    \n",
        "  #creating the models for each client  \n",
        "  models,optimizers = [], []\n",
        "  #print(device)\n",
        "  for i in range(num_workers):\n",
        "    #print(i)\n",
        "    models.append(Net1().to(device))\n",
        "    models[i] = models[i].send(clients[i])\n",
        "    optimizers.append(optim.SGD(params=models[i].parameters(),lr=0.1))\n",
        "    \n",
        "    \n",
        "  def train(args, model, device, federated_train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, targs) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
        "        #IF ON DATA LOCATION TO GET THE RIGHT MODEL AND OPTIMIZER \n",
        "        i = int(data.location.id.split()[-1])\n",
        "        mod_c,opt_c = models[i], optimizers[i]\n",
        "          \n",
        "        \n",
        "          \n",
        "        # 1) erase previous gradients (if they exist) and update parameters\n",
        "        optimizer.step()\n",
        "        opt_c.step()\n",
        "        opt_c.zero_grad()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        tg_copy = targs.copy()\n",
        "        target = tg_copy.get()\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        # 2) make a prediction until cut layer (client location)\n",
        "        pred_c = mod_c(data)\n",
        "        copy = pred_c.copy()\n",
        "        \n",
        "        \n",
        "        # 3) get this to the server \n",
        "        inp = copy.get()\n",
        "        \n",
        "        \n",
        "        # 4) make prediction with second part of the model (server location)\n",
        "        pred = model(inp)\n",
        "\n",
        "        # 5) calculate how much we missed \n",
        "        loss = F.nll_loss(pred, target)\n",
        "        loss.backward()\n",
        "        \n",
        "        gradient = inp.grad\n",
        "        \n",
        "        clients_mem[i] += (gradient.element_size()*gradient.nelement()) + (inp.element_size() * inp.nelement())\n",
        "        \n",
        "        \n",
        "        gradient = gradient.send(data.location)\n",
        "        #print(\"grad shape:\",gradient.shape)\n",
        "        #print(\"pred_c shape:\", pred_c.shape)\n",
        "        #gradient = gradient.view(pred_c.shape)\n",
        "        pred_c.backward(gradient)\n",
        "        \n",
        "        \n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            #loss = loss.get() # <-- NEW: get the loss back\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,\n",
        "                100. * batch_idx / len(federated_train_loader), loss.item()))\n",
        "    \n",
        "    \n",
        "  def test(args, model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    M1 = models[0].copy()\n",
        "    M2 = models[1].copy()\n",
        "    M1 = M1.get()\n",
        "    M2 = M2.get()\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(M1(data))\n",
        "            #output2 = model(M2(data))\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "    \n",
        "  \n",
        "  \n",
        "\n",
        "  start = time.time()\n",
        "\n",
        "\n",
        "  %%time\n",
        "  model = Net2().to(device)\n",
        "  optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
        "\n",
        "  for epoch in range(1, args.epochs + 1):\n",
        "      train(args, model, device, federated_train_loader, optimizer, epoch)\n",
        "      test(args, model, device, test_loader)\n",
        "\n",
        "  if (args.save_model):\n",
        "      torch.save(model.state_dict(), \"mnist_cnn.pt\")\n",
        "  \n",
        "  end = time.time()\n",
        "  print(end - start)\n",
        "  print(clients_mem)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXpnXEL9e-VX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6152
        },
        "outputId": "38820ec0-6eba-477c-ae2b-2c6c2fe1a9a2"
      },
      "source": [
        "experiment(5,False)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0701 15:06:34.327800 140281323091840 hook.py:97] Torch was already hooked... skipping hooking process\n",
            "W0701 15:06:44.334294 140281323091840 dataloader.py:197] The following options are not supported: num_workers: 0, pin_memory: False\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
            "Wall time: 5.72 µs\n",
            "Train Epoch: 1 [0/60032 (0%)]\tLoss: 2.327776\n",
            "Train Epoch: 1 [1920/60032 (3%)]\tLoss: 2.139923\n",
            "Train Epoch: 1 [3840/60032 (6%)]\tLoss: 1.298053\n",
            "Train Epoch: 1 [5760/60032 (10%)]\tLoss: 0.610383\n",
            "Train Epoch: 1 [7680/60032 (13%)]\tLoss: 0.477114\n",
            "Train Epoch: 1 [9600/60032 (16%)]\tLoss: 0.463847\n",
            "Train Epoch: 1 [11520/60032 (19%)]\tLoss: 0.421263\n",
            "Train Epoch: 1 [13440/60032 (22%)]\tLoss: 0.402401\n",
            "Train Epoch: 1 [15360/60032 (26%)]\tLoss: 0.485806\n",
            "Train Epoch: 1 [17280/60032 (29%)]\tLoss: 0.394701\n",
            "Train Epoch: 1 [19200/60032 (32%)]\tLoss: 0.249427\n",
            "Train Epoch: 1 [21120/60032 (35%)]\tLoss: 0.289939\n",
            "Train Epoch: 1 [23040/60032 (38%)]\tLoss: 0.228413\n",
            "Train Epoch: 1 [24960/60032 (42%)]\tLoss: 0.505655\n",
            "Train Epoch: 1 [26880/60032 (45%)]\tLoss: 0.192751\n",
            "Train Epoch: 1 [28800/60032 (48%)]\tLoss: 0.383269\n",
            "Train Epoch: 1 [30720/60032 (51%)]\tLoss: 0.170697\n",
            "Train Epoch: 1 [32640/60032 (54%)]\tLoss: 0.315471\n",
            "Train Epoch: 1 [34560/60032 (58%)]\tLoss: 0.280150\n",
            "Train Epoch: 1 [36480/60032 (61%)]\tLoss: 0.422749\n",
            "Train Epoch: 1 [38400/60032 (64%)]\tLoss: 0.323269\n",
            "Train Epoch: 1 [40320/60032 (67%)]\tLoss: 0.254440\n",
            "Train Epoch: 1 [42240/60032 (70%)]\tLoss: 0.148997\n",
            "Train Epoch: 1 [44160/60032 (74%)]\tLoss: 0.121905\n",
            "Train Epoch: 1 [46080/60032 (77%)]\tLoss: 0.332846\n",
            "Train Epoch: 1 [48000/60032 (80%)]\tLoss: 0.200272\n",
            "Train Epoch: 1 [49920/60032 (83%)]\tLoss: 0.175257\n",
            "Train Epoch: 1 [51840/60032 (86%)]\tLoss: 0.072417\n",
            "Train Epoch: 1 [53760/60032 (90%)]\tLoss: 0.165821\n",
            "Train Epoch: 1 [55680/60032 (93%)]\tLoss: 0.092970\n",
            "Train Epoch: 1 [57600/60032 (96%)]\tLoss: 0.050224\n",
            "Train Epoch: 1 [59520/60032 (99%)]\tLoss: 0.077086\n",
            "\n",
            "Test set: Average loss: 0.2114, Accuracy: 9431/10000 (94%)\n",
            "\n",
            "Train Epoch: 2 [0/60032 (0%)]\tLoss: 0.036953\n",
            "Train Epoch: 2 [1920/60032 (3%)]\tLoss: 0.362037\n",
            "Train Epoch: 2 [3840/60032 (6%)]\tLoss: 0.091044\n",
            "Train Epoch: 2 [5760/60032 (10%)]\tLoss: 0.137177\n",
            "Train Epoch: 2 [7680/60032 (13%)]\tLoss: 0.181223\n",
            "Train Epoch: 2 [9600/60032 (16%)]\tLoss: 0.215715\n",
            "Train Epoch: 2 [11520/60032 (19%)]\tLoss: 0.165866\n",
            "Train Epoch: 2 [13440/60032 (22%)]\tLoss: 0.143442\n",
            "Train Epoch: 2 [15360/60032 (26%)]\tLoss: 0.233931\n",
            "Train Epoch: 2 [17280/60032 (29%)]\tLoss: 0.089560\n",
            "Train Epoch: 2 [19200/60032 (32%)]\tLoss: 0.132194\n",
            "Train Epoch: 2 [21120/60032 (35%)]\tLoss: 0.106143\n",
            "Train Epoch: 2 [23040/60032 (38%)]\tLoss: 0.118441\n",
            "Train Epoch: 2 [24960/60032 (42%)]\tLoss: 0.156977\n",
            "Train Epoch: 2 [26880/60032 (45%)]\tLoss: 0.048643\n",
            "Train Epoch: 2 [28800/60032 (48%)]\tLoss: 0.083481\n",
            "Train Epoch: 2 [30720/60032 (51%)]\tLoss: 0.156076\n",
            "Train Epoch: 2 [32640/60032 (54%)]\tLoss: 0.054386\n",
            "Train Epoch: 2 [34560/60032 (58%)]\tLoss: 0.096422\n",
            "Train Epoch: 2 [36480/60032 (61%)]\tLoss: 0.157837\n",
            "Train Epoch: 2 [38400/60032 (64%)]\tLoss: 0.113633\n",
            "Train Epoch: 2 [40320/60032 (67%)]\tLoss: 0.078812\n",
            "Train Epoch: 2 [42240/60032 (70%)]\tLoss: 0.109222\n",
            "Train Epoch: 2 [44160/60032 (74%)]\tLoss: 0.243395\n",
            "Train Epoch: 2 [46080/60032 (77%)]\tLoss: 0.115157\n",
            "Train Epoch: 2 [48000/60032 (80%)]\tLoss: 0.119519\n",
            "Train Epoch: 2 [49920/60032 (83%)]\tLoss: 0.074012\n",
            "Train Epoch: 2 [51840/60032 (86%)]\tLoss: 0.072892\n",
            "Train Epoch: 2 [53760/60032 (90%)]\tLoss: 0.092434\n",
            "Train Epoch: 2 [55680/60032 (93%)]\tLoss: 0.118952\n",
            "Train Epoch: 2 [57600/60032 (96%)]\tLoss: 0.065255\n",
            "Train Epoch: 2 [59520/60032 (99%)]\tLoss: 0.095545\n",
            "\n",
            "Test set: Average loss: 0.1092, Accuracy: 9664/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60032 (0%)]\tLoss: 0.131530\n",
            "Train Epoch: 3 [1920/60032 (3%)]\tLoss: 0.023076\n",
            "Train Epoch: 3 [3840/60032 (6%)]\tLoss: 0.213165\n",
            "Train Epoch: 3 [5760/60032 (10%)]\tLoss: 0.082699\n",
            "Train Epoch: 3 [7680/60032 (13%)]\tLoss: 0.056450\n",
            "Train Epoch: 3 [9600/60032 (16%)]\tLoss: 0.023170\n",
            "Train Epoch: 3 [11520/60032 (19%)]\tLoss: 0.156221\n",
            "Train Epoch: 3 [13440/60032 (22%)]\tLoss: 0.117885\n",
            "Train Epoch: 3 [15360/60032 (26%)]\tLoss: 0.024403\n",
            "Train Epoch: 3 [17280/60032 (29%)]\tLoss: 0.065781\n",
            "Train Epoch: 3 [19200/60032 (32%)]\tLoss: 0.069189\n",
            "Train Epoch: 3 [21120/60032 (35%)]\tLoss: 0.056130\n",
            "Train Epoch: 3 [23040/60032 (38%)]\tLoss: 0.024269\n",
            "Train Epoch: 3 [24960/60032 (42%)]\tLoss: 0.066622\n",
            "Train Epoch: 3 [26880/60032 (45%)]\tLoss: 0.098452\n",
            "Train Epoch: 3 [28800/60032 (48%)]\tLoss: 0.062894\n",
            "Train Epoch: 3 [30720/60032 (51%)]\tLoss: 0.107616\n",
            "Train Epoch: 3 [32640/60032 (54%)]\tLoss: 0.040253\n",
            "Train Epoch: 3 [34560/60032 (58%)]\tLoss: 0.128675\n",
            "Train Epoch: 3 [36480/60032 (61%)]\tLoss: 0.086261\n",
            "Train Epoch: 3 [38400/60032 (64%)]\tLoss: 0.077690\n",
            "Train Epoch: 3 [40320/60032 (67%)]\tLoss: 0.042430\n",
            "Train Epoch: 3 [42240/60032 (70%)]\tLoss: 0.059757\n",
            "Train Epoch: 3 [44160/60032 (74%)]\tLoss: 0.193973\n",
            "Train Epoch: 3 [46080/60032 (77%)]\tLoss: 0.050007\n",
            "Train Epoch: 3 [48000/60032 (80%)]\tLoss: 0.024153\n",
            "Train Epoch: 3 [49920/60032 (83%)]\tLoss: 0.023272\n",
            "Train Epoch: 3 [51840/60032 (86%)]\tLoss: 0.121457\n",
            "Train Epoch: 3 [53760/60032 (90%)]\tLoss: 0.142022\n",
            "Train Epoch: 3 [55680/60032 (93%)]\tLoss: 0.072580\n",
            "Train Epoch: 3 [57600/60032 (96%)]\tLoss: 0.039566\n",
            "Train Epoch: 3 [59520/60032 (99%)]\tLoss: 0.337532\n",
            "\n",
            "Test set: Average loss: 0.0705, Accuracy: 9771/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60032 (0%)]\tLoss: 0.013122\n",
            "Train Epoch: 4 [1920/60032 (3%)]\tLoss: 0.034607\n",
            "Train Epoch: 4 [3840/60032 (6%)]\tLoss: 0.095374\n",
            "Train Epoch: 4 [5760/60032 (10%)]\tLoss: 0.109220\n",
            "Train Epoch: 4 [7680/60032 (13%)]\tLoss: 0.078033\n",
            "Train Epoch: 4 [9600/60032 (16%)]\tLoss: 0.028281\n",
            "Train Epoch: 4 [11520/60032 (19%)]\tLoss: 0.017301\n",
            "Train Epoch: 4 [13440/60032 (22%)]\tLoss: 0.122161\n",
            "Train Epoch: 4 [15360/60032 (26%)]\tLoss: 0.086036\n",
            "Train Epoch: 4 [17280/60032 (29%)]\tLoss: 0.049800\n",
            "Train Epoch: 4 [19200/60032 (32%)]\tLoss: 0.055385\n",
            "Train Epoch: 4 [21120/60032 (35%)]\tLoss: 0.041354\n",
            "Train Epoch: 4 [23040/60032 (38%)]\tLoss: 0.054206\n",
            "Train Epoch: 4 [24960/60032 (42%)]\tLoss: 0.029019\n",
            "Train Epoch: 4 [26880/60032 (45%)]\tLoss: 0.044018\n",
            "Train Epoch: 4 [28800/60032 (48%)]\tLoss: 0.059321\n",
            "Train Epoch: 4 [30720/60032 (51%)]\tLoss: 0.061124\n",
            "Train Epoch: 4 [32640/60032 (54%)]\tLoss: 0.059809\n",
            "Train Epoch: 4 [34560/60032 (58%)]\tLoss: 0.108879\n",
            "Train Epoch: 4 [36480/60032 (61%)]\tLoss: 0.134592\n",
            "Train Epoch: 4 [38400/60032 (64%)]\tLoss: 0.098372\n",
            "Train Epoch: 4 [40320/60032 (67%)]\tLoss: 0.055352\n",
            "Train Epoch: 4 [42240/60032 (70%)]\tLoss: 0.018754\n",
            "Train Epoch: 4 [44160/60032 (74%)]\tLoss: 0.053880\n",
            "Train Epoch: 4 [46080/60032 (77%)]\tLoss: 0.015533\n",
            "Train Epoch: 4 [48000/60032 (80%)]\tLoss: 0.120831\n",
            "Train Epoch: 4 [49920/60032 (83%)]\tLoss: 0.121547\n",
            "Train Epoch: 4 [51840/60032 (86%)]\tLoss: 0.040748\n",
            "Train Epoch: 4 [53760/60032 (90%)]\tLoss: 0.086249\n",
            "Train Epoch: 4 [55680/60032 (93%)]\tLoss: 0.104531\n",
            "Train Epoch: 4 [57600/60032 (96%)]\tLoss: 0.155545\n",
            "Train Epoch: 4 [59520/60032 (99%)]\tLoss: 0.038046\n",
            "\n",
            "Test set: Average loss: 0.0591, Accuracy: 9806/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60032 (0%)]\tLoss: 0.175205\n",
            "Train Epoch: 5 [1920/60032 (3%)]\tLoss: 0.045058\n",
            "Train Epoch: 5 [3840/60032 (6%)]\tLoss: 0.015187\n",
            "Train Epoch: 5 [5760/60032 (10%)]\tLoss: 0.068708\n",
            "Train Epoch: 5 [7680/60032 (13%)]\tLoss: 0.088766\n",
            "Train Epoch: 5 [9600/60032 (16%)]\tLoss: 0.028170\n",
            "Train Epoch: 5 [11520/60032 (19%)]\tLoss: 0.031031\n",
            "Train Epoch: 5 [13440/60032 (22%)]\tLoss: 0.034135\n",
            "Train Epoch: 5 [15360/60032 (26%)]\tLoss: 0.024718\n",
            "Train Epoch: 5 [17280/60032 (29%)]\tLoss: 0.033989\n",
            "Train Epoch: 5 [19200/60032 (32%)]\tLoss: 0.099099\n",
            "Train Epoch: 5 [21120/60032 (35%)]\tLoss: 0.117155\n",
            "Train Epoch: 5 [23040/60032 (38%)]\tLoss: 0.034584\n",
            "Train Epoch: 5 [24960/60032 (42%)]\tLoss: 0.056416\n",
            "Train Epoch: 5 [26880/60032 (45%)]\tLoss: 0.081159\n",
            "Train Epoch: 5 [28800/60032 (48%)]\tLoss: 0.042720\n",
            "Train Epoch: 5 [30720/60032 (51%)]\tLoss: 0.032624\n",
            "Train Epoch: 5 [32640/60032 (54%)]\tLoss: 0.038900\n",
            "Train Epoch: 5 [34560/60032 (58%)]\tLoss: 0.026721\n",
            "Train Epoch: 5 [36480/60032 (61%)]\tLoss: 0.026670\n",
            "Train Epoch: 5 [38400/60032 (64%)]\tLoss: 0.142878\n",
            "Train Epoch: 5 [40320/60032 (67%)]\tLoss: 0.027457\n",
            "Train Epoch: 5 [42240/60032 (70%)]\tLoss: 0.026741\n",
            "Train Epoch: 5 [44160/60032 (74%)]\tLoss: 0.088418\n",
            "Train Epoch: 5 [46080/60032 (77%)]\tLoss: 0.077605\n",
            "Train Epoch: 5 [48000/60032 (80%)]\tLoss: 0.009868\n",
            "Train Epoch: 5 [49920/60032 (83%)]\tLoss: 0.074918\n",
            "Train Epoch: 5 [51840/60032 (86%)]\tLoss: 0.097109\n",
            "Train Epoch: 5 [53760/60032 (90%)]\tLoss: 0.079834\n",
            "Train Epoch: 5 [55680/60032 (93%)]\tLoss: 0.101249\n",
            "Train Epoch: 5 [57600/60032 (96%)]\tLoss: 0.021547\n",
            "Train Epoch: 5 [59520/60032 (99%)]\tLoss: 0.035844\n",
            "\n",
            "Test set: Average loss: 0.0526, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 6 [0/60032 (0%)]\tLoss: 0.071559\n",
            "Train Epoch: 6 [1920/60032 (3%)]\tLoss: 0.023036\n",
            "Train Epoch: 6 [3840/60032 (6%)]\tLoss: 0.044301\n",
            "Train Epoch: 6 [5760/60032 (10%)]\tLoss: 0.073719\n",
            "Train Epoch: 6 [7680/60032 (13%)]\tLoss: 0.006204\n",
            "Train Epoch: 6 [9600/60032 (16%)]\tLoss: 0.134801\n",
            "Train Epoch: 6 [11520/60032 (19%)]\tLoss: 0.044166\n",
            "Train Epoch: 6 [13440/60032 (22%)]\tLoss: 0.102899\n",
            "Train Epoch: 6 [15360/60032 (26%)]\tLoss: 0.013032\n",
            "Train Epoch: 6 [17280/60032 (29%)]\tLoss: 0.051252\n",
            "Train Epoch: 6 [19200/60032 (32%)]\tLoss: 0.013514\n",
            "Train Epoch: 6 [21120/60032 (35%)]\tLoss: 0.010048\n",
            "Train Epoch: 6 [23040/60032 (38%)]\tLoss: 0.031416\n",
            "Train Epoch: 6 [24960/60032 (42%)]\tLoss: 0.014066\n",
            "Train Epoch: 6 [26880/60032 (45%)]\tLoss: 0.068814\n",
            "Train Epoch: 6 [28800/60032 (48%)]\tLoss: 0.039889\n",
            "Train Epoch: 6 [30720/60032 (51%)]\tLoss: 0.008508\n",
            "Train Epoch: 6 [32640/60032 (54%)]\tLoss: 0.007000\n",
            "Train Epoch: 6 [34560/60032 (58%)]\tLoss: 0.104588\n",
            "Train Epoch: 6 [36480/60032 (61%)]\tLoss: 0.070333\n",
            "Train Epoch: 6 [38400/60032 (64%)]\tLoss: 0.065585\n",
            "Train Epoch: 6 [40320/60032 (67%)]\tLoss: 0.047318\n",
            "Train Epoch: 6 [42240/60032 (70%)]\tLoss: 0.072826\n",
            "Train Epoch: 6 [44160/60032 (74%)]\tLoss: 0.057012\n",
            "Train Epoch: 6 [46080/60032 (77%)]\tLoss: 0.028227\n",
            "Train Epoch: 6 [48000/60032 (80%)]\tLoss: 0.040917\n",
            "Train Epoch: 6 [49920/60032 (83%)]\tLoss: 0.052306\n",
            "Train Epoch: 6 [51840/60032 (86%)]\tLoss: 0.100292\n",
            "Train Epoch: 6 [53760/60032 (90%)]\tLoss: 0.051053\n",
            "Train Epoch: 6 [55680/60032 (93%)]\tLoss: 0.006587\n",
            "Train Epoch: 6 [57600/60032 (96%)]\tLoss: 0.046540\n",
            "Train Epoch: 6 [59520/60032 (99%)]\tLoss: 0.015276\n",
            "\n",
            "Test set: Average loss: 0.0483, Accuracy: 9851/10000 (99%)\n",
            "\n",
            "Train Epoch: 7 [0/60032 (0%)]\tLoss: 0.044385\n",
            "Train Epoch: 7 [1920/60032 (3%)]\tLoss: 0.042525\n",
            "Train Epoch: 7 [3840/60032 (6%)]\tLoss: 0.059522\n",
            "Train Epoch: 7 [5760/60032 (10%)]\tLoss: 0.008932\n",
            "Train Epoch: 7 [7680/60032 (13%)]\tLoss: 0.007817\n",
            "Train Epoch: 7 [9600/60032 (16%)]\tLoss: 0.014737\n",
            "Train Epoch: 7 [11520/60032 (19%)]\tLoss: 0.013589\n",
            "Train Epoch: 7 [13440/60032 (22%)]\tLoss: 0.014980\n",
            "Train Epoch: 7 [15360/60032 (26%)]\tLoss: 0.033111\n",
            "Train Epoch: 7 [17280/60032 (29%)]\tLoss: 0.070106\n",
            "Train Epoch: 7 [19200/60032 (32%)]\tLoss: 0.078096\n",
            "Train Epoch: 7 [21120/60032 (35%)]\tLoss: 0.029427\n",
            "Train Epoch: 7 [23040/60032 (38%)]\tLoss: 0.029831\n",
            "Train Epoch: 7 [24960/60032 (42%)]\tLoss: 0.006459\n",
            "Train Epoch: 7 [26880/60032 (45%)]\tLoss: 0.022903\n",
            "Train Epoch: 7 [28800/60032 (48%)]\tLoss: 0.025555\n",
            "Train Epoch: 7 [30720/60032 (51%)]\tLoss: 0.039362\n",
            "Train Epoch: 7 [32640/60032 (54%)]\tLoss: 0.056181\n",
            "Train Epoch: 7 [34560/60032 (58%)]\tLoss: 0.107079\n",
            "Train Epoch: 7 [36480/60032 (61%)]\tLoss: 0.025369\n",
            "Train Epoch: 7 [38400/60032 (64%)]\tLoss: 0.077776\n",
            "Train Epoch: 7 [40320/60032 (67%)]\tLoss: 0.017984\n",
            "Train Epoch: 7 [42240/60032 (70%)]\tLoss: 0.031926\n",
            "Train Epoch: 7 [44160/60032 (74%)]\tLoss: 0.046817\n",
            "Train Epoch: 7 [46080/60032 (77%)]\tLoss: 0.084569\n",
            "Train Epoch: 7 [48000/60032 (80%)]\tLoss: 0.007959\n",
            "Train Epoch: 7 [49920/60032 (83%)]\tLoss: 0.057815\n",
            "Train Epoch: 7 [51840/60032 (86%)]\tLoss: 0.068594\n",
            "Train Epoch: 7 [53760/60032 (90%)]\tLoss: 0.023778\n",
            "Train Epoch: 7 [55680/60032 (93%)]\tLoss: 0.133418\n",
            "Train Epoch: 7 [57600/60032 (96%)]\tLoss: 0.124556\n",
            "Train Epoch: 7 [59520/60032 (99%)]\tLoss: 0.032086\n",
            "\n",
            "Test set: Average loss: 0.0476, Accuracy: 9845/10000 (98%)\n",
            "\n",
            "Train Epoch: 8 [0/60032 (0%)]\tLoss: 0.018518\n",
            "Train Epoch: 8 [1920/60032 (3%)]\tLoss: 0.012629\n",
            "Train Epoch: 8 [3840/60032 (6%)]\tLoss: 0.077853\n",
            "Train Epoch: 8 [5760/60032 (10%)]\tLoss: 0.012902\n",
            "Train Epoch: 8 [7680/60032 (13%)]\tLoss: 0.096459\n",
            "Train Epoch: 8 [9600/60032 (16%)]\tLoss: 0.011746\n",
            "Train Epoch: 8 [11520/60032 (19%)]\tLoss: 0.044986\n",
            "Train Epoch: 8 [13440/60032 (22%)]\tLoss: 0.022224\n",
            "Train Epoch: 8 [15360/60032 (26%)]\tLoss: 0.017419\n",
            "Train Epoch: 8 [17280/60032 (29%)]\tLoss: 0.018421\n",
            "Train Epoch: 8 [19200/60032 (32%)]\tLoss: 0.009784\n",
            "Train Epoch: 8 [21120/60032 (35%)]\tLoss: 0.026753\n",
            "Train Epoch: 8 [23040/60032 (38%)]\tLoss: 0.009856\n",
            "Train Epoch: 8 [24960/60032 (42%)]\tLoss: 0.049624\n",
            "Train Epoch: 8 [26880/60032 (45%)]\tLoss: 0.011525\n",
            "Train Epoch: 8 [28800/60032 (48%)]\tLoss: 0.051648\n",
            "Train Epoch: 8 [30720/60032 (51%)]\tLoss: 0.028503\n",
            "Train Epoch: 8 [32640/60032 (54%)]\tLoss: 0.013926\n",
            "Train Epoch: 8 [34560/60032 (58%)]\tLoss: 0.016863\n",
            "Train Epoch: 8 [36480/60032 (61%)]\tLoss: 0.022578\n",
            "Train Epoch: 8 [38400/60032 (64%)]\tLoss: 0.127593\n",
            "Train Epoch: 8 [40320/60032 (67%)]\tLoss: 0.015252\n",
            "Train Epoch: 8 [42240/60032 (70%)]\tLoss: 0.018943\n",
            "Train Epoch: 8 [44160/60032 (74%)]\tLoss: 0.039527\n",
            "Train Epoch: 8 [46080/60032 (77%)]\tLoss: 0.018861\n",
            "Train Epoch: 8 [48000/60032 (80%)]\tLoss: 0.039885\n",
            "Train Epoch: 8 [49920/60032 (83%)]\tLoss: 0.011201\n",
            "Train Epoch: 8 [51840/60032 (86%)]\tLoss: 0.055718\n",
            "Train Epoch: 8 [53760/60032 (90%)]\tLoss: 0.031844\n",
            "Train Epoch: 8 [55680/60032 (93%)]\tLoss: 0.077607\n",
            "Train Epoch: 8 [57600/60032 (96%)]\tLoss: 0.015766\n",
            "Train Epoch: 8 [59520/60032 (99%)]\tLoss: 0.023754\n",
            "\n",
            "Test set: Average loss: 0.0445, Accuracy: 9850/10000 (98%)\n",
            "\n",
            "Train Epoch: 9 [0/60032 (0%)]\tLoss: 0.009031\n",
            "Train Epoch: 9 [1920/60032 (3%)]\tLoss: 0.123686\n",
            "Train Epoch: 9 [3840/60032 (6%)]\tLoss: 0.144692\n",
            "Train Epoch: 9 [5760/60032 (10%)]\tLoss: 0.094534\n",
            "Train Epoch: 9 [7680/60032 (13%)]\tLoss: 0.008324\n",
            "Train Epoch: 9 [9600/60032 (16%)]\tLoss: 0.046921\n",
            "Train Epoch: 9 [11520/60032 (19%)]\tLoss: 0.005300\n",
            "Train Epoch: 9 [13440/60032 (22%)]\tLoss: 0.017167\n",
            "Train Epoch: 9 [15360/60032 (26%)]\tLoss: 0.013448\n",
            "Train Epoch: 9 [17280/60032 (29%)]\tLoss: 0.006064\n",
            "Train Epoch: 9 [19200/60032 (32%)]\tLoss: 0.004603\n",
            "Train Epoch: 9 [21120/60032 (35%)]\tLoss: 0.012890\n",
            "Train Epoch: 9 [23040/60032 (38%)]\tLoss: 0.106601\n",
            "Train Epoch: 9 [24960/60032 (42%)]\tLoss: 0.058219\n",
            "Train Epoch: 9 [26880/60032 (45%)]\tLoss: 0.028813\n",
            "Train Epoch: 9 [28800/60032 (48%)]\tLoss: 0.096407\n",
            "Train Epoch: 9 [30720/60032 (51%)]\tLoss: 0.102944\n",
            "Train Epoch: 9 [32640/60032 (54%)]\tLoss: 0.009171\n",
            "Train Epoch: 9 [34560/60032 (58%)]\tLoss: 0.024307\n",
            "Train Epoch: 9 [36480/60032 (61%)]\tLoss: 0.007443\n",
            "Train Epoch: 9 [38400/60032 (64%)]\tLoss: 0.013283\n",
            "Train Epoch: 9 [40320/60032 (67%)]\tLoss: 0.023390\n",
            "Train Epoch: 9 [42240/60032 (70%)]\tLoss: 0.028465\n",
            "Train Epoch: 9 [44160/60032 (74%)]\tLoss: 0.009346\n",
            "Train Epoch: 9 [46080/60032 (77%)]\tLoss: 0.005336\n",
            "Train Epoch: 9 [48000/60032 (80%)]\tLoss: 0.017525\n",
            "Train Epoch: 9 [49920/60032 (83%)]\tLoss: 0.028676\n",
            "Train Epoch: 9 [51840/60032 (86%)]\tLoss: 0.005126\n",
            "Train Epoch: 9 [53760/60032 (90%)]\tLoss: 0.066154\n",
            "Train Epoch: 9 [55680/60032 (93%)]\tLoss: 0.001549\n",
            "Train Epoch: 9 [57600/60032 (96%)]\tLoss: 0.040549\n",
            "Train Epoch: 9 [59520/60032 (99%)]\tLoss: 0.066943\n",
            "\n",
            "Test set: Average loss: 0.0475, Accuracy: 9837/10000 (98%)\n",
            "\n",
            "Train Epoch: 10 [0/60032 (0%)]\tLoss: 0.018242\n",
            "Train Epoch: 10 [1920/60032 (3%)]\tLoss: 0.011060\n",
            "Train Epoch: 10 [3840/60032 (6%)]\tLoss: 0.030620\n",
            "Train Epoch: 10 [5760/60032 (10%)]\tLoss: 0.007169\n",
            "Train Epoch: 10 [7680/60032 (13%)]\tLoss: 0.015498\n",
            "Train Epoch: 10 [9600/60032 (16%)]\tLoss: 0.005510\n",
            "Train Epoch: 10 [11520/60032 (19%)]\tLoss: 0.025589\n",
            "Train Epoch: 10 [13440/60032 (22%)]\tLoss: 0.006170\n",
            "Train Epoch: 10 [15360/60032 (26%)]\tLoss: 0.017884\n",
            "Train Epoch: 10 [17280/60032 (29%)]\tLoss: 0.094470\n",
            "Train Epoch: 10 [19200/60032 (32%)]\tLoss: 0.021403\n",
            "Train Epoch: 10 [21120/60032 (35%)]\tLoss: 0.014228\n",
            "Train Epoch: 10 [23040/60032 (38%)]\tLoss: 0.022748\n",
            "Train Epoch: 10 [24960/60032 (42%)]\tLoss: 0.017408\n",
            "Train Epoch: 10 [26880/60032 (45%)]\tLoss: 0.022442\n",
            "Train Epoch: 10 [28800/60032 (48%)]\tLoss: 0.030657\n",
            "Train Epoch: 10 [30720/60032 (51%)]\tLoss: 0.027751\n",
            "Train Epoch: 10 [32640/60032 (54%)]\tLoss: 0.024210\n",
            "Train Epoch: 10 [34560/60032 (58%)]\tLoss: 0.012632\n",
            "Train Epoch: 10 [36480/60032 (61%)]\tLoss: 0.024678\n",
            "Train Epoch: 10 [38400/60032 (64%)]\tLoss: 0.018610\n",
            "Train Epoch: 10 [40320/60032 (67%)]\tLoss: 0.097007\n",
            "Train Epoch: 10 [42240/60032 (70%)]\tLoss: 0.063843\n",
            "Train Epoch: 10 [44160/60032 (74%)]\tLoss: 0.009524\n",
            "Train Epoch: 10 [46080/60032 (77%)]\tLoss: 0.071466\n",
            "Train Epoch: 10 [48000/60032 (80%)]\tLoss: 0.006624\n",
            "Train Epoch: 10 [49920/60032 (83%)]\tLoss: 0.121376\n",
            "Train Epoch: 10 [51840/60032 (86%)]\tLoss: 0.047842\n",
            "Train Epoch: 10 [53760/60032 (90%)]\tLoss: 0.032266\n",
            "Train Epoch: 10 [55680/60032 (93%)]\tLoss: 0.062350\n",
            "Train Epoch: 10 [57600/60032 (96%)]\tLoss: 0.039332\n",
            "Train Epoch: 10 [59520/60032 (99%)]\tLoss: 0.031044\n",
            "\n",
            "Test set: Average loss: 0.0367, Accuracy: 9875/10000 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otcbz6R1fpTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALtGqqvFyGcd",
        "colab_type": "text"
      },
      "source": [
        "## TEST 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ph7WdWURj2lD"
      },
      "source": [
        "### INSTALLATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "813b8347-eeb1-458a-ccbe-66540b55e8cf",
        "id": "6XcVWZADj2lU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "! git clone https://github.com/OpenMined/PySyft.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PySyft'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects:  25% (1/4)   \u001b[K\rremote: Counting objects:  50% (2/4)   \u001b[K\rremote: Counting objects:  75% (3/4)   \u001b[K\rremote: Counting objects: 100% (4/4)   \u001b[K\rremote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 28321 (delta 0), reused 0 (delta 0), pack-reused 28317\u001b[K\n",
            "Receiving objects: 100% (28321/28321), 31.91 MiB | 22.61 MiB/s, done.\n",
            "Resolving deltas: 100% (18686/18686), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YLQFzLNogin",
        "colab_type": "code",
        "outputId": "56e6a200-03cf-4338-ad63-7cdb33540676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd PySyft"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/PySyft\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb-HUxxaeoZb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "6156cc7d-1c48-4793-ce78-b6aba60025b1"
      },
      "source": [
        "! git checkout 7b6f9fb"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Note: checking out '7b6f9fb'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at 7b6f9fb2 Merge pull request #2303 from amit-rastogi/dev\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UHm7tKQe1Co",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "9a1f49ca-6b61-4b4c-f984-41d1461d003c"
      },
      "source": [
        "! git show"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mcommit 7b6f9fb2b98865f4ad45f93d337970c885ee3534\u001b[m\u001b[33m (\u001b[m\u001b[1;36mHEAD\u001b[m\u001b[33m)\u001b[m\n",
            "Merge: ab75db1e 0273a8f1\n",
            "Author: Robert (Bobby) Wagner <raw141@case.edu>\n",
            "Date:   Thu Jun 20 14:52:49 2019 -0400\n",
            "\n",
            "    Merge pull request #2303 from amit-rastogi/dev\n",
            "    \n",
            "    Added tutorial for using pysyft to train a reinforcement learning agent\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef8-3ERfbxJw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1350
        },
        "outputId": "e54c5895-5113-4c6b-d442-26678a92aa56"
      },
      "source": [
        "! pip install -r requirements.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.0.3)\n",
            "Collecting flask_socketio>=3.3.2 (from -r requirements.txt (line 2))\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/68/fe4806d3a0a5909d274367eb9b3b87262906c1515024f46c2443a36a0c82/Flask_SocketIO-4.1.0-py2.py3-none-any.whl\n",
            "Collecting lz4>=2.1.6 (from -r requirements.txt (line 3))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 4.2MB/s \n",
            "\u001b[?25hCollecting msgpack>=0.6.1 (from -r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/7e/ae9e91c1bb8d846efafd1f353476e3fd7309778b582d2fb4cea4cc15b9a2/msgpack-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 43.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (1.16.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.21.2)\n",
            "Requirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (1.4.0)\n",
            "Collecting tf_encrypted>=0.5.4 (from -r requirements.txt (line 8))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/ce/da9916e7e78f736894b15538b702c0b213fd5d60a7fd6e481d74033a90c0/tf_encrypted-0.5.6-py3-none-manylinux1_x86_64.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 38.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (1.1.0)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (0.3.0)\n",
            "Collecting websocket_client>=0.56.0 (from -r requirements.txt (line 11))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 43.2MB/s \n",
            "\u001b[?25hCollecting websockets>=7.0 (from -r requirements.txt (line 12))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/71/8bfa882b9c502c36e5c9ef6732969533670d2b039cbf95a82ced8f762b80/websockets-7.0-cp36-cp36m-manylinux1_x86_64.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 27.2MB/s \n",
            "\u001b[?25hCollecting zstd>=1.4.0.0 (from -r requirements.txt (line 13))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/27/1ea8086d37424e83ab692015cc8dd7d5e37cf791e339633a40dc828dfb74/zstd-1.4.0.0.tar.gz (450kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 40.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: Werkzeug>=0.14 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->-r requirements.txt (line 1)) (0.15.4)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->-r requirements.txt (line 1)) (7.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->-r requirements.txt (line 1)) (2.10.1)\n",
            "Collecting python-socketio>=2.1.0 (from flask_socketio>=3.3.2->-r requirements.txt (line 2))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/1b/57e860a86f2a01be86ae1dacfa0cd8c4dfbfcd4593322268b61b5a07b564/python_socketio-4.2.0-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 21.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->-r requirements.txt (line 6)) (0.13.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->-r requirements.txt (line 6)) (1.3.0)\n",
            "Collecting pyyaml>=5.1 (from tf_encrypted>=0.5.4->-r requirements.txt (line 8))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/837fefac7475963d1eccf4aa684c23b95aa6c1d033a2c5965ccb11e22623/PyYAML-5.1.1.tar.gz (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 40.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.14.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->-r requirements.txt (line 10)) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->-r requirements.txt (line 10)) (1.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10->Flask>=1.0.2->-r requirements.txt (line 1)) (1.1.1)\n",
            "Collecting python-engineio>=3.8.0 (from python-socketio>=2.1.0->flask_socketio>=3.3.2->-r requirements.txt (line 2))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/1c/601f8ad22681ec9b86acafabc145b6bd02ca62aeac6aae4045d262a94a56/python_engineio-3.8.2-py2.py3-none-any.whl (119kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 39.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.11.2)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.14.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (0.8.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (3.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (0.33.4)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->-r requirements.txt (line 10)) (0.46)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (2.8.0)\n",
            "Building wheels for collected packages: zstd, pyyaml\n",
            "  Building wheel for zstd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/9a/f4/3105b5209674ac77fcca7fede95184c62a95df0196888e0e76\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/27/a1/775c62ddea7bfa62324fd1f65847ed31c55dadb6051481ba3f\n",
            "Successfully built zstd pyyaml\n",
            "Installing collected packages: python-engineio, python-socketio, flask-socketio, lz4, msgpack, pyyaml, tf-encrypted, websocket-client, websockets, zstd\n",
            "  Found existing installation: msgpack 0.5.6\n",
            "    Uninstalling msgpack-0.5.6:\n",
            "      Successfully uninstalled msgpack-0.5.6\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed flask-socketio-4.1.0 lz4-2.1.10 msgpack-0.6.1 python-engineio-3.8.2 python-socketio-4.2.0 pyyaml-5.1.1 tf-encrypted-0.5.6 websocket-client-0.56.0 websockets-7.0 zstd-1.4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6de79e28-967d-46a3-a138-9757e2ad5558",
        "id": "NULjmqsaj2lg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd .."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VzkMjP3tj2lr",
        "colab": {}
      },
      "source": [
        "! mv native.py PySyft/syft/frameworks/torch/tensors/interpreters/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "060d518f-014c-447e-a832-c5a17a5f9f86",
        "id": "FB-hQqUuj2lt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd PySyft/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/PySyft\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8e38e946-9ca8-4592-f2f7-3813f417f155",
        "id": "4fFN0xmij2ly",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11524
        }
      },
      "source": [
        "! python3 setup.py install"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating syft.egg-info\n",
            "writing syft.egg-info/PKG-INFO\n",
            "writing dependency_links to syft.egg-info/dependency_links.txt\n",
            "writing requirements to syft.egg-info/requires.txt\n",
            "writing top-level names to syft.egg-info/top_level.txt\n",
            "writing manifest file 'syft.egg-info/SOURCES.txt'\n",
            "writing manifest file 'syft.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/syft\n",
            "copying syft/grid.py -> build/lib/syft\n",
            "copying syft/codes.py -> build/lib/syft\n",
            "copying syft/__init__.py -> build/lib/syft\n",
            "copying syft/exceptions.py -> build/lib/syft\n",
            "creating build/lib/test\n",
            "copying test/test_grid.py -> build/lib/test\n",
            "copying test/test_local_worker.py -> build/lib/test\n",
            "copying test/test_serde.py -> build/lib/test\n",
            "copying test/test_udacity.py -> build/lib/test\n",
            "copying test/__init__.py -> build/lib/test\n",
            "copying test/conftest.py -> build/lib/test\n",
            "copying test/test_exceptions.py -> build/lib/test\n",
            "copying test/test_sandbox.py -> build/lib/test\n",
            "creating build/lib/syft/workers\n",
            "copying syft/workers/base.py -> build/lib/syft/workers\n",
            "copying syft/workers/__init__.py -> build/lib/syft/workers\n",
            "copying syft/workers/abstract.py -> build/lib/syft/workers\n",
            "copying syft/workers/websocket_client.py -> build/lib/syft/workers\n",
            "copying syft/workers/websocket_server.py -> build/lib/syft/workers\n",
            "copying syft/workers/virtual.py -> build/lib/syft/workers\n",
            "copying syft/workers/tfe.py -> build/lib/syft/workers\n",
            "creating build/lib/syft/generic\n",
            "copying syft/generic/__init__.py -> build/lib/syft/generic\n",
            "copying syft/generic/id_provider.py -> build/lib/syft/generic\n",
            "copying syft/generic/object_storage.py -> build/lib/syft/generic\n",
            "creating build/lib/syft/frameworks\n",
            "copying syft/frameworks/__init__.py -> build/lib/syft/frameworks\n",
            "creating build/lib/syft/serde\n",
            "copying syft/serde/serde.py -> build/lib/syft/serde\n",
            "copying syft/serde/torch_serde.py -> build/lib/syft/serde\n",
            "copying syft/serde/__init__.py -> build/lib/syft/serde\n",
            "copying syft/serde/native_serde.py -> build/lib/syft/serde\n",
            "creating build/lib/syft/federated\n",
            "copying syft/federated/__init__.py -> build/lib/syft/federated\n",
            "copying syft/federated/train_config.py -> build/lib/syft/federated\n",
            "copying syft/federated/plan.py -> build/lib/syft/federated\n",
            "copying syft/federated/federated_client.py -> build/lib/syft/federated\n",
            "creating build/lib/syft/frameworks/keras\n",
            "copying syft/frameworks/keras/__init__.py -> build/lib/syft/frameworks/keras\n",
            "copying syft/frameworks/keras/hook.py -> build/lib/syft/frameworks/keras\n",
            "creating build/lib/syft/frameworks/torch\n",
            "copying syft/frameworks/torch/overload_torch.py -> build/lib/syft/frameworks/torch\n",
            "copying syft/frameworks/torch/torch_attributes.py -> build/lib/syft/frameworks/torch\n",
            "copying syft/frameworks/torch/functions.py -> build/lib/syft/frameworks/torch\n",
            "copying syft/frameworks/torch/__init__.py -> build/lib/syft/frameworks/torch\n",
            "creating build/lib/syft/frameworks/keras/model\n",
            "copying syft/frameworks/keras/model/sequential.py -> build/lib/syft/frameworks/keras/model\n",
            "copying syft/frameworks/keras/model/__init__.py -> build/lib/syft/frameworks/keras/model\n",
            "creating build/lib/syft/frameworks/keras/layers\n",
            "copying syft/frameworks/keras/layers/constructor.py -> build/lib/syft/frameworks/keras/layers\n",
            "copying syft/frameworks/keras/layers/__init__.py -> build/lib/syft/frameworks/keras/layers\n",
            "creating build/lib/syft/frameworks/torch/crypto\n",
            "copying syft/frameworks/torch/crypto/__init__.py -> build/lib/syft/frameworks/torch/crypto\n",
            "copying syft/frameworks/torch/crypto/spdz.py -> build/lib/syft/frameworks/torch/crypto\n",
            "copying syft/frameworks/torch/crypto/securenn.py -> build/lib/syft/frameworks/torch/crypto\n",
            "creating build/lib/syft/frameworks/torch/pointers\n",
            "copying syft/frameworks/torch/pointers/object_wrapper.py -> build/lib/syft/frameworks/torch/pointers\n",
            "copying syft/frameworks/torch/pointers/pointer_tensor.py -> build/lib/syft/frameworks/torch/pointers\n",
            "copying syft/frameworks/torch/pointers/__init__.py -> build/lib/syft/frameworks/torch/pointers\n",
            "copying syft/frameworks/torch/pointers/object_pointer.py -> build/lib/syft/frameworks/torch/pointers\n",
            "copying syft/frameworks/torch/pointers/callable_pointer.py -> build/lib/syft/frameworks/torch/pointers\n",
            "creating build/lib/syft/frameworks/torch/hook\n",
            "copying syft/frameworks/torch/hook/__init__.py -> build/lib/syft/frameworks/torch/hook\n",
            "copying syft/frameworks/torch/hook/hook.py -> build/lib/syft/frameworks/torch/hook\n",
            "copying syft/frameworks/torch/hook/hook_args.py -> build/lib/syft/frameworks/torch/hook\n",
            "creating build/lib/syft/frameworks/torch/tensors\n",
            "copying syft/frameworks/torch/tensors/__init__.py -> build/lib/syft/frameworks/torch/tensors\n",
            "creating build/lib/syft/frameworks/torch/federated\n",
            "copying syft/frameworks/torch/federated/__init__.py -> build/lib/syft/frameworks/torch/federated\n",
            "copying syft/frameworks/torch/federated/utils.py -> build/lib/syft/frameworks/torch/federated\n",
            "copying syft/frameworks/torch/federated/dataloader.py -> build/lib/syft/frameworks/torch/federated\n",
            "copying syft/frameworks/torch/federated/dataset.py -> build/lib/syft/frameworks/torch/federated\n",
            "creating build/lib/syft/frameworks/torch/differential_privacy\n",
            "copying syft/frameworks/torch/differential_privacy/__init__.py -> build/lib/syft/frameworks/torch/differential_privacy\n",
            "copying syft/frameworks/torch/differential_privacy/pate.py -> build/lib/syft/frameworks/torch/differential_privacy\n",
            "creating build/lib/syft/frameworks/torch/tensors/decorators\n",
            "copying syft/frameworks/torch/tensors/decorators/__init__.py -> build/lib/syft/frameworks/torch/tensors/decorators\n",
            "copying syft/frameworks/torch/tensors/decorators/logging.py -> build/lib/syft/frameworks/torch/tensors/decorators\n",
            "creating build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/gradients.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/native.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/additive_shared.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/__init__.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/polynomial.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/multi_pointer.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/abstract.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/gradients_core.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/build_gradients.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/autograd.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/plusisminus.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/precision.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "creating build/lib/test/workers\n",
            "copying test/workers/__init__.py -> build/lib/test/workers\n",
            "copying test/workers/test_websocket_worker.py -> build/lib/test/workers\n",
            "copying test/workers/test_base.py -> build/lib/test/workers\n",
            "copying test/workers/test_worker.py -> build/lib/test/workers\n",
            "copying test/workers/test_virtual.py -> build/lib/test/workers\n",
            "creating build/lib/test/torch\n",
            "copying test/torch/__init__.py -> build/lib/test/torch\n",
            "copying test/torch/test_functions.py -> build/lib/test/torch\n",
            "copying test/torch/test_hook.py -> build/lib/test/torch\n",
            "copying test/torch/test_federated_learning.py -> build/lib/test/torch\n",
            "creating build/lib/test/generic\n",
            "copying test/generic/__init__.py -> build/lib/test/generic\n",
            "copying test/generic/test_id_provider.py -> build/lib/test/generic\n",
            "creating build/lib/test/federated\n",
            "copying test/federated/test_train_config.py -> build/lib/test/federated\n",
            "copying test/federated/test_federated_client.py -> build/lib/test/federated\n",
            "copying test/federated/__init__.py -> build/lib/test/federated\n",
            "copying test/federated/test_plan.py -> build/lib/test/federated\n",
            "creating build/lib/test/torch/crypto\n",
            "copying test/torch/crypto/__init__.py -> build/lib/test/torch/crypto\n",
            "copying test/torch/crypto/test_snn.py -> build/lib/test/torch/crypto\n",
            "creating build/lib/test/torch/pointers\n",
            "copying test/torch/pointers/test_callable_pointer.py -> build/lib/test/torch/pointers\n",
            "copying test/torch/pointers/test_pointer_tensor.py -> build/lib/test/torch/pointers\n",
            "copying test/torch/pointers/__init__.py -> build/lib/test/torch/pointers\n",
            "creating build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_logging.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_gc.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_multi_pointer.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/__init__.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_autograd.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_parameter.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_additive_shared.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_polynomial.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_native.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_precision.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_tensor.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_variable.py -> build/lib/test/torch/tensors\n",
            "creating build/lib/test/torch/federated\n",
            "copying test/torch/federated/__init__.py -> build/lib/test/torch/federated\n",
            "copying test/torch/federated/test_dataset.py -> build/lib/test/torch/federated\n",
            "copying test/torch/federated/test_dataloader.py -> build/lib/test/torch/federated\n",
            "copying test/torch/federated/test_utils.py -> build/lib/test/torch/federated\n",
            "creating build/lib/test/torch/differential_privacy\n",
            "copying test/torch/differential_privacy/__init__.py -> build/lib/test/torch/differential_privacy\n",
            "copying test/torch/differential_privacy/test_pate.py -> build/lib/test/torch/differential_privacy\n",
            "creating build/lib/test/keras\n",
            "copying test/keras/test_sequential.py -> build/lib/test/keras\n",
            "copying syft/frameworks/keras/README.md -> build/lib/syft/frameworks/keras\n",
            "copying syft/frameworks/torch/tensors/interpreters/derivatives.yaml -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/syft\n",
            "copying build/lib/syft/grid.py -> build/bdist.linux-x86_64/egg/syft\n",
            "copying build/lib/syft/codes.py -> build/bdist.linux-x86_64/egg/syft\n",
            "creating build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/base.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/__init__.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/abstract.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/websocket_client.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/websocket_server.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/virtual.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/tfe.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/__init__.py -> build/bdist.linux-x86_64/egg/syft\n",
            "copying build/lib/syft/exceptions.py -> build/bdist.linux-x86_64/egg/syft\n",
            "creating build/bdist.linux-x86_64/egg/syft/generic\n",
            "copying build/lib/syft/generic/__init__.py -> build/bdist.linux-x86_64/egg/syft/generic\n",
            "copying build/lib/syft/generic/id_provider.py -> build/bdist.linux-x86_64/egg/syft/generic\n",
            "copying build/lib/syft/generic/object_storage.py -> build/bdist.linux-x86_64/egg/syft/generic\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/keras\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/keras/model\n",
            "copying build/lib/syft/frameworks/keras/model/sequential.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras/model\n",
            "copying build/lib/syft/frameworks/keras/model/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras/model\n",
            "copying build/lib/syft/frameworks/keras/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras\n",
            "copying build/lib/syft/frameworks/keras/hook.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras\n",
            "copying build/lib/syft/frameworks/keras/README.md -> build/bdist.linux-x86_64/egg/syft/frameworks/keras\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/keras/layers\n",
            "copying build/lib/syft/frameworks/keras/layers/constructor.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras/layers\n",
            "copying build/lib/syft/frameworks/keras/layers/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras/layers\n",
            "copying build/lib/syft/frameworks/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch\n",
            "copying build/lib/syft/frameworks/torch/overload_torch.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch\n",
            "copying build/lib/syft/frameworks/torch/torch_attributes.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch\n",
            "copying build/lib/syft/frameworks/torch/functions.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch\n",
            "copying build/lib/syft/frameworks/torch/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto\n",
            "copying build/lib/syft/frameworks/torch/crypto/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto\n",
            "copying build/lib/syft/frameworks/torch/crypto/spdz.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto\n",
            "copying build/lib/syft/frameworks/torch/crypto/securenn.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/pointers/object_wrapper.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/pointers/pointer_tensor.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/pointers/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/pointers/object_pointer.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/pointers/callable_pointer.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook\n",
            "copying build/lib/syft/frameworks/torch/hook/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook\n",
            "copying build/lib/syft/frameworks/torch/hook/hook.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook\n",
            "copying build/lib/syft/frameworks/torch/hook/hook_args.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/decorators\n",
            "copying build/lib/syft/frameworks/torch/tensors/decorators/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/decorators\n",
            "copying build/lib/syft/frameworks/torch/tensors/decorators/logging.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/decorators\n",
            "copying build/lib/syft/frameworks/torch/tensors/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/gradients.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/native.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/additive_shared.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/polynomial.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/multi_pointer.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/abstract.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/gradients_core.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/derivatives.yaml -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/build_gradients.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/autograd.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/plusisminus.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/precision.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated\n",
            "copying build/lib/syft/frameworks/torch/federated/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated\n",
            "copying build/lib/syft/frameworks/torch/federated/utils.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated\n",
            "copying build/lib/syft/frameworks/torch/federated/dataloader.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated\n",
            "copying build/lib/syft/frameworks/torch/federated/dataset.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/differential_privacy\n",
            "copying build/lib/syft/frameworks/torch/differential_privacy/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/differential_privacy\n",
            "copying build/lib/syft/frameworks/torch/differential_privacy/pate.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/differential_privacy\n",
            "creating build/bdist.linux-x86_64/egg/syft/serde\n",
            "copying build/lib/syft/serde/serde.py -> build/bdist.linux-x86_64/egg/syft/serde\n",
            "copying build/lib/syft/serde/torch_serde.py -> build/bdist.linux-x86_64/egg/syft/serde\n",
            "copying build/lib/syft/serde/__init__.py -> build/bdist.linux-x86_64/egg/syft/serde\n",
            "copying build/lib/syft/serde/native_serde.py -> build/bdist.linux-x86_64/egg/syft/serde\n",
            "creating build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/federated/__init__.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/federated/train_config.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/federated/plan.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/federated/federated_client.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "creating build/bdist.linux-x86_64/egg/test\n",
            "creating build/bdist.linux-x86_64/egg/test/keras\n",
            "copying build/lib/test/keras/test_sequential.py -> build/bdist.linux-x86_64/egg/test/keras\n",
            "copying build/lib/test/test_grid.py -> build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/test_local_worker.py -> build/bdist.linux-x86_64/egg/test\n",
            "creating build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/workers/__init__.py -> build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/workers/test_websocket_worker.py -> build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/workers/test_base.py -> build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/workers/test_worker.py -> build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/workers/test_virtual.py -> build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/test_serde.py -> build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/test_udacity.py -> build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/__init__.py -> build/bdist.linux-x86_64/egg/test\n",
            "creating build/bdist.linux-x86_64/egg/test/torch\n",
            "copying build/lib/test/torch/__init__.py -> build/bdist.linux-x86_64/egg/test/torch\n",
            "creating build/bdist.linux-x86_64/egg/test/torch/crypto\n",
            "copying build/lib/test/torch/crypto/__init__.py -> build/bdist.linux-x86_64/egg/test/torch/crypto\n",
            "copying build/lib/test/torch/crypto/test_snn.py -> build/bdist.linux-x86_64/egg/test/torch/crypto\n",
            "creating build/bdist.linux-x86_64/egg/test/torch/pointers\n",
            "copying build/lib/test/torch/pointers/test_callable_pointer.py -> build/bdist.linux-x86_64/egg/test/torch/pointers\n",
            "copying build/lib/test/torch/pointers/test_pointer_tensor.py -> build/bdist.linux-x86_64/egg/test/torch/pointers\n",
            "copying build/lib/test/torch/pointers/__init__.py -> build/bdist.linux-x86_64/egg/test/torch/pointers\n",
            "copying build/lib/test/torch/test_functions.py -> build/bdist.linux-x86_64/egg/test/torch\n",
            "copying build/lib/test/torch/test_hook.py -> build/bdist.linux-x86_64/egg/test/torch\n",
            "creating build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_logging.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_gc.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_multi_pointer.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/__init__.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_autograd.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_parameter.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_additive_shared.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_polynomial.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_native.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_precision.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_tensor.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_variable.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/test_federated_learning.py -> build/bdist.linux-x86_64/egg/test/torch\n",
            "creating build/bdist.linux-x86_64/egg/test/torch/federated\n",
            "copying build/lib/test/torch/federated/__init__.py -> build/bdist.linux-x86_64/egg/test/torch/federated\n",
            "copying build/lib/test/torch/federated/test_dataset.py -> build/bdist.linux-x86_64/egg/test/torch/federated\n",
            "copying build/lib/test/torch/federated/test_dataloader.py -> build/bdist.linux-x86_64/egg/test/torch/federated\n",
            "copying build/lib/test/torch/federated/test_utils.py -> build/bdist.linux-x86_64/egg/test/torch/federated\n",
            "creating build/bdist.linux-x86_64/egg/test/torch/differential_privacy\n",
            "copying build/lib/test/torch/differential_privacy/__init__.py -> build/bdist.linux-x86_64/egg/test/torch/differential_privacy\n",
            "copying build/lib/test/torch/differential_privacy/test_pate.py -> build/bdist.linux-x86_64/egg/test/torch/differential_privacy\n",
            "copying build/lib/test/conftest.py -> build/bdist.linux-x86_64/egg/test\n",
            "creating build/bdist.linux-x86_64/egg/test/generic\n",
            "copying build/lib/test/generic/__init__.py -> build/bdist.linux-x86_64/egg/test/generic\n",
            "copying build/lib/test/generic/test_id_provider.py -> build/bdist.linux-x86_64/egg/test/generic\n",
            "copying build/lib/test/test_exceptions.py -> build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/test_sandbox.py -> build/bdist.linux-x86_64/egg/test\n",
            "creating build/bdist.linux-x86_64/egg/test/federated\n",
            "copying build/lib/test/federated/test_train_config.py -> build/bdist.linux-x86_64/egg/test/federated\n",
            "copying build/lib/test/federated/test_federated_client.py -> build/bdist.linux-x86_64/egg/test/federated\n",
            "copying build/lib/test/federated/__init__.py -> build/bdist.linux-x86_64/egg/test/federated\n",
            "copying build/lib/test/federated/test_plan.py -> build/bdist.linux-x86_64/egg/test/federated\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid.py to grid.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/codes.py to codes.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/base.py to base.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/abstract.py to abstract.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/websocket_client.py to websocket_client.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/websocket_server.py to websocket_server.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/virtual.py to virtual.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/tfe.py to tfe.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/exceptions.py to exceptions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/generic/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/generic/id_provider.py to id_provider.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/generic/object_storage.py to object_storage.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/model/sequential.py to sequential.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/model/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/hook.py to hook.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/layers/constructor.py to constructor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/layers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/overload_torch.py to overload_torch.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/torch_attributes.py to torch_attributes.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/functions.py to functions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto/spdz.py to spdz.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto/securenn.py to securenn.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers/object_wrapper.py to object_wrapper.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers/pointer_tensor.py to pointer_tensor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers/object_pointer.py to object_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers/callable_pointer.py to callable_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook/hook.py to hook.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook/hook_args.py to hook_args.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/decorators/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/decorators/logging.py to logging.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/gradients.py to gradients.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/native.py to native.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/additive_shared.py to additive_shared.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/polynomial.py to polynomial.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/multi_pointer.py to multi_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/abstract.py to abstract.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/gradients_core.py to gradients_core.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/build_gradients.py to build_gradients.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/autograd.py to autograd.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/plusisminus.py to plusisminus.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/precision.py to precision.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated/utils.py to utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated/dataloader.py to dataloader.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated/dataset.py to dataset.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/differential_privacy/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/differential_privacy/pate.py to pate.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/serde/serde.py to serde.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/serde/torch_serde.py to torch_serde.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/serde/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/serde/native_serde.py to native_serde.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/train_config.py to train_config.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/plan.py to plan.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/federated_client.py to federated_client.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/keras/test_sequential.py to test_sequential.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_grid.py to test_grid.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_local_worker.py to test_local_worker.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/workers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/workers/test_websocket_worker.py to test_websocket_worker.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/workers/test_base.py to test_base.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/workers/test_worker.py to test_worker.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/workers/test_virtual.py to test_virtual.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_serde.py to test_serde.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_udacity.py to test_udacity.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/crypto/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/crypto/test_snn.py to test_snn.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/pointers/test_callable_pointer.py to test_callable_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/pointers/test_pointer_tensor.py to test_pointer_tensor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/pointers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/test_functions.py to test_functions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/test_hook.py to test_hook.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_logging.py to test_logging.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_gc.py to test_gc.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_multi_pointer.py to test_multi_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_autograd.py to test_autograd.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_parameter.py to test_parameter.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_additive_shared.py to test_additive_shared.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_polynomial.py to test_polynomial.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_native.py to test_native.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_precision.py to test_precision.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_tensor.py to test_tensor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_variable.py to test_variable.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/test_federated_learning.py to test_federated_learning.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/federated/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/federated/test_dataset.py to test_dataset.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/federated/test_dataloader.py to test_dataloader.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/federated/test_utils.py to test_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/differential_privacy/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/differential_privacy/test_pate.py to test_pate.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/conftest.py to conftest.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/generic/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/generic/test_id_provider.py to test_id_provider.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_exceptions.py to test_exceptions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_sandbox.py to test_sandbox.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/federated/test_train_config.py to test_train_config.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/federated/test_federated_client.py to test_federated_client.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/federated/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/federated/test_plan.py to test_plan.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syft.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syft.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syft.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syft.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syft.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/syft-0.1.19a1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing syft-0.1.19a1-py3.6.egg\n",
            "Copying syft-0.1.19a1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding syft 0.1.19a1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/syft-0.1.19a1-py3.6.egg\n",
            "Processing dependencies for syft==0.1.19a1\n",
            "Searching for zstd==1.4.0.0\n",
            "Best match: zstd 1.4.0.0\n",
            "Adding zstd 1.4.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for websockets==7.0\n",
            "Best match: websockets 7.0\n",
            "Adding websockets 7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for websocket-client==0.56.0\n",
            "Best match: websocket-client 0.56.0\n",
            "Adding websocket-client 0.56.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for torchvision==0.3.0\n",
            "Best match: torchvision 0.3.0\n",
            "Adding torchvision 0.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for torch==1.1.0\n",
            "Best match: torch 1.1.0\n",
            "Adding torch 1.1.0 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tf-encrypted==0.5.6\n",
            "Best match: tf-encrypted 0.5.6\n",
            "Adding tf-encrypted 0.5.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tblib==1.4.0\n",
            "Best match: tblib 1.4.0\n",
            "Adding tblib 1.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scikit-learn==0.21.2\n",
            "Best match: scikit-learn 0.21.2\n",
            "Adding scikit-learn 0.21.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.16.4\n",
            "Best match: numpy 1.16.4\n",
            "Adding numpy 1.16.4 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for msgpack==0.6.1\n",
            "Best match: msgpack 0.6.1\n",
            "Adding msgpack 0.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for lz4==2.1.10\n",
            "Best match: lz4 2.1.10\n",
            "Adding lz4 2.1.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Flask-SocketIO==4.1.0\n",
            "Best match: Flask-SocketIO 4.1.0\n",
            "Adding Flask-SocketIO 4.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Flask==1.0.3\n",
            "Best match: Flask 1.0.3\n",
            "Adding Flask 1.0.3 to easy-install.pth file\n",
            "Installing flask script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.12.0\n",
            "Best match: six 1.12.0\n",
            "Adding six 1.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Pillow==4.3.0\n",
            "Best match: Pillow 4.3.0\n",
            "Adding Pillow 4.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for PyYAML==5.1.1\n",
            "Best match: PyYAML 5.1.1\n",
            "Adding PyYAML 5.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorflow==1.14.0\n",
            "Best match: tensorflow 1.14.0\n",
            "Adding tensorflow 1.14.0 to easy-install.pth file\n",
            "Installing freeze_graph script to /usr/local/bin\n",
            "Installing saved_model_cli script to /usr/local/bin\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "Installing tf_upgrade_v2 script to /usr/local/bin\n",
            "Installing tflite_convert script to /usr/local/bin\n",
            "Installing toco script to /usr/local/bin\n",
            "Installing toco_from_protos script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for joblib==0.13.2\n",
            "Best match: joblib 0.13.2\n",
            "Adding joblib 0.13.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scipy==1.3.0\n",
            "Best match: scipy 1.3.0\n",
            "Adding scipy 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for python-socketio==4.2.0\n",
            "Best match: python-socketio 4.2.0\n",
            "Adding python-socketio 4.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for itsdangerous==1.1.0\n",
            "Best match: itsdangerous 1.1.0\n",
            "Adding itsdangerous 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Jinja2==2.10.1\n",
            "Best match: Jinja2 2.10.1\n",
            "Adding Jinja2 2.10.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Werkzeug==0.15.4\n",
            "Best match: Werkzeug 0.15.4\n",
            "Adding Werkzeug 0.15.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Click==7.0\n",
            "Best match: Click 7.0\n",
            "Adding Click 7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for olefile==0.46\n",
            "Best match: olefile 0.46\n",
            "Adding olefile 0.46 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for wheel==0.33.4\n",
            "Best match: wheel 0.33.4\n",
            "Adding wheel 0.33.4 to easy-install.pth file\n",
            "Installing wheel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for astor==0.8.0\n",
            "Best match: astor 0.8.0\n",
            "Adding astor 0.8.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Keras-Applications==1.0.8\n",
            "Best match: Keras-Applications 1.0.8\n",
            "Adding Keras-Applications 1.0.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for grpcio==1.15.0\n",
            "Best match: grpcio 1.15.0\n",
            "Adding grpcio 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for protobuf==3.7.1\n",
            "Best match: protobuf 3.7.1\n",
            "Adding protobuf 3.7.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for wrapt==1.11.2\n",
            "Best match: wrapt 1.11.2\n",
            "Adding wrapt 1.11.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Keras-Preprocessing==1.1.0\n",
            "Best match: Keras-Preprocessing 1.1.0\n",
            "Adding Keras-Preprocessing 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorboard==1.14.0\n",
            "Best match: tensorboard 1.14.0\n",
            "Adding tensorboard 1.14.0 to easy-install.pth file\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for absl-py==0.7.1\n",
            "Best match: absl-py 0.7.1\n",
            "Adding absl-py 0.7.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for gast==0.2.2\n",
            "Best match: gast 0.2.2\n",
            "Adding gast 0.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for google-pasta==0.1.7\n",
            "Best match: google-pasta 0.1.7\n",
            "Adding google-pasta 0.1.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorflow-estimator==1.14.0\n",
            "Best match: tensorflow-estimator 1.14.0\n",
            "Adding tensorflow-estimator 1.14.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for termcolor==1.1.0\n",
            "Best match: termcolor 1.1.0\n",
            "Adding termcolor 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for python-engineio==3.8.2\n",
            "Best match: python-engineio 3.8.2\n",
            "Adding python-engineio 3.8.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for MarkupSafe==1.1.1\n",
            "Best match: MarkupSafe 1.1.1\n",
            "Adding MarkupSafe 1.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for h5py==2.8.0\n",
            "Best match: h5py 2.8.0\n",
            "Adding h5py 2.8.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for setuptools==41.0.1\n",
            "Best match: setuptools 41.0.1\n",
            "Adding setuptools 41.0.1 to easy-install.pth file\n",
            "Installing easy_install script to /usr/local/bin\n",
            "Installing easy_install-3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Markdown==3.1.1\n",
            "Best match: Markdown 3.1.1\n",
            "Adding Markdown 3.1.1 to easy-install.pth file\n",
            "Installing markdown_py script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for syft==0.1.19a1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e99d362c-109b-4af1-8aa4-9157e4098319",
        "id": "Pzr9WhVQj2l6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "! git clone https://github.com/tf-encrypted/tf-encrypted"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tf-encrypted'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/60)   \u001b[K\rremote: Counting objects:   3% (2/60)   \u001b[K\rremote: Counting objects:   5% (3/60)   \u001b[K\rremote: Counting objects:   6% (4/60)   \u001b[K\rremote: Counting objects:   8% (5/60)   \u001b[K\rremote: Counting objects:  10% (6/60)   \u001b[K\rremote: Counting objects:  11% (7/60)   \u001b[K\rremote: Counting objects:  13% (8/60)   \u001b[K\rremote: Counting objects:  15% (9/60)   \u001b[K\rremote: Counting objects:  16% (10/60)   \u001b[K\rremote: Counting objects:  18% (11/60)   \u001b[K\rremote: Counting objects:  20% (12/60)   \u001b[K\rremote: Counting objects:  21% (13/60)   \u001b[K\rremote: Counting objects:  23% (14/60)   \u001b[K\rremote: Counting objects:  25% (15/60)   \u001b[K\rremote: Counting objects:  26% (16/60)   \u001b[K\rremote: Counting objects:  28% (17/60)   \u001b[K\rremote: Counting objects:  30% (18/60)   \u001b[K\rremote: Counting objects:  31% (19/60)   \u001b[K\rremote: Counting objects:  33% (20/60)   \u001b[K\rremote: Counting objects:  35% (21/60)   \u001b[K\rremote: Counting objects:  36% (22/60)   \u001b[K\rremote: Counting objects:  38% (23/60)   \u001b[K\rremote: Counting objects:  40% (24/60)   \u001b[K\rremote: Counting objects:  41% (25/60)   \u001b[K\rremote: Counting objects:  43% (26/60)   \u001b[K\rremote: Counting objects:  45% (27/60)   \u001b[K\rremote: Counting objects:  46% (28/60)   \u001b[K\rremote: Counting objects:  48% (29/60)   \u001b[K\rremote: Counting objects:  50% (30/60)   \u001b[K\rremote: Counting objects:  51% (31/60)   \u001b[K\rremote: Counting objects:  53% (32/60)   \u001b[K\rremote: Counting objects:  55% (33/60)   \u001b[K\rremote: Counting objects:  56% (34/60)   \u001b[K\rremote: Counting objects:  58% (35/60)   \u001b[K\rremote: Counting objects:  60% (36/60)   \u001b[K\rremote: Counting objects:  61% (37/60)   \u001b[K\rremote: Counting objects:  63% (38/60)   \u001b[K\rremote: Counting objects:  65% (39/60)   \u001b[K\rremote: Counting objects:  66% (40/60)   \u001b[K\rremote: Counting objects:  68% (41/60)   \u001b[K\rremote: Counting objects:  70% (42/60)   \u001b[K\rremote: Counting objects:  71% (43/60)   \u001b[K\rremote: Counting objects:  73% (44/60)   \u001b[K\rremote: Counting objects:  75% (45/60)   \u001b[K\rremote: Counting objects:  76% (46/60)   \u001b[K\rremote: Counting objects:  78% (47/60)   \u001b[K\rremote: Counting objects:  80% (48/60)   \u001b[K\rremote: Counting objects:  81% (49/60)   \u001b[K\rremote: Counting objects:  83% (50/60)   \u001b[K\rremote: Counting objects:  85% (51/60)   \u001b[K\rremote: Counting objects:  86% (52/60)   \u001b[K\rremote: Counting objects:  88% (53/60)   \u001b[K\rremote: Counting objects:  90% (54/60)   \u001b[K\rremote: Counting objects:  91% (55/60)   \u001b[K\rremote: Counting objects:  93% (56/60)   \u001b[K\rremote: Counting objects:  95% (57/60)   \u001b[K\rremote: Counting objects:  96% (58/60)   \u001b[K\rremote: Counting objects:  98% (59/60)   \u001b[K\rremote: Counting objects: 100% (60/60)   \u001b[K\rremote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects:   2% (1/39)   \u001b[K\rremote: Compressing objects:   5% (2/39)   \u001b[K\rremote: Compressing objects:   7% (3/39)   \u001b[K\rremote: Compressing objects:  10% (4/39)   \u001b[K\rremote: Compressing objects:  12% (5/39)   \u001b[K\rremote: Compressing objects:  15% (6/39)   \u001b[K\rremote: Compressing objects:  17% (7/39)   \u001b[K\rremote: Compressing objects:  20% (8/39)   \u001b[K\rremote: Compressing objects:  23% (9/39)   \u001b[K\rremote: Compressing objects:  25% (10/39)   \u001b[K\rremote: Compressing objects:  28% (11/39)   \u001b[K\rremote: Compressing objects:  30% (12/39)   \u001b[K\rremote: Compressing objects:  33% (13/39)   \u001b[K\rremote: Compressing objects:  35% (14/39)   \u001b[K\rremote: Compressing objects:  38% (15/39)   \u001b[K\rremote: Compressing objects:  41% (16/39)   \u001b[K\rremote: Compressing objects:  43% (17/39)   \u001b[K\rremote: Compressing objects:  46% (18/39)   \u001b[K\rremote: Compressing objects:  48% (19/39)   \u001b[K\rremote: Compressing objects:  51% (20/39)   \u001b[K\rremote: Compressing objects:  53% (21/39)   \u001b[K\rremote: Compressing objects:  56% (22/39)   \u001b[K\rremote: Compressing objects:  58% (23/39)   \u001b[K\rremote: Compressing objects:  61% (24/39)   \u001b[K\rremote: Compressing objects:  64% (25/39)   \u001b[K\rremote: Compressing objects:  66% (26/39)   \u001b[K\rremote: Compressing objects:  69% (27/39)   \u001b[K\rremote: Compressing objects:  71% (28/39)   \u001b[K\rremote: Compressing objects:  74% (29/39)   \u001b[K\rremote: Compressing objects:  76% (30/39)   \u001b[K\rremote: Compressing objects:  79% (31/39)   \u001b[K\rremote: Compressing objects:  82% (32/39)   \u001b[K\rremote: Compressing objects:  84% (33/39)   \u001b[K\rremote: Compressing objects:  87% (34/39)   \u001b[K\rremote: Compressing objects:  89% (35/39)   \u001b[K\rremote: Compressing objects:  92% (36/39)   \u001b[K\rremote: Compressing objects:  94% (37/39)   \u001b[K\rremote: Compressing objects:  97% (38/39)   \u001b[K\rremote: Compressing objects: 100% (39/39)   \u001b[K\rremote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "Receiving objects:   0% (1/5586)   \rReceiving objects:   1% (56/5586)   \rReceiving objects:   2% (112/5586)   \rReceiving objects:   3% (168/5586)   \rReceiving objects:   4% (224/5586)   \rReceiving objects:   5% (280/5586)   \rReceiving objects:   6% (336/5586)   \rReceiving objects:   7% (392/5586)   \rReceiving objects:   8% (447/5586)   \rReceiving objects:   9% (503/5586)   \rReceiving objects:  10% (559/5586)   \rReceiving objects:  11% (615/5586)   \rReceiving objects:  12% (671/5586)   \rReceiving objects:  13% (727/5586)   \rReceiving objects:  14% (783/5586)   \rReceiving objects:  15% (838/5586)   \rReceiving objects:  16% (894/5586)   \rReceiving objects:  17% (950/5586)   \rReceiving objects:  18% (1006/5586)   \rReceiving objects:  19% (1062/5586)   \rReceiving objects:  20% (1118/5586)   \rReceiving objects:  21% (1174/5586)   \rReceiving objects:  22% (1229/5586)   \rReceiving objects:  23% (1285/5586)   \rReceiving objects:  24% (1341/5586)   \rReceiving objects:  25% (1397/5586)   \rReceiving objects:  26% (1453/5586)   \rReceiving objects:  27% (1509/5586)   \rReceiving objects:  28% (1565/5586)   \rReceiving objects:  29% (1620/5586)   \rReceiving objects:  30% (1676/5586)   \rReceiving objects:  31% (1732/5586)   \rReceiving objects:  32% (1788/5586)   \rReceiving objects:  33% (1844/5586)   \rReceiving objects:  34% (1900/5586)   \rReceiving objects:  35% (1956/5586)   \rReceiving objects:  36% (2011/5586)   \rReceiving objects:  37% (2067/5586)   \rReceiving objects:  38% (2123/5586)   \rReceiving objects:  39% (2179/5586)   \rReceiving objects:  40% (2235/5586)   \rReceiving objects:  41% (2291/5586)   \rReceiving objects:  42% (2347/5586)   \rReceiving objects:  43% (2402/5586)   \rReceiving objects:  44% (2458/5586)   \rReceiving objects:  45% (2514/5586)   \rReceiving objects:  46% (2570/5586)   \rReceiving objects:  47% (2626/5586)   \rReceiving objects:  48% (2682/5586)   \rReceiving objects:  49% (2738/5586)   \rReceiving objects:  50% (2793/5586)   \rReceiving objects:  51% (2849/5586)   \rReceiving objects:  52% (2905/5586)   \rReceiving objects:  53% (2961/5586)   \rReceiving objects:  54% (3017/5586)   \rReceiving objects:  55% (3073/5586)   \rReceiving objects:  56% (3129/5586)   \rReceiving objects:  57% (3185/5586)   \rReceiving objects:  58% (3240/5586)   \rReceiving objects:  59% (3296/5586)   \rReceiving objects:  60% (3352/5586)   \rReceiving objects:  61% (3408/5586)   \rReceiving objects:  62% (3464/5586)   \rReceiving objects:  63% (3520/5586)   \rReceiving objects:  64% (3576/5586)   \rReceiving objects:  65% (3631/5586)   \rReceiving objects:  66% (3687/5586)   \rReceiving objects:  67% (3743/5586)   \rReceiving objects:  68% (3799/5586)   \rReceiving objects:  69% (3855/5586)   \rReceiving objects:  70% (3911/5586)   \rReceiving objects:  71% (3967/5586)   \rReceiving objects:  72% (4022/5586)   \rReceiving objects:  73% (4078/5586)   \rReceiving objects:  74% (4134/5586)   \rReceiving objects:  75% (4190/5586)   \rReceiving objects:  76% (4246/5586)   \rReceiving objects:  77% (4302/5586)   \rReceiving objects:  78% (4358/5586)   \rReceiving objects:  79% (4413/5586)   \rReceiving objects:  80% (4469/5586)   \rReceiving objects:  81% (4525/5586)   \rReceiving objects:  82% (4581/5586)   \rReceiving objects:  83% (4637/5586)   \rReceiving objects:  84% (4693/5586)   \rReceiving objects:  85% (4749/5586)   \rReceiving objects:  86% (4804/5586)   \rReceiving objects:  87% (4860/5586)   \rReceiving objects:  88% (4916/5586)   \rReceiving objects:  89% (4972/5586)   \rReceiving objects:  90% (5028/5586)   \rReceiving objects:  91% (5084/5586)   \rReceiving objects:  92% (5140/5586)   \rremote: Total 5586 (delta 34), reused 35 (delta 21), pack-reused 5526\u001b[K\n",
            "Receiving objects: 100% (5586/5586), 20.82 MiB | 45.95 MiB/s, done.\n",
            "Resolving deltas: 100% (3778/3778), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9492538d-4de1-4fd3-e917-276dbc7a0eb9",
        "id": "NoVgl8xOj2l9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd tf-encrypted/"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/PySyft/tf-encrypted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8AsODIO3whX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "f6714b11-584a-4d7c-b414-061c45a8e8c8"
      },
      "source": [
        "! git checkout 22e4ae8"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Note: checking out '22e4ae8'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at 22e4ae8 better exception handling of .so files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXlC3k6bwntG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1143
        },
        "outputId": "9ed52e46-8b2c-4f7a-c0f5-5f78e7045c87"
      },
      "source": [
        "! git show"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mcommit 22e4ae8f415926b8886a09f13279f905cec3443f\u001b[m\u001b[33m (\u001b[m\u001b[1;36mHEAD\u001b[m\u001b[33m)\u001b[m\n",
            "Author: Morten Dahl <mortendahlcs@gmail.com>\n",
            "Date:   Mon Jun 17 16:34:45 2019 +0200\n",
            "\n",
            "    better exception handling of .so files\n",
            "\n",
            "\u001b[1mdiff --git a/tf_encrypted/operations/secure_random/secure_random.py b/tf_encrypted/operations/secure_random/secure_random.py\u001b[m\n",
            "\u001b[1mindex 052951f..c9c66bf 100644\u001b[m\n",
            "\u001b[1m--- a/tf_encrypted/operations/secure_random/secure_random.py\u001b[m\n",
            "\u001b[1m+++ b/tf_encrypted/operations/secure_random/secure_random.py\u001b[m\n",
            "\u001b[36m@@ -9,19 +9,41 @@\u001b[m \u001b[mfrom tensorflow.python.framework.errors import NotFoundError\u001b[m\n",
            " import tf_encrypted as tfe\u001b[m\n",
            " \u001b[m\n",
            " logger = logging.getLogger('tf_encrypted')\u001b[m\n",
            "\u001b[31m-dirname = os.path.dirname(tfe.__file__)\u001b[m\n",
            "\u001b[31m-so_name = '{dn}/operations/secure_random/secure_random_module_tf_{tfv}.so'\u001b[m\n",
            "\u001b[31m-shared_object = so_name.format(dn=dirname, tfv=tf.__version__)\u001b[m\n",
            "\u001b[31m-\u001b[m\n",
            "\u001b[31m-try:\u001b[m\n",
            "\u001b[31m-  secure_random_module = tf.load_op_library(shared_object)\u001b[m\n",
            "\u001b[31m-except NotFoundError:\u001b[m\n",
            "\u001b[31m-  logger.warning(\u001b[m\n",
            "\u001b[31m-      (\"Falling back to insecure randomness since the required custom op \"\u001b[m\n",
            "\u001b[31m-       \"could not be found for the installed version of TensorFlow (%s). \"\u001b[m\n",
            "\u001b[31m-       \"Fix this by compiling custom ops.\"), tf.__version__)\u001b[m\n",
            "\u001b[31m-  secure_random_module = None\u001b[m\n",
            " \u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32mdef _try_load_secure_random_module():\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m  \"\"\"\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m  Attempt to load and return secure random module; returns None if failed.\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m  \"\"\"\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m  so_file = '{dn}/operations/secure_random/secure_random_module_tf_{tfv}.so'.format(  # pylint: disable=line-too-long\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m      dn=os.path.dirname(tfe.__file__),\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m      tfv=tf.__version__,\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m  )\u001b[m\n",
            "\u001b[32m+\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m  if not os.path.exists(so_file):\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m    logger.warning(\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m        (\"Falling back to insecure randomness since the required custom op \"\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m         \"could not be found for the installed version of TensorFlow. Fix this \"\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m         \"by compiling custom ops. Missing file was '%s'\"), so_file)\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m    return None\u001b[m\n",
            "\u001b[32m+\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m  try:\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m    return tf.load_op_library(so_file)\u001b[m\n",
            "\u001b[32m+\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m  except NotFoundError as ex:\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m    logger.warning(\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m        (\"Falling back to insecure randomness since the required custom op \"\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m         \"could not be found for the installed version of TensorFlow. Fix this \"\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m         \"by compiling custom ops. \"\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m         \"Missing file was '%s', error was \\\"%s\\\".\"), so_file, ex)\u001b[m\n",
            "\u001b[32m+\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m  except Exception as ex:  # pylint: disable=broad-except\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m    logger.error(\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m        (\"Falling back to insecure randomness since an error occurred loading \"\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m         \"the required custom op: \\\"%s\\\".\"), ex)\u001b[m\n",
            "\u001b[32m+\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32m  return None\u001b[m\n",
            "\u001b[32m+\u001b[m\n",
            "\u001b[32m+\u001b[m\u001b[32msecure_random_module = _try_load_secure_random_module()\u001b[m\n",
            " \u001b[m\n",
            " def supports_secure_randomness():\u001b[m\n",
            "   return secure_random_module is not None\u001b[m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c0b1b38c-3758-4ee1-e665-30365c6be22b",
        "id": "985PCpurj2mA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "! pip3 install -e ."
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/PySyft/tf-encrypted\n",
            "Requirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted==0.5.6) (1.14.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted==0.5.6) (1.16.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted==0.5.6) (5.1.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (3.7.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (0.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (0.1.7)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (0.33.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (0.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (1.11.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (41.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (0.15.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted==0.5.6) (3.1.1)\n",
            "Installing collected packages: tf-encrypted\n",
            "  Found existing installation: tf-encrypted 0.5.6\n",
            "    Uninstalling tf-encrypted-0.5.6:\n",
            "      Successfully uninstalled tf-encrypted-0.5.6\n",
            "  Running setup.py develop for tf-encrypted\n",
            "Successfully installed tf-encrypted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "497ac9fd-5f74-4f59-a2a1-8cb1380ce3b0",
        "id": "6NUPTOMij2mE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "import tf_encrypted as tfe"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0701 11:13:46.417343 140070989662080 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/content/PySyft/tf-encrypted/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0701 11:13:46.471324 140070989662080 deprecation_wrapper.py:119] From /content/PySyft/tf-encrypted/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "553bbfb3-c298-40ee-c93f-f98007780e72",
        "id": "V4FBzFoFj2mK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd .."
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/PySyft\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xmGwteE_GjW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1436
        },
        "outputId": "ddf1d907-95f0-4766-e759-210f8fd4355b"
      },
      "source": [
        "! pip install syft "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting syft\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/49/1262a301e9db38f4822fa9e0e3b15831c86af9eaeb43b2b0aea3d0c6e1a1/syft-0.1.22a1-py3-none-any.whl (249kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 3.5MB/s \n",
            "\u001b[?25hCollecting websocket-client>=0.56.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 50.9MB/s \n",
            "\u001b[?25hCollecting flask-socketio>=3.3.2 (from syft)\n",
            "  Downloading https://files.pythonhosted.org/packages/33/31/f779e69e59f528684d8c9925b3c82a9303d148655d9671ba2975ab8c3894/Flask_SocketIO-4.2.0-py2.py3-none-any.whl\n",
            "Collecting msgpack>=0.6.1 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/7e/ae9e91c1bb8d846efafd1f353476e3fd7309778b582d2fb4cea4cc15b9a2/msgpack-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 32.3MB/s \n",
            "\u001b[?25hCollecting zstd>=1.4.0.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/37/6a7ba746ebddbd6cd06de84367515d6bc239acd94fb3e0b1c85788176ca2/zstd-1.4.1.0.tar.gz (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 54.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Collecting websockets>=7.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/4b/ad228451b1c071c5c52616b7d4298ebcfcac5ae8515ede959db19e4cd56d/websockets-8.0.2-cp36-cp36m-manylinux1_x86_64.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 34.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.1)\n",
            "Collecting lz4>=2.1.6 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 59.9MB/s \n",
            "\u001b[?25hCollecting tf-encrypted!=0.5.7,>=0.5.4 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/ce/da9916e7e78f736894b15538b702c0b213fd5d60a7fd6e481d74033a90c0/tf_encrypted-0.5.6-py3-none-manylinux1_x86_64.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 51.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.21.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.16.4)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client>=0.56.0->syft) (1.12.0)\n",
            "Collecting python-socketio>=4.3.0 (from flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/5a/9429c1fbc399b6079725150a36491efd6bd4691c11110f5a57e8c991de96/python_socketio-4.3.0-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 26.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (0.15.5)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (2.10.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (7.0)\n",
            "Collecting pyyaml>=5.1 (from tf-encrypted!=0.5.7,>=0.5.4->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/e8/b3212641ee2718d556df0f23f78de8303f068fe29cdaa7a91018849582fe/PyYAML-5.1.2.tar.gz (265kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 59.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted!=0.5.7,>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (0.13.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (1.3.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (4.3.0)\n",
            "Collecting python-engineio>=3.9.0 (from python-socketio>=4.3.0->flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/ba/5a689b07d399cd91cd91875232a1af8a63f0bd2cd0d0898da295f127544e/python_engineio-3.9.2-py2.py3-none-any.whl (119kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 60.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=1.0.2->syft) (1.1.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (0.1.7)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (1.11.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (0.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->syft) (0.46)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (41.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted!=0.5.7,>=0.5.4->syft) (3.1.1)\n",
            "Building wheels for collected packages: zstd, pyyaml\n",
            "  Building wheel for zstd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for zstd: filename=zstd-1.4.1.0-cp36-cp36m-linux_x86_64.whl size=1067084 sha256=916c6bebdd1ac6e7c2525ae7f5805886cfbf0c78c5bac5a2fe9d35250cccf361\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/3f/ee/ac08c81af7c1b24a80c746df669ea3cb37542d27877d66ccf4\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1.2-cp36-cp36m-linux_x86_64.whl size=44105 sha256=76753dcb093a60fe45d89a397ca0eb658e3a803abb4c2f9533cccc41e1c56717\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/45/dd/65f0b38450c47cf7e5312883deb97d065e030c5cca0a365030\n",
            "Successfully built zstd pyyaml\n",
            "Installing collected packages: websocket-client, python-engineio, python-socketio, flask-socketio, msgpack, zstd, websockets, lz4, pyyaml, tf-encrypted, syft\n",
            "  Found existing installation: msgpack 0.5.6\n",
            "    Uninstalling msgpack-0.5.6:\n",
            "      Successfully uninstalled msgpack-0.5.6\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed flask-socketio-4.2.0 lz4-2.1.10 msgpack-0.6.1 python-engineio-3.9.2 python-socketio-4.3.0 pyyaml-5.1.2 syft-0.1.22a1 tf-encrypted-0.5.6 websocket-client-0.56.0 websockets-8.0.2 zstd-1.4.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7g2wkDaNrOp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "a365707a-08b7-4acf-98f8-e10c98d11d60"
      },
      "source": [
        "import syft as sy"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0805 18:15:28.740150 139975302981504 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0805 18:15:28.756932 139975302981504 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bZj0m86yj2mR",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bf8lEAs_j2mT",
        "colab": {}
      },
      "source": [
        "#import syft as sy  # <-- NEW: import the Pysyft library\n",
        "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")  # <-- NEW: define remote worker bob\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")  # <-- NEW: and alice"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XnJvLCKCyB5M"
      },
      "source": [
        "### SPLIT LEARNING GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hN1z3NwkyB5Q",
        "colab": {}
      },
      "source": [
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 64\n",
        "        self.test_batch_size = 1000\n",
        "        self.epochs = 10\n",
        "        self.lr = 0.01\n",
        "        self.momentum = 0.5\n",
        "        self.no_cuda = False\n",
        "        self.seed = 1\n",
        "        self.log_interval = 30\n",
        "        self.save_model = False\n",
        "\n",
        "args = Arguments()\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "if use_cuda:\n",
        "        # TODO Quickhack. Actually need to fix the problem moving the model to CUDA\\n\",\n",
        "        torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "#device = torch.device(\"cpu\")\n",
        "\n",
        "#kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "kwargs = {'num_workers': 0, 'pin_memory': False} if use_cuda else {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2c1937e7-564f-4dc4-a449-ef1967801424",
        "id": "nr4qqcG1yB5T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n",
        "    .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
        "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=args.test_batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9912422 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 21454938.40it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 327644.38it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 5276304.41it/s]                           \n",
            "8192it [00:00, 126739.13it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0805 18:16:39.846578 139975302981504 dataloader.py:197] The following options are not supported: num_workers: 0, pin_memory: False\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dFkulxZ3yB5b",
        "colab": {}
      },
      "source": [
        "class Net1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net1, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        return F.max_pool2d(x, 2, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6U2Vzkx-yB5l",
        "colab": {}
      },
      "source": [
        "class Net2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net2, self).__init__()\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K6n2NsCRyB5o",
        "colab": {}
      },
      "source": [
        "models = [Net1().to(device), Net1().to(device)]\n",
        "#models = [Net1(), Net1()]\n",
        "models[0] = models[0].send(bob)\n",
        "models[1] = models[1].send(alice)\n",
        "\n",
        "\n",
        "\n",
        "opt1 = optim.SGD(params=models[0].parameters(),lr=0.1)\n",
        "opt2 = optim.SGD(params=models[1].parameters(),lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JfT-Yg76yB5q",
        "colab": {}
      },
      "source": [
        "def train(args, model, device, federated_train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, targs) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
        "        #IF ON DATA LOCATION TO GET THE RIGHT MODEL\n",
        "        if data.location.id == 'bob':\n",
        "          mod_c,opt_c = models[0], opt1\n",
        "        else : \n",
        "          mod_c,opt_c = models[1], opt2\n",
        "          \n",
        "       # 1) erase previous gradients (if they exist)\n",
        "        optimizer.step()\n",
        "        opt_c.step()\n",
        "        opt_c.zero_grad()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        tg_copy = targs.copy()\n",
        "        target = tg_copy.get()\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        # 2) make a prediction until cut layer (client location)\n",
        "        pred_c = mod_c(data)\n",
        "        copy = pred_c.copy()\n",
        "        \n",
        "        # 3) get this to the server \n",
        "        inp = copy.get()\n",
        "\n",
        "        # 4) make prediction with second part of the model (server location)\n",
        "        print('memory:',inp.element_size() * inp.nelement())\n",
        "        pred = model(inp)\n",
        "\n",
        "        # 5) calculate how much we missed \n",
        "        loss = F.nll_loss(pred, target)\n",
        "        loss.backward()\n",
        "        \n",
        "        gradient = inp.grad\n",
        "        gradient = gradient.send(data.location)\n",
        "        print(\"memory2:\",gradient.element_size()*gradient.nelement())\n",
        "        #print(\"grad shape:\",gradient.shape)\n",
        "        #print(\"pred_c shape:\", pred_c.shape)\n",
        "        #gradient = gradient.view(pred_c.shape)\n",
        "        pred_c.backward(gradient)\n",
        "        \n",
        "        \n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            #loss = loss.get() # <-- NEW: get the loss back\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,\n",
        "                100. * batch_idx / len(federated_train_loader), loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y-vH1L2GyB5u",
        "colab": {}
      },
      "source": [
        "def test(args, model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    M1 = models[0].copy()\n",
        "    M2 = models[1].copy()\n",
        "    M1 = M1.get()\n",
        "    M2 = M2.get()\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(M1(data))\n",
        "            #output2 = model(M2(data))\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b7a91877-56c7-43b5-cf6f-91b2f0466520",
        "id": "O7rPLOU6yB5z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 20591
        }
      },
      "source": [
        "%%time\n",
        "model = Net2().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(args, model, device, federated_train_loader, optimizer, epoch)\n",
        "    test(args, model, device, test_loader)\n",
        "\n",
        "if (args.save_model):\n",
        "    torch.save(model.state_dict(), \"mnist_cnn.pt\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "memory: 737280\n",
            "memory2: 737280\n",
            "Train Epoch: 1 [0/60032 (0%)]\tLoss: 2.303194\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "Train Epoch: 1 [1920/60032 (3%)]\tLoss: 2.078506\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "Train Epoch: 1 [3840/60032 (6%)]\tLoss: 1.259486\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "Train Epoch: 1 [5760/60032 (10%)]\tLoss: 0.758909\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "Train Epoch: 1 [7680/60032 (13%)]\tLoss: 0.427306\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "Train Epoch: 1 [9600/60032 (16%)]\tLoss: 0.587750\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "Train Epoch: 1 [11520/60032 (19%)]\tLoss: 0.230708\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "Train Epoch: 1 [13440/60032 (22%)]\tLoss: 0.524272\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "Train Epoch: 1 [15360/60032 (26%)]\tLoss: 0.428650\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "Train Epoch: 1 [17280/60032 (29%)]\tLoss: 0.136508\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "Train Epoch: 1 [19200/60032 (32%)]\tLoss: 0.614463\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "Train Epoch: 1 [21120/60032 (35%)]\tLoss: 0.144826\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "Train Epoch: 1 [23040/60032 (38%)]\tLoss: 0.157424\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "Train Epoch: 1 [24960/60032 (42%)]\tLoss: 0.284133\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "Train Epoch: 1 [26880/60032 (45%)]\tLoss: 0.321567\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "Train Epoch: 1 [28800/60032 (48%)]\tLoss: 0.361882\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 552960\n",
            "memory2: 552960\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "Train Epoch: 1 [30720/60032 (51%)]\tLoss: 0.484095\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "Train Epoch: 1 [32640/60032 (54%)]\tLoss: 0.242376\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "Train Epoch: 1 [34560/60032 (58%)]\tLoss: 0.153495\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "Train Epoch: 1 [36480/60032 (61%)]\tLoss: 0.301547\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n",
            "memory2: 737280\n",
            "memory: 737280\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0325af6d78a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model = Net2().to(device)\\noptimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\\n\\nfor epoch in range(1, args.epochs + 1):\\n    train(args, model, device, federated_train_loader, optimizer, epoch)\\n    test(args, model, device, test_loader)\\n\\nif (args.save_model):\\n    torch.save(model.state_dict(), \"mnist_cnn.pt\")'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-5ca6d556789f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, device, federated_train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory2:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#print(\"grad shape:\",gradient.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, inplace, local_autograd, preinitialize_grad, no_wrap, garbage_collect_data, *location)\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0mlocal_autograd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_autograd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0mpreinitialize_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreinitialize_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m                 \u001b[0mgarbage_collect_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgarbage_collect_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m             )\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/workers/base.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, obj, workers, ptr_id, local_autograd, preinitialize_grad, garbage_collect_data)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mpointer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;31m# Send the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpointer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/workers/base.py\u001b[0m in \u001b[0;36msend_obj\u001b[0;34m(self, obj, location)\u001b[0m\n\u001b[1;32m    522\u001b[0m                 \u001b[0mreceive\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \"\"\"\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSGTYPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOBJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrequest_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"BaseWorker\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/workers/base.py\u001b[0m in \u001b[0;36msend_msg\u001b[0;34m(self, msg_type, message, location)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Step 1: serialize the message to simple python objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mbin_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;31m# Step 2: send the message and wait for a response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/serde/serde.py\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(obj, simplified, force_no_compression, force_no_serialization, force_full_simplification)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/serde/serde.py\u001b[0m in \u001b[0;36m_compress\u001b[0;34m(decompressed_input_bin)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \"\"\"\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0mcompress_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress_scheme\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_apply_compress_scheme\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecompressed_input_bin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscheme_to_bytes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompress_scheme\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcompress_stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/serde/serde.py\u001b[0m in \u001b[0;36m_apply_compress_scheme\u001b[0;34m(decompressed_input_bin)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mdecompressed_input_bin\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mcompressed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \"\"\"\n\u001b[0;32m--> 290\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply_lz4_compression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecompressed_input_bin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/syft/serde/serde.py\u001b[0m in \u001b[0;36mapply_lz4_compression\u001b[0;34m(decompressed_input_bin)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcompressed_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLZ4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \"\"\"\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlz4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecompressed_input_bin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLZ4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D40QkFfCHpXh",
        "colab_type": "text"
      },
      "source": [
        "## TEST 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w1j1G4dHrlJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "cc75fe18-327f-4de8-e1f8-87a2b7f7a5dd"
      },
      "source": [
        "bob"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7b64f0f20721>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'bob' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ecb81b86-a821-43a2-a56f-a7a34f78861a",
        "id": "47WdPxEXH1Ul",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1402
        }
      },
      "source": [
        "! pip install syft"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting syft\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/e0/7466833685e21917a78b3e26503e675c9bc82bd81c0d9a6a90c30adf9938/syft-0.1.20a1-py3-none-any.whl (213kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.21.2)\n",
            "Collecting websocket-client>=0.56.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 45.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Collecting zstd>=1.4.0.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/27/1ea8086d37424e83ab692015cc8dd7d5e37cf791e339633a40dc828dfb74/zstd-1.4.0.0.tar.gz (450kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 53.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Requirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft) (1.0.3)\n",
            "Collecting flask-socketio>=3.3.2 (from syft)\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/68/fe4806d3a0a5909d274367eb9b3b87262906c1515024f46c2443a36a0c82/Flask_SocketIO-4.1.0-py2.py3-none-any.whl\n",
            "Collecting lz4>=2.1.6 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 46.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.16.4)\n",
            "Collecting msgpack>=0.6.1 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/7e/ae9e91c1bb8d846efafd1f353476e3fd7309778b582d2fb4cea4cc15b9a2/msgpack-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 46.8MB/s \n",
            "\u001b[?25hCollecting websockets>=7.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/71/8bfa882b9c502c36e5c9ef6732969533670d2b039cbf95a82ced8f762b80/websockets-7.0-cp36-cp36m-manylinux1_x86_64.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 25.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Collecting tf-encrypted>=0.5.4 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/ce/da9916e7e78f736894b15538b702c0b213fd5d60a7fd6e481d74033a90c0/tf_encrypted-0.5.6-py3-none-manylinux1_x86_64.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 42.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (0.13.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client>=0.56.0->syft) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (4.3.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (7.0)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (2.10.1)\n",
            "Requirement already satisfied: Werkzeug>=0.14 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (0.15.4)\n",
            "Collecting python-socketio>=2.1.0 (from flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/1b/57e860a86f2a01be86ae1dacfa0cd8c4dfbfcd4593322268b61b5a07b564/python_socketio-4.2.0-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 22.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Collecting pyyaml>=5.1 (from tf-encrypted>=0.5.4->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/837fefac7475963d1eccf4aa684c23b95aa6c1d033a2c5965ccb11e22623/PyYAML-5.1.1.tar.gz (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 47.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->syft) (0.46)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10->Flask>=1.0.2->syft) (1.1.1)\n",
            "Collecting python-engineio>=3.8.0 (from python-socketio>=2.1.0->flask-socketio>=3.3.2->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/1c/601f8ad22681ec9b86acafabc145b6bd02ca62aeac6aae4045d262a94a56/python_engineio-3.8.2-py2.py3-none-any.whl (119kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 37.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.1.7)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.11.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (41.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (2.8.0)\n",
            "Building wheels for collected packages: zstd, pyyaml\n",
            "  Building wheel for zstd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/9a/f4/3105b5209674ac77fcca7fede95184c62a95df0196888e0e76\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/27/a1/775c62ddea7bfa62324fd1f65847ed31c55dadb6051481ba3f\n",
            "Successfully built zstd pyyaml\n",
            "Installing collected packages: websocket-client, zstd, python-engineio, python-socketio, flask-socketio, lz4, msgpack, websockets, pyyaml, tf-encrypted, syft\n",
            "  Found existing installation: msgpack 0.5.6\n",
            "    Uninstalling msgpack-0.5.6:\n",
            "      Successfully uninstalled msgpack-0.5.6\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed flask-socketio-4.1.0 lz4-2.1.10 msgpack-0.6.1 python-engineio-3.8.2 python-socketio-4.2.0 pyyaml-5.1.1 syft-0.1.20a1 tf-encrypted-0.5.6 websocket-client-0.56.0 websockets-7.0 zstd-1.4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pm2XCdmVH1Uv",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "#torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "#torch.set_default_tensor_type(torch.cuda.FloatTensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f16cfe31-20c1-403e-e649-e00f66935a2f",
        "id": "sB8tUcYmH1Ux",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "import syft as sy  # <-- NEW: import the Pysyft library\n",
        "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")  # <-- NEW: define remote worker bob\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")  # <-- NEW: and alice"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0702 10:01:57.270458 139712204683136 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0702 10:01:57.294049 139712204683136 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DibOzt34Iedl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor([1.,2.,3.,4.])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fetdCVhmIqFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = x.send(bob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFDKyKHAIt4O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fd53b62f-e02d-44ff-b75f-02ae90075d95"
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{57110002802: tensor([1., 2., 3., 4.])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdhn_6ysIvea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = x.move(alice)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hXGll0kIzHR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5aa47aa2-874f-4a05-fca5-cabff1a9b47c"
      },
      "source": [
        "bob._objects"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm7uKVzVI1MM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = list(alice._objects.values())[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0Iq8ojZKbgD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5624125c-66da-4304-aa9c-56f03bc8caff"
      },
      "source": [
        "a.element_size()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiIBTyqXKhdQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1abc6ae3-a8c7-4078-c58d-f8152cd0c678"
      },
      "source": [
        "a.nelement()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG3NSkXvI3Bh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "51449240-9dfd-48b3-a673-9dec235e203b"
      },
      "source": [
        "a.element_size() * a.nelement()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPM6OSMRKkSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAtZf94FyoRR",
        "colab_type": "text"
      },
      "source": [
        "## DISTANCE CORRELATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL0BJSEWIS2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9SFB4shCJIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = torch.randn((15,20))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn6QLh5-CXjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "Y = X**2-X+3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mwhVF-UCbgM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "548671bb-d22b-4262-cc22-a8b9ec6e35aa"
      },
      "source": [
        "Y.size()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([15, 20])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7psEnNsFEnQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "fe0583f2-a72e-409e-f676-7fe6384f9b02"
      },
      "source": [
        "torch.zeros(2,2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0oACLZaE3U7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dist_matrix(X):\n",
        "  N = X.shape[0]\n",
        "  print(\"N=\",N)\n",
        "  dist = torch.zeros(N,N)\n",
        "  #print(X.size())\n",
        "  X = X.view(N,-1)\n",
        "  print(X.shape)\n",
        "  #print(X.size())\n",
        "  for i in range(N):\n",
        "    for j in range(i,N):\n",
        "      #x1_norm = (X[i]**2).sum().view(-1, 1)\n",
        "      #x2_norm = (X[j]**2).sum().view(-1, 1)\n",
        "      #dist[i,j] = x1_norm + x2_norm - 2.0 * torch.matmul(X[i], X[j])\n",
        "     # print(X.size())\n",
        "      tmp = torch.matmul((X[i]-X[j]).t(),(X[i]-X[j]))\n",
        "      #print(tmp.clone().get())\n",
        "      dist[i,j] = tmp.item()    \n",
        "      dist[j,i] = dist[i,j]\n",
        "  return dist\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skESsf9pPnQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def a_dot_l(dist):\n",
        "  N = dist.shape[0]\n",
        "  a_l = torch.zeros(N)\n",
        "  for l in range(N):\n",
        "    a_l[l] = dist[:,l].sum()\n",
        "  return  1./N*a_l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaz1kYpQRDfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def a_k_dot(dist):\n",
        "  N = dist.shape[0]\n",
        "  a_k = torch.zeros(N)\n",
        "  for k in range(N):\n",
        "    a_k[k] = dist[k,:].sum()\n",
        "  return  1./N*a_k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1nMuQBNF-W7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def A_matrix(dist):\n",
        "  N = dist.shape[0]\n",
        "  A = dist\n",
        "  a_l = a_dot_l(dist)\n",
        "  a_k = a_k_dot(dist)\n",
        "  for k in range(N):\n",
        "    A[k,:] -= a_l\n",
        "    A[:,k] -= a_k\n",
        "  a_dot = 1/N**2*dist.sum()*torch.ones(N,N)\n",
        "  A += a_dot\n",
        "  return A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMErNRneCcyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def distance_covariance(X,Y):\n",
        "  dist_x = dist_matrix(X) \n",
        "  dist_y = dist_matrix(Y)\n",
        "  N = dist_x.shape[0]\n",
        "  A = A_matrix(dist_x)\n",
        "  B = A_matrix(dist_y)\n",
        "  C = A*B\n",
        "  return 1/N**2*C.sum()\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjaB0iDhKHLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def distance_variance(X):\n",
        "  dist_x = dist_matrix(X) \n",
        "  N = dist_x.shape[0]\n",
        "  A = A_matrix(dist_x)\n",
        "  #print(A)\n",
        "  return 1/N**2*(A**2).sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4UHnYyzLVis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def distance_correlation(X,Y):\n",
        "  cov = distance_covariance(X,Y)\n",
        "  #print(cov)\n",
        "  V_x = distance_variance(X)\n",
        "  V_y = distance_variance(Y)\n",
        "  #print(V_x,V_y)\n",
        "  corr = cov/torch.sqrt(V_x*V_y)\n",
        "  return corr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAzbZQIaR96w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_dcor(X,Y):\n",
        "  return np.log(distance_correlation(X,Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SvwVEvtJjvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_dcor(X,Y):\n",
        "  #n = len(X.size())\n",
        "  n = len(X.shape)\n",
        "  a = X.shape[0]\n",
        "  #print(X.size())\n",
        "  X_new = X.view(a,-1)\n",
        "  Y_new = Y.view(a,-1)\n",
        "  return distance_correlation(X_new,Y_new)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFBi4a3dmCy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_log_dcor(X,Y):\n",
        "  return np.log(batch_dcor(X,Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4e5fXNDlMfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(0)\n",
        "X = torch.randn(5,20,20)\n",
        "\n",
        "torch.manual_seed(1)\n",
        "Y = torch.randn(5,20,20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2exc6QImzapk",
        "colab_type": "text"
      },
      "source": [
        "###Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkHuEil7T835",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDweAYHmSrTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ])),\n",
        "  batch_size=64, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ])),\n",
        "  batch_size=1000, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxwSLWRwSCKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "examples = enumerate(test_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQCvfOAYJvyi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "outputId": "c45e70bd-5c39-4e0a-8368-be7cd44bb02c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "fig"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAELCAYAAAAP/iu7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZAMAiI5kAwCIjmQDAIju/wM0fpLuuu5MQAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAELCAYAAAAP/iu7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZAMAiI5kAwCIjmQDAIju/wM0fpLuuu5MQAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z_3EKZLSCFF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba313114-8e23-4e97-adc5-11c5a42d42f5"
      },
      "source": [
        "example_data.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxgl0njLBzvk",
        "colab_type": "text"
      },
      "source": [
        "## TEST 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rK0kpv8pCIRU"
      },
      "source": [
        "### INSTALLATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d3ca9479-a216-4ea0-d323-680b1392c0fc",
        "id": "W6cdujvBCIRX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "! git clone https://github.com/OpenMined/PySyft.git"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'PySyft' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5a315bc0-6a07-4b03-c776-99438444694e",
        "id": "bEDx1qlmCIRd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd PySyft"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/PySyft\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bf2e6b36-f253-48c4-cb5e-47a7f557897c",
        "id": "BFZA4XYHCIRf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "! git checkout 7b6f9fb"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "M\tsyft/frameworks/torch/tensors/interpreters/native.py\n",
            "HEAD is now at 7b6f9fb2 Merge pull request #2303 from amit-rastogi/dev\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9bbc887a-7351-406a-bb20-0367c837a69d",
        "id": "1AzROdmeCIRi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "! git show"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mcommit 7b6f9fb2b98865f4ad45f93d337970c885ee3534\u001b[m\u001b[33m (\u001b[m\u001b[1;36mHEAD\u001b[m\u001b[33m)\u001b[m\n",
            "Merge: ab75db1e 0273a8f1\n",
            "Author: Robert (Bobby) Wagner <raw141@case.edu>\n",
            "Date:   Thu Jun 20 14:52:49 2019 -0400\n",
            "\n",
            "    Merge pull request #2303 from amit-rastogi/dev\n",
            "    \n",
            "    Added tutorial for using pysyft to train a reinforcement learning agent\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "20a7d69f-0ead-41db-f235-5b5dc3573096",
        "id": "Apdx9DJlCIRl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        }
      },
      "source": [
        "! pip install -r requirements.txt"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.0.3)\n",
            "Requirement already satisfied: flask_socketio>=3.3.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (4.1.0)\n",
            "Requirement already satisfied: lz4>=2.1.6 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.1.10)\n",
            "Requirement already satisfied: msgpack>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (0.6.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (1.16.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.21.2)\n",
            "Requirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: tf_encrypted>=0.5.4 in ./tf-encrypted (from -r requirements.txt (line 8)) (0.5.5)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (1.1.0)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (0.3.0)\n",
            "Requirement already satisfied: websocket_client>=0.56.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (0.56.0)\n",
            "Requirement already satisfied: websockets>=7.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 12)) (8.0)\n",
            "Requirement already satisfied: zstd>=1.4.0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 13)) (1.4.0.0)\n",
            "Requirement already satisfied: Werkzeug>=0.14 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->-r requirements.txt (line 1)) (0.15.4)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->-r requirements.txt (line 1)) (7.0)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->-r requirements.txt (line 1)) (2.10.1)\n",
            "Requirement already satisfied: python-socketio>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from flask_socketio>=3.3.2->-r requirements.txt (line 2)) (4.2.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->-r requirements.txt (line 6)) (0.13.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.14.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (5.1.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->-r requirements.txt (line 10)) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->-r requirements.txt (line 10)) (1.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10->Flask>=1.0.2->-r requirements.txt (line 1)) (1.1.1)\n",
            "Requirement already satisfied: python-engineio>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from python-socketio>=2.1.0->flask_socketio>=3.3.2->-r requirements.txt (line 2)) (3.8.2.post1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (0.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (3.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (0.33.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (0.1.7)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.11.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (0.8.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.14.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.14.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->-r requirements.txt (line 10)) (0.46)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (41.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b075798f-c45d-4420-ed7c-983212e08090",
        "id": "pOW8aHhQCIRn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd .."
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qsnwCdfWCIRq",
        "colab": {}
      },
      "source": [
        "! mv native.py PySyft/syft/frameworks/torch/tensors/interpreters/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "40a5e0db-7e22-41ea-d7f6-f7eff53f2c48",
        "id": "6wiJ32-ZCIRr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd PySyft/"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/PySyft\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "aaa4a556-cc82-4b80-87b8-68f1ba83afff",
        "id": "TT1rvxbkCIRw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8985
        }
      },
      "source": [
        "! python3 setup.py install"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing syft.egg-info/PKG-INFO\n",
            "writing dependency_links to syft.egg-info/dependency_links.txt\n",
            "writing requirements to syft.egg-info/requires.txt\n",
            "writing top-level names to syft.egg-info/top_level.txt\n",
            "writing manifest file 'syft.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "copying syft/frameworks/torch/tensors/interpreters/native.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/test_serde.py -> build/bdist.linux-x86_64/egg/test\n",
            "creating build/bdist.linux-x86_64/egg/test/torch\n",
            "creating build/bdist.linux-x86_64/egg/test/torch/differential_privacy\n",
            "copying build/lib/test/torch/differential_privacy/__init__.py -> build/bdist.linux-x86_64/egg/test/torch/differential_privacy\n",
            "copying build/lib/test/torch/differential_privacy/test_pate.py -> build/bdist.linux-x86_64/egg/test/torch/differential_privacy\n",
            "creating build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_parameter.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_native.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_polynomial.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_variable.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_additive_shared.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_precision.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_gc.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_tensor.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/__init__.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_autograd.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_logging.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_multi_pointer.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "creating build/bdist.linux-x86_64/egg/test/torch/crypto\n",
            "copying build/lib/test/torch/crypto/test_snn.py -> build/bdist.linux-x86_64/egg/test/torch/crypto\n",
            "copying build/lib/test/torch/crypto/__init__.py -> build/bdist.linux-x86_64/egg/test/torch/crypto\n",
            "copying build/lib/test/torch/test_federated_learning.py -> build/bdist.linux-x86_64/egg/test/torch\n",
            "copying build/lib/test/torch/test_functions.py -> build/bdist.linux-x86_64/egg/test/torch\n",
            "creating build/bdist.linux-x86_64/egg/test/torch/pointers\n",
            "copying build/lib/test/torch/pointers/test_callable_pointer.py -> build/bdist.linux-x86_64/egg/test/torch/pointers\n",
            "copying build/lib/test/torch/pointers/__init__.py -> build/bdist.linux-x86_64/egg/test/torch/pointers\n",
            "copying build/lib/test/torch/pointers/test_pointer_tensor.py -> build/bdist.linux-x86_64/egg/test/torch/pointers\n",
            "copying build/lib/test/torch/__init__.py -> build/bdist.linux-x86_64/egg/test/torch\n",
            "copying build/lib/test/torch/test_hook.py -> build/bdist.linux-x86_64/egg/test/torch\n",
            "creating build/bdist.linux-x86_64/egg/test/torch/federated\n",
            "copying build/lib/test/torch/federated/test_dataset.py -> build/bdist.linux-x86_64/egg/test/torch/federated\n",
            "copying build/lib/test/torch/federated/test_dataloader.py -> build/bdist.linux-x86_64/egg/test/torch/federated\n",
            "copying build/lib/test/torch/federated/__init__.py -> build/bdist.linux-x86_64/egg/test/torch/federated\n",
            "copying build/lib/test/torch/federated/test_utils.py -> build/bdist.linux-x86_64/egg/test/torch/federated\n",
            "copying build/lib/test/test_grid.py -> build/bdist.linux-x86_64/egg/test\n",
            "creating build/bdist.linux-x86_64/egg/test/generic\n",
            "copying build/lib/test/generic/test_id_provider.py -> build/bdist.linux-x86_64/egg/test/generic\n",
            "copying build/lib/test/generic/__init__.py -> build/bdist.linux-x86_64/egg/test/generic\n",
            "copying build/lib/test/test_exceptions.py -> build/bdist.linux-x86_64/egg/test\n",
            "creating build/bdist.linux-x86_64/egg/test/keras\n",
            "copying build/lib/test/keras/test_sequential.py -> build/bdist.linux-x86_64/egg/test/keras\n",
            "creating build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/workers/test_base.py -> build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/workers/test_worker.py -> build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/workers/__init__.py -> build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/workers/test_virtual.py -> build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/workers/test_websocket_worker.py -> build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/__init__.py -> build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/test_udacity.py -> build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/test_sandbox.py -> build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/test_local_worker.py -> build/bdist.linux-x86_64/egg/test\n",
            "creating build/bdist.linux-x86_64/egg/test/federated\n",
            "copying build/lib/test/federated/test_federated_client.py -> build/bdist.linux-x86_64/egg/test/federated\n",
            "copying build/lib/test/federated/test_plan.py -> build/bdist.linux-x86_64/egg/test/federated\n",
            "copying build/lib/test/federated/test_train_config.py -> build/bdist.linux-x86_64/egg/test/federated\n",
            "copying build/lib/test/federated/__init__.py -> build/bdist.linux-x86_64/egg/test/federated\n",
            "copying build/lib/test/conftest.py -> build/bdist.linux-x86_64/egg/test\n",
            "creating build/bdist.linux-x86_64/egg/syft\n",
            "copying build/lib/syft/exceptions.py -> build/bdist.linux-x86_64/egg/syft\n",
            "creating build/bdist.linux-x86_64/egg/syft/generic\n",
            "copying build/lib/syft/generic/object_storage.py -> build/bdist.linux-x86_64/egg/syft/generic\n",
            "copying build/lib/syft/generic/id_provider.py -> build/bdist.linux-x86_64/egg/syft/generic\n",
            "copying build/lib/syft/generic/__init__.py -> build/bdist.linux-x86_64/egg/syft/generic\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/differential_privacy\n",
            "copying build/lib/syft/frameworks/torch/differential_privacy/pate.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/differential_privacy\n",
            "copying build/lib/syft/frameworks/torch/differential_privacy/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/differential_privacy\n",
            "copying build/lib/syft/frameworks/torch/functions.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/derivatives.yaml -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/multi_pointer.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/gradients_core.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/native.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/precision.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/additive_shared.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/plusisminus.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/abstract.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/gradients.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/autograd.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/build_gradients.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/polynomial.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/decorators\n",
            "copying build/lib/syft/frameworks/torch/tensors/decorators/logging.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/decorators\n",
            "copying build/lib/syft/frameworks/torch/tensors/decorators/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/decorators\n",
            "copying build/lib/syft/frameworks/torch/tensors/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors\n",
            "copying build/lib/syft/frameworks/torch/torch_attributes.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto\n",
            "copying build/lib/syft/frameworks/torch/crypto/spdz.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto\n",
            "copying build/lib/syft/frameworks/torch/crypto/securenn.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto\n",
            "copying build/lib/syft/frameworks/torch/crypto/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/pointers/pointer_tensor.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/pointers/object_pointer.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/pointers/object_wrapper.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/pointers/callable_pointer.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/pointers/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/overload_torch.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch\n",
            "copying build/lib/syft/frameworks/torch/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated\n",
            "copying build/lib/syft/frameworks/torch/federated/utils.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated\n",
            "copying build/lib/syft/frameworks/torch/federated/dataset.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated\n",
            "copying build/lib/syft/frameworks/torch/federated/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated\n",
            "copying build/lib/syft/frameworks/torch/federated/dataloader.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook\n",
            "copying build/lib/syft/frameworks/torch/hook/hook_args.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook\n",
            "copying build/lib/syft/frameworks/torch/hook/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook\n",
            "copying build/lib/syft/frameworks/torch/hook/hook.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/keras\n",
            "copying build/lib/syft/frameworks/keras/README.md -> build/bdist.linux-x86_64/egg/syft/frameworks/keras\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/keras/layers\n",
            "copying build/lib/syft/frameworks/keras/layers/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras/layers\n",
            "copying build/lib/syft/frameworks/keras/layers/constructor.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras/layers\n",
            "copying build/lib/syft/frameworks/keras/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/keras/model\n",
            "copying build/lib/syft/frameworks/keras/model/sequential.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras/model\n",
            "copying build/lib/syft/frameworks/keras/model/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras/model\n",
            "copying build/lib/syft/frameworks/keras/hook.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras\n",
            "copying build/lib/syft/frameworks/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks\n",
            "copying build/lib/syft/codes.py -> build/bdist.linux-x86_64/egg/syft\n",
            "creating build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/base.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/tfe.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/websocket_server.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/websocket_client.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/virtual.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/abstract.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/__init__.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/__init__.py -> build/bdist.linux-x86_64/egg/syft\n",
            "creating build/bdist.linux-x86_64/egg/syft/serde\n",
            "copying build/lib/syft/serde/native_serde.py -> build/bdist.linux-x86_64/egg/syft/serde\n",
            "copying build/lib/syft/serde/torch_serde.py -> build/bdist.linux-x86_64/egg/syft/serde\n",
            "copying build/lib/syft/serde/__init__.py -> build/bdist.linux-x86_64/egg/syft/serde\n",
            "copying build/lib/syft/serde/serde.py -> build/bdist.linux-x86_64/egg/syft/serde\n",
            "creating build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/federated/federated_client.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/federated/__init__.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/federated/train_config.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/federated/plan.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/grid.py -> build/bdist.linux-x86_64/egg/syft\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_serde.py to test_serde.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/differential_privacy/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/differential_privacy/test_pate.py to test_pate.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_parameter.py to test_parameter.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_native.py to test_native.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_polynomial.py to test_polynomial.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_variable.py to test_variable.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_additive_shared.py to test_additive_shared.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_precision.py to test_precision.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_gc.py to test_gc.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_tensor.py to test_tensor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_autograd.py to test_autograd.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_logging.py to test_logging.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_multi_pointer.py to test_multi_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/crypto/test_snn.py to test_snn.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/crypto/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/test_federated_learning.py to test_federated_learning.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/test_functions.py to test_functions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/pointers/test_callable_pointer.py to test_callable_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/pointers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/pointers/test_pointer_tensor.py to test_pointer_tensor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/test_hook.py to test_hook.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/federated/test_dataset.py to test_dataset.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/federated/test_dataloader.py to test_dataloader.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/federated/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/federated/test_utils.py to test_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_grid.py to test_grid.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/generic/test_id_provider.py to test_id_provider.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/generic/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_exceptions.py to test_exceptions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/keras/test_sequential.py to test_sequential.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/workers/test_base.py to test_base.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/workers/test_worker.py to test_worker.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/workers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/workers/test_virtual.py to test_virtual.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/workers/test_websocket_worker.py to test_websocket_worker.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_udacity.py to test_udacity.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_sandbox.py to test_sandbox.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_local_worker.py to test_local_worker.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/federated/test_federated_client.py to test_federated_client.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/federated/test_plan.py to test_plan.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/federated/test_train_config.py to test_train_config.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/federated/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/conftest.py to conftest.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/exceptions.py to exceptions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/generic/object_storage.py to object_storage.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/generic/id_provider.py to id_provider.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/generic/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/differential_privacy/pate.py to pate.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/differential_privacy/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/functions.py to functions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/multi_pointer.py to multi_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/gradients_core.py to gradients_core.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/native.py to native.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/precision.py to precision.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/additive_shared.py to additive_shared.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/plusisminus.py to plusisminus.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/abstract.py to abstract.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/gradients.py to gradients.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/autograd.py to autograd.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/build_gradients.py to build_gradients.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/polynomial.py to polynomial.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/decorators/logging.py to logging.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/decorators/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/torch_attributes.py to torch_attributes.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto/spdz.py to spdz.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto/securenn.py to securenn.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers/pointer_tensor.py to pointer_tensor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers/object_pointer.py to object_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers/object_wrapper.py to object_wrapper.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers/callable_pointer.py to callable_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/overload_torch.py to overload_torch.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated/utils.py to utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated/dataset.py to dataset.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated/dataloader.py to dataloader.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook/hook_args.py to hook_args.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook/hook.py to hook.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/layers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/layers/constructor.py to constructor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/model/sequential.py to sequential.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/model/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/hook.py to hook.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/codes.py to codes.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/base.py to base.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/tfe.py to tfe.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/websocket_server.py to websocket_server.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/websocket_client.py to websocket_client.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/virtual.py to virtual.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/abstract.py to abstract.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/serde/native_serde.py to native_serde.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/serde/torch_serde.py to torch_serde.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/serde/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/serde/serde.py to serde.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/federated_client.py to federated_client.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/train_config.py to train_config.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/plan.py to plan.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid.py to grid.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syft.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syft.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syft.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syft.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syft.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating 'dist/syft-0.1.19a1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing syft-0.1.19a1-py3.6.egg\n",
            "Removing /usr/local/lib/python3.6/dist-packages/syft-0.1.19a1-py3.6.egg\n",
            "Copying syft-0.1.19a1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "syft 0.1.19a1 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/syft-0.1.19a1-py3.6.egg\n",
            "Processing dependencies for syft==0.1.19a1\n",
            "Searching for zstd==1.4.0.0\n",
            "Best match: zstd 1.4.0.0\n",
            "Adding zstd 1.4.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for websockets==8.0\n",
            "Best match: websockets 8.0\n",
            "Adding websockets 8.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for websocket-client==0.56.0\n",
            "Best match: websocket-client 0.56.0\n",
            "Adding websocket-client 0.56.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for torchvision==0.3.0\n",
            "Best match: torchvision 0.3.0\n",
            "Adding torchvision 0.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for torch==1.1.0\n",
            "Best match: torch 1.1.0\n",
            "Adding torch 1.1.0 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tf-encrypted==0.5.5\n",
            "Best match: tf-encrypted 0.5.5\n",
            "tf-encrypted 0.5.5 is already the active version in easy-install.pth\n",
            "\n",
            "Using /content/PySyft/tf-encrypted\n",
            "Searching for tblib==1.4.0\n",
            "Best match: tblib 1.4.0\n",
            "Adding tblib 1.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scikit-learn==0.21.2\n",
            "Best match: scikit-learn 0.21.2\n",
            "Adding scikit-learn 0.21.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.16.4\n",
            "Best match: numpy 1.16.4\n",
            "Adding numpy 1.16.4 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for msgpack==0.6.1\n",
            "Best match: msgpack 0.6.1\n",
            "Adding msgpack 0.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for lz4==2.1.10\n",
            "Best match: lz4 2.1.10\n",
            "Adding lz4 2.1.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Flask-SocketIO==4.1.0\n",
            "Best match: Flask-SocketIO 4.1.0\n",
            "Adding Flask-SocketIO 4.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Flask==1.0.3\n",
            "Best match: Flask 1.0.3\n",
            "Adding Flask 1.0.3 to easy-install.pth file\n",
            "Installing flask script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.12.0\n",
            "Best match: six 1.12.0\n",
            "Adding six 1.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Pillow==4.3.0\n",
            "Best match: Pillow 4.3.0\n",
            "Adding Pillow 4.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for PyYAML==5.1.1\n",
            "Best match: PyYAML 5.1.1\n",
            "Adding PyYAML 5.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorflow==1.14.0\n",
            "Best match: tensorflow 1.14.0\n",
            "Adding tensorflow 1.14.0 to easy-install.pth file\n",
            "Installing freeze_graph script to /usr/local/bin\n",
            "Installing saved_model_cli script to /usr/local/bin\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "Installing tf_upgrade_v2 script to /usr/local/bin\n",
            "Installing tflite_convert script to /usr/local/bin\n",
            "Installing toco script to /usr/local/bin\n",
            "Installing toco_from_protos script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for joblib==0.13.2\n",
            "Best match: joblib 0.13.2\n",
            "Adding joblib 0.13.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scipy==1.3.0\n",
            "Best match: scipy 1.3.0\n",
            "Adding scipy 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for python-socketio==4.2.0\n",
            "Best match: python-socketio 4.2.0\n",
            "Adding python-socketio 4.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Jinja2==2.10.1\n",
            "Best match: Jinja2 2.10.1\n",
            "Adding Jinja2 2.10.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for itsdangerous==1.1.0\n",
            "Best match: itsdangerous 1.1.0\n",
            "Adding itsdangerous 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Click==7.0\n",
            "Best match: Click 7.0\n",
            "Adding Click 7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Werkzeug==0.15.4\n",
            "Best match: Werkzeug 0.15.4\n",
            "Adding Werkzeug 0.15.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for olefile==0.46\n",
            "Best match: olefile 0.46\n",
            "Adding olefile 0.46 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for absl-py==0.7.1\n",
            "Best match: absl-py 0.7.1\n",
            "Adding absl-py 0.7.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for termcolor==1.1.0\n",
            "Best match: termcolor 1.1.0\n",
            "Adding termcolor 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Keras-Applications==1.0.8\n",
            "Best match: Keras-Applications 1.0.8\n",
            "Adding Keras-Applications 1.0.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for wrapt==1.11.2\n",
            "Best match: wrapt 1.11.2\n",
            "Adding wrapt 1.11.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorboard==1.14.0\n",
            "Best match: tensorboard 1.14.0\n",
            "Adding tensorboard 1.14.0 to easy-install.pth file\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for protobuf==3.7.1\n",
            "Best match: protobuf 3.7.1\n",
            "Adding protobuf 3.7.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Keras-Preprocessing==1.1.0\n",
            "Best match: Keras-Preprocessing 1.1.0\n",
            "Adding Keras-Preprocessing 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for gast==0.2.2\n",
            "Best match: gast 0.2.2\n",
            "Adding gast 0.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for grpcio==1.15.0\n",
            "Best match: grpcio 1.15.0\n",
            "Adding grpcio 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorflow-estimator==1.14.0\n",
            "Best match: tensorflow-estimator 1.14.0\n",
            "Adding tensorflow-estimator 1.14.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for wheel==0.33.4\n",
            "Best match: wheel 0.33.4\n",
            "Adding wheel 0.33.4 to easy-install.pth file\n",
            "Installing wheel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for astor==0.8.0\n",
            "Best match: astor 0.8.0\n",
            "Adding astor 0.8.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for google-pasta==0.1.7\n",
            "Best match: google-pasta 0.1.7\n",
            "Adding google-pasta 0.1.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for python-engineio==3.8.2.post1\n",
            "Best match: python-engineio 3.8.2.post1\n",
            "Adding python-engineio 3.8.2.post1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for MarkupSafe==1.1.1\n",
            "Best match: MarkupSafe 1.1.1\n",
            "Adding MarkupSafe 1.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for h5py==2.8.0\n",
            "Best match: h5py 2.8.0\n",
            "Adding h5py 2.8.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Markdown==3.1.1\n",
            "Best match: Markdown 3.1.1\n",
            "Adding Markdown 3.1.1 to easy-install.pth file\n",
            "Installing markdown_py script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for setuptools==41.0.1\n",
            "Best match: setuptools 41.0.1\n",
            "Adding setuptools 41.0.1 to easy-install.pth file\n",
            "Installing easy_install script to /usr/local/bin\n",
            "Installing easy_install-3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for syft==0.1.19a1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a5d82a67-024e-496c-cd5b-750771a7ee0d",
        "id": "2xKRs0LQCIR6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "! git clone https://github.com/tf-encrypted/tf-encrypted"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'tf-encrypted' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a43c40ed-1ecd-4ac6-8103-516f3347c591",
        "id": "lQh71DZ9CIR9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd tf-encrypted/"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/PySyft/tf-encrypted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f478f656-f016-4e83-9b1b-084cf34429b0",
        "id": "2DI7hRChCISK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "! pip3 install -e ."
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/PySyft/tf-encrypted\n",
            "Requirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted==0.5.5) (1.14.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted==0.5.5) (1.16.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted==0.5.5) (5.1.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.5) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.5) (0.33.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.5) (1.11.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.5) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.5) (0.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.5) (0.1.7)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.5) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.5) (0.7.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.5) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.5) (3.7.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.5) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.5) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.5) (1.14.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted==0.5.5) (1.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<2,>=1.12.0->tf-encrypted==0.5.5) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted==0.5.5) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted==0.5.5) (0.15.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted==0.5.5) (2.8.0)\n",
            "Installing collected packages: tf-encrypted\n",
            "  Found existing installation: tf-encrypted 0.5.6\n",
            "    Uninstalling tf-encrypted-0.5.6:\n",
            "      Successfully uninstalled tf-encrypted-0.5.6\n",
            "  Running setup.py develop for tf-encrypted\n",
            "Successfully installed tf-encrypted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c6bc1af1-8685-4ac7-94db-be64adf496d6",
        "id": "z2gVJIZcCISL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "import tf_encrypted as tfe"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0708 09:34:01.363904 140491739932544 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/content/PySyft/tf-encrypted/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0708 09:34:01.420444 140491739932544 deprecation_wrapper.py:119] From /content/PySyft/tf-encrypted/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e7f3fbdb-2699-4641-ae07-1a88c606db17",
        "id": "tN3hlwaKCISP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd .."
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/PySyft\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FE6oi47ZCISQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "4bb8d66e-cd2c-4376-bbbb-ea9af2d3b301"
      },
      "source": [
        "import syft as sy"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0708 13:29:02.946363 140322888656768 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/content/PySyft/tf-encrypted/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0708 13:29:02.962099 140322888656768 deprecation_wrapper.py:119] From /content/PySyft/tf-encrypted/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NngstSxnCISR",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OQ5u_b5GCISS",
        "colab": {}
      },
      "source": [
        "#import syft as sy  # <-- NEW: import the Pysyft library\n",
        "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")  # <-- NEW: define remote worker bob\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")  # <-- NEW: and alice"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kr6KMgBBCRXd"
      },
      "source": [
        "### NoPeekNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QbQ04GjBCRXf",
        "colab": {}
      },
      "source": [
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 64\n",
        "        self.test_batch_size = 1000\n",
        "        self.epochs = 10\n",
        "        self.lr = 0.01\n",
        "        self.momentum = 0.5\n",
        "        self.no_cuda = False\n",
        "        self.seed = 1\n",
        "        self.log_interval = 30\n",
        "        self.save_model = False\n",
        "\n",
        "args = Arguments()\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "if use_cuda:\n",
        "        # TODO Quickhack. Actually need to fix the problem moving the model to CUDA\\n\",\n",
        "        torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "#device = torch.device(\"cpu\")\n",
        "\n",
        "#kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "kwargs = {'num_workers': 0, 'pin_memory': False} if use_cuda else {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "56fb019c-714e-4eec-cf44-3534d8c85ff8",
        "id": "0ZKD-LEFCRXj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n",
        "    .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
        "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=args.test_batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m_getencoder\u001b[0;34m(mode, encoder_name, args, extra)\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mENCODERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'raw'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-4085cd6569bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                        \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1307\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.3081\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                    ]))\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;34m.\u001b[0m\u001b[0mfederate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     batch_size=args.batch_size, shuffle=True, **kwargs)\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/federated/dataset.py\u001b[0m in \u001b[0;36mdataset_federate\u001b[0;34m(dataset, workers)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdataset_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0mworker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sending data to worker %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;31m# PIL image mode: L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'YCbCr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0;31m# unpack data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_getencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m_getencoder\u001b[0;34m(mode, encoder_name, args, extra)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mENCODERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "th_L8BehCRXp",
        "colab": {}
      },
      "source": [
        "class Net1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net1, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        return F.max_pool2d(x, 2, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "boSVyHAVCRXw",
        "colab": {}
      },
      "source": [
        "class Net2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net2, self).__init__()\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-AiVVo6rCRXy",
        "colab": {}
      },
      "source": [
        "models = [Net1().to(device), Net1().to(device)]\n",
        "#models = [Net1(), Net1()]\n",
        "models[0] = models[0].send(bob)\n",
        "models[1] = models[1].send(alice)\n",
        "\n",
        "\n",
        "\n",
        "opt1 = optim.SGD(params=models[0].parameters(),lr=0.1)\n",
        "opt2 = optim.SGD(params=models[1].parameters(),lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-WUGy0weCRX0",
        "colab": {}
      },
      "source": [
        "def train(args, model, device, federated_train_loader, optimizer, epoch, alpha1=0.1,alpha2=0.9):\n",
        "    model.train()\n",
        "    for batch_idx, (data, targs) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
        "        #IF ON DATA LOCATION TO GET THE RIGHT MODEL\n",
        "        if data.location.id == 'bob':\n",
        "          mod_c,opt_c = models[0], opt1\n",
        "        else : \n",
        "          mod_c,opt_c = models[1], opt2\n",
        "        \n",
        "        #print(\"data\",data.clone().get().size())\n",
        "       # 1) erase previous gradients (if they exist)\n",
        "        optimizer.step()\n",
        "        opt_c.step()\n",
        "        opt_c.zero_grad()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        tg_copy = targs.copy()\n",
        "        target = tg_copy.get()\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        # 2) make a prediction until cut layer (client location)\n",
        "        pred_c = mod_c(data)\n",
        "        copy = pred_c.copy()\n",
        "        \n",
        "\n",
        "        \n",
        "        \n",
        "        # 3) get this to the server \n",
        "        inp = copy.get()\n",
        "\n",
        "        # compute the distance correlation\n",
        "        dist = batch_dcor(data.clone().get(),inp)\n",
        "        dist.backward()\n",
        "        \n",
        "        \n",
        "        # 4) make prediction with second part of the model (server location)\n",
        "        pred = model(inp)\n",
        "\n",
        "        # 5) calculate how much we missed \n",
        "        loss = F.nll_loss(pred, target)\n",
        "        loss.backward()\n",
        "        print(dist.grad)\n",
        "        print(inp.grad)\n",
        "        gradient = alpha1*dist.grad + alpha2*inp.grad\n",
        "        gradient = gradient.send(data.location)\n",
        "        dist.backward()\n",
        "        pred_c.backward(gradient)\n",
        "        \n",
        "        \n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            #loss = loss.get() # <-- NEW: get the loss back\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} \\tDCor:'.format(\n",
        "                epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,\n",
        "                100. * batch_idx / len(federated_train_loader), loss.item(),dist))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L3qR8TPR9GGF",
        "colab": {}
      },
      "source": [
        "def train(args, model, device, federated_train_loader, optimizer, epoch, alpha1=0.1,alpha2=0.9):\n",
        "    model.train()\n",
        "    for batch_idx, (data, targs) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
        "        #IF ON DATA LOCATION TO GET THE RIGHT MODEL\n",
        "        if data.location.id == 'bob':\n",
        "          mod_c,opt_c = models[0], opt1\n",
        "        else : \n",
        "          mod_c,opt_c = models[1], opt2\n",
        "        \n",
        "        #print(\"data\",data.clone().get().size())\n",
        "        # 1) erase previous gradients (if they exist)\n",
        "        optimizer.step()\n",
        "        opt_c.step()\n",
        "        opt_c.zero_grad()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        tg_copy = targs.copy()\n",
        "        target = tg_copy.get()\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        # 2) make a prediction until cut layer (client location)\n",
        "        pred_c = mod_c(data)\n",
        "        copy = pred_c.copy()\n",
        "        \n",
        "        \n",
        "        # 3) get this to the server \n",
        "        inp = copy.get()\n",
        "\n",
        "        # compute the distance correlation\n",
        "        print(data.shape)\n",
        "        dist = batch_dcor(data,pred_c)\n",
        "        dist.backward()\n",
        "        \n",
        "        \n",
        "        # 4) make prediction with second part of the model (server location)\n",
        "        pred = model(inp)\n",
        "\n",
        "        # 5) calculate how much we missed \n",
        "        loss = F.nll_loss(pred, target)\n",
        "        loss.backward()\n",
        "        print(dist.grad)\n",
        "        print(inp.grad)\n",
        "        #gradient = alpha1*dist.grad + alpha2*inp.grad\n",
        "        gradient = inp.grad\n",
        "        gradient = gradient.send(data.location)\n",
        "        dist.backward()\n",
        "        pred_c.backward(gradient)\n",
        "        \n",
        "        \n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            #loss = loss.get() # <-- NEW: get the loss back\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} \\tDCor:'.format(\n",
        "                epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,\n",
        "                100. * batch_idx / len(federated_train_loader), loss.item(),dist))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5gP68QJwCRX1",
        "colab": {}
      },
      "source": [
        "def test(args, model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    M1 = models[0].copy()\n",
        "    M2 = models[1].copy()\n",
        "    M1 = M1.get()\n",
        "    M2 = M2.get()\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(M1(data))\n",
        "            #output2 = model(M2(data))\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "39efc1d3-586c-4a7d-e262-24347581f6b5",
        "id": "fn_AncP2CRX3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1522
        }
      },
      "source": [
        "%%time\n",
        "model = Net2().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(args, model, device, federated_train_loader, optimizer, epoch)\n",
        "    test(args, model, device, test_loader)\n",
        "\n",
        "if (args.save_model):\n",
        "    torch.save(model.state_dict(), \"mnist_cnn.pt\")"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "N= 64\n",
            "torch.Size([64, 784])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-0325af6d78a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model = Net2().to(device)\\noptimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\\n\\nfor epoch in range(1, args.epochs + 1):\\n    train(args, model, device, federated_train_loader, optimizer, epoch)\\n    test(args, model, device, test_loader)\\n\\nif (args.save_model):\\n    torch.save(model.state_dict(), \"mnist_cnn.pt\")'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-4ae2f0544f2a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, device, federated_train_loader, optimizer, epoch, alpha1, alpha2)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# compute the distance correlation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_dcor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-78-56582420dee4>\u001b[0m in \u001b[0;36mbatch_dcor\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mY_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mdistance_correlation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-76-fb8372a4c79e>\u001b[0m in \u001b[0;36mdistance_correlation\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdistance_correlation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;31m#print(cov)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mV_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance_variance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mV_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance_variance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-74-2c4a251dab0f>\u001b[0m in \u001b[0;36mdistance_covariance\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdistance_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mdist_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mdist_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-99-970619c0cb46>\u001b[0m in \u001b[0;36mdist_matrix\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0;31m#print(tmp.clone().get())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m       \u001b[0mdist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m       \u001b[0mdist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0;31m# Send the new command to the appropriate class and get the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m                 \u001b[0;31m# For inplace methods, just directly return self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PySyft/syft/frameworks/torch/pointers/pointer_tensor.py\u001b[0m in \u001b[0;36mitem\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \"\"\"\n\u001b[1;32m    193\u001b[0m         raise RuntimeError(\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0;34m'Error, Please consider calling \".get\" method instead of \".item\" method, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0;34m\"so you can be safely getting the item you need.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error, Please consider calling \".get\" method instead of \".item\" method, so you can be safely getting the item you need."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22MPahr4zXTV",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ETbNMPoLxcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Q = torch.zeros(3,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxTNcVGSL1Dz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = torch.tensor(1.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnGR-NkCL4wb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "52237f7b-3d78-41cf-f402-6f07cf264867"
      },
      "source": [
        "Q"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IG_NiEML5qN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Q[1,1]=c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr-eg-jyL8is",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eeea912f-f7bb-4dd5-8dc0-3f67c5531fbe"
      },
      "source": [
        "c.shape"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSaWH8bAL9fM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c5c13e4d-b184-4f02-ec75-6cf00d7a82eb"
      },
      "source": [
        "Q"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db4VUTPdL_FQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "867a1565-ec04-4c7f-aaa3-37de65b48465"
      },
      "source": [
        "1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jbBdkuHoltD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4cf83440-ec27-4d34-8aa9-e80e02578d2c"
      },
      "source": [
        "! python3 --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWvtf-UOWjLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fonc(a,\n",
        "        b,\n",
        "        c,\n",
        "        d,\n",
        "        ):\n",
        "  return a*b +c-d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cntot2FhGSfC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f1ab5f55-0d6b-41ae-a1a4-dbdeaee159d8"
      },
      "source": [
        "fonc(1,2,3,4)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQFlveQLGahn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2c1b40f1-11b8-4e8f-b596-6d7634c37081",
        "id": "GCybb6ZkHfsK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 13285
        }
      },
      "source": [
        "# Installation + Imports \n",
        "! git clone https://github.com/OpenMined/PySyft.git \n",
        "% cd PySyft\n",
        "#! git checkout @{30.days.ago} # 30 days when 26th June\n",
        "#! git checkout d126b3110a3970bef8932ffaf8987ba77d32deb1 .\n",
        "! git checkout 7b6f9fb\n",
        "! pip install -r requirements.txt\n",
        "% cd .. \n",
        "! mv native.py PySyft/syft/frameworks/torch/tensors/interpreters/ \n",
        "% cd PySyft\n",
        "! python3 setup.py install \n",
        "\n",
        "\n",
        "import syft as sy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import time"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PySyft'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 29888 (delta 21), reused 22 (delta 9), pack-reused 29844\u001b[K\n",
            "Receiving objects: 100% (29888/29888), 32.37 MiB | 20.21 MiB/s, done.\n",
            "Resolving deltas: 100% (19905/19905), done.\n",
            "/content/PySyft\n",
            "Note: checking out '7b6f9fb'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at 7b6f9fb2 Merge pull request #2303 from amit-rastogi/dev\n",
            "Requirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.1.1)\n",
            "Collecting flask_socketio>=3.3.2 (from -r requirements.txt (line 2))\n",
            "  Downloading https://files.pythonhosted.org/packages/33/31/f779e69e59f528684d8c9925b3c82a9303d148655d9671ba2975ab8c3894/Flask_SocketIO-4.2.0-py2.py3-none-any.whl\n",
            "Collecting lz4>=2.1.6 (from -r requirements.txt (line 3))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 14.4MB/s \n",
            "\u001b[?25hCollecting msgpack>=0.6.1 (from -r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/7e/ae9e91c1bb8d846efafd1f353476e3fd7309778b582d2fb4cea4cc15b9a2/msgpack-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 51.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (1.16.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.21.2)\n",
            "Requirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (1.4.0)\n",
            "Collecting tf_encrypted>=0.5.4 (from -r requirements.txt (line 8))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/ff/7dbd5fc77fcec0df1798268a6b72a2ab0150b854761bc39c77d566798f0b/tf_encrypted-0.5.7-py3-none-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 54.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (1.1.0)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (0.3.0)\n",
            "Collecting websocket_client>=0.56.0 (from -r requirements.txt (line 11))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 58.0MB/s \n",
            "\u001b[?25hCollecting websockets>=7.0 (from -r requirements.txt (line 12))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/d2/bf72435a7d56f94b57efdeae26c76bf0d16f409fd44ff595da745c3fbefd/websockets-8.0.1-cp36-cp36m-manylinux1_x86_64.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 34.0MB/s \n",
            "\u001b[?25hCollecting zstd>=1.4.0.0 (from -r requirements.txt (line 13))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/37/6a7ba746ebddbd6cd06de84367515d6bc239acd94fb3e0b1c85788176ca2/zstd-1.4.1.0.tar.gz (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 49.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->-r requirements.txt (line 1)) (2.10.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->-r requirements.txt (line 1)) (0.15.5)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->-r requirements.txt (line 1)) (7.0)\n",
            "Collecting python-socketio>=4.3.0 (from flask_socketio>=3.3.2->-r requirements.txt (line 2))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/5a/9429c1fbc399b6079725150a36491efd6bd4691c11110f5a57e8c991de96/python_socketio-4.3.0-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 24.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->-r requirements.txt (line 6)) (0.13.2)\n",
            "Requirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.14.0)\n",
            "Collecting pyyaml>=5.1 (from tf_encrypted>=0.5.4->-r requirements.txt (line 8))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/837fefac7475963d1eccf4aa684c23b95aa6c1d033a2c5965ccb11e22623/PyYAML-5.1.1.tar.gz (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 42.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->-r requirements.txt (line 10)) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->-r requirements.txt (line 10)) (4.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=1.0.2->-r requirements.txt (line 1)) (1.1.1)\n",
            "Collecting python-engineio>=3.9.0 (from python-socketio>=4.3.0->flask_socketio>=3.3.2->-r requirements.txt (line 2))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/96/b7c61073023569efa30b17ad9115aa4c0489df5b2bf81b896e80d8e2b573/python_engineio-3.9.0-py2.py3-none-any.whl (119kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 50.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (0.7.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.11.2)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.14.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (0.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (0.1.7)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (0.2.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (0.33.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (3.7.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->-r requirements.txt (line 10)) (0.46)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf_encrypted>=0.5.4->-r requirements.txt (line 8)) (2.8.0)\n",
            "Building wheels for collected packages: zstd, pyyaml\n",
            "  Building wheel for zstd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/3f/ee/ac08c81af7c1b24a80c746df669ea3cb37542d27877d66ccf4\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/27/a1/775c62ddea7bfa62324fd1f65847ed31c55dadb6051481ba3f\n",
            "Successfully built zstd pyyaml\n",
            "Installing collected packages: python-engineio, python-socketio, flask-socketio, lz4, msgpack, pyyaml, tf-encrypted, websocket-client, websockets, zstd\n",
            "  Found existing installation: msgpack 0.5.6\n",
            "    Uninstalling msgpack-0.5.6:\n",
            "      Successfully uninstalled msgpack-0.5.6\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed flask-socketio-4.2.0 lz4-2.1.10 msgpack-0.6.1 python-engineio-3.9.0 python-socketio-4.3.0 pyyaml-5.1.1 tf-encrypted-0.5.7 websocket-client-0.56.0 websockets-8.0.1 zstd-1.4.1.0\n",
            "/content\n",
            "/content/PySyft\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating syft.egg-info\n",
            "writing syft.egg-info/PKG-INFO\n",
            "writing dependency_links to syft.egg-info/dependency_links.txt\n",
            "writing requirements to syft.egg-info/requires.txt\n",
            "writing top-level names to syft.egg-info/top_level.txt\n",
            "writing manifest file 'syft.egg-info/SOURCES.txt'\n",
            "writing manifest file 'syft.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/test\n",
            "copying test/test_sandbox.py -> build/lib/test\n",
            "copying test/test_local_worker.py -> build/lib/test\n",
            "copying test/conftest.py -> build/lib/test\n",
            "copying test/test_grid.py -> build/lib/test\n",
            "copying test/__init__.py -> build/lib/test\n",
            "copying test/test_udacity.py -> build/lib/test\n",
            "copying test/test_exceptions.py -> build/lib/test\n",
            "copying test/test_serde.py -> build/lib/test\n",
            "creating build/lib/syft\n",
            "copying syft/codes.py -> build/lib/syft\n",
            "copying syft/exceptions.py -> build/lib/syft\n",
            "copying syft/__init__.py -> build/lib/syft\n",
            "copying syft/grid.py -> build/lib/syft\n",
            "creating build/lib/test/torch\n",
            "copying test/torch/test_federated_learning.py -> build/lib/test/torch\n",
            "copying test/torch/__init__.py -> build/lib/test/torch\n",
            "copying test/torch/test_hook.py -> build/lib/test/torch\n",
            "copying test/torch/test_functions.py -> build/lib/test/torch\n",
            "creating build/lib/test/generic\n",
            "copying test/generic/test_id_provider.py -> build/lib/test/generic\n",
            "copying test/generic/__init__.py -> build/lib/test/generic\n",
            "creating build/lib/test/federated\n",
            "copying test/federated/test_federated_client.py -> build/lib/test/federated\n",
            "copying test/federated/test_plan.py -> build/lib/test/federated\n",
            "copying test/federated/__init__.py -> build/lib/test/federated\n",
            "copying test/federated/test_train_config.py -> build/lib/test/federated\n",
            "creating build/lib/test/workers\n",
            "copying test/workers/test_virtual.py -> build/lib/test/workers\n",
            "copying test/workers/test_base.py -> build/lib/test/workers\n",
            "copying test/workers/test_worker.py -> build/lib/test/workers\n",
            "copying test/workers/test_websocket_worker.py -> build/lib/test/workers\n",
            "copying test/workers/__init__.py -> build/lib/test/workers\n",
            "creating build/lib/test/torch/pointers\n",
            "copying test/torch/pointers/test_callable_pointer.py -> build/lib/test/torch/pointers\n",
            "copying test/torch/pointers/__init__.py -> build/lib/test/torch/pointers\n",
            "copying test/torch/pointers/test_pointer_tensor.py -> build/lib/test/torch/pointers\n",
            "creating build/lib/test/torch/federated\n",
            "copying test/torch/federated/test_utils.py -> build/lib/test/torch/federated\n",
            "copying test/torch/federated/__init__.py -> build/lib/test/torch/federated\n",
            "copying test/torch/federated/test_dataset.py -> build/lib/test/torch/federated\n",
            "copying test/torch/federated/test_dataloader.py -> build/lib/test/torch/federated\n",
            "creating build/lib/test/torch/crypto\n",
            "copying test/torch/crypto/__init__.py -> build/lib/test/torch/crypto\n",
            "copying test/torch/crypto/test_snn.py -> build/lib/test/torch/crypto\n",
            "creating build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_autograd.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_polynomial.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_gc.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_tensor.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_precision.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_additive_shared.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_multi_pointer.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/__init__.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_variable.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_native.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_logging.py -> build/lib/test/torch/tensors\n",
            "copying test/torch/tensors/test_parameter.py -> build/lib/test/torch/tensors\n",
            "creating build/lib/test/torch/differential_privacy\n",
            "copying test/torch/differential_privacy/test_pate.py -> build/lib/test/torch/differential_privacy\n",
            "copying test/torch/differential_privacy/__init__.py -> build/lib/test/torch/differential_privacy\n",
            "creating build/lib/syft/generic\n",
            "copying syft/generic/id_provider.py -> build/lib/syft/generic\n",
            "copying syft/generic/__init__.py -> build/lib/syft/generic\n",
            "copying syft/generic/object_storage.py -> build/lib/syft/generic\n",
            "creating build/lib/syft/serde\n",
            "copying syft/serde/native_serde.py -> build/lib/syft/serde\n",
            "copying syft/serde/__init__.py -> build/lib/syft/serde\n",
            "copying syft/serde/serde.py -> build/lib/syft/serde\n",
            "copying syft/serde/torch_serde.py -> build/lib/syft/serde\n",
            "creating build/lib/syft/federated\n",
            "copying syft/federated/__init__.py -> build/lib/syft/federated\n",
            "copying syft/federated/federated_client.py -> build/lib/syft/federated\n",
            "copying syft/federated/plan.py -> build/lib/syft/federated\n",
            "copying syft/federated/train_config.py -> build/lib/syft/federated\n",
            "creating build/lib/syft/workers\n",
            "copying syft/workers/websocket_client.py -> build/lib/syft/workers\n",
            "copying syft/workers/abstract.py -> build/lib/syft/workers\n",
            "copying syft/workers/base.py -> build/lib/syft/workers\n",
            "copying syft/workers/__init__.py -> build/lib/syft/workers\n",
            "copying syft/workers/websocket_server.py -> build/lib/syft/workers\n",
            "copying syft/workers/virtual.py -> build/lib/syft/workers\n",
            "copying syft/workers/tfe.py -> build/lib/syft/workers\n",
            "creating build/lib/syft/frameworks\n",
            "copying syft/frameworks/__init__.py -> build/lib/syft/frameworks\n",
            "creating build/lib/syft/frameworks/torch\n",
            "copying syft/frameworks/torch/overload_torch.py -> build/lib/syft/frameworks/torch\n",
            "copying syft/frameworks/torch/functions.py -> build/lib/syft/frameworks/torch\n",
            "copying syft/frameworks/torch/__init__.py -> build/lib/syft/frameworks/torch\n",
            "copying syft/frameworks/torch/torch_attributes.py -> build/lib/syft/frameworks/torch\n",
            "creating build/lib/syft/frameworks/keras\n",
            "copying syft/frameworks/keras/__init__.py -> build/lib/syft/frameworks/keras\n",
            "copying syft/frameworks/keras/hook.py -> build/lib/syft/frameworks/keras\n",
            "creating build/lib/syft/frameworks/torch/hook\n",
            "copying syft/frameworks/torch/hook/hook_args.py -> build/lib/syft/frameworks/torch/hook\n",
            "copying syft/frameworks/torch/hook/__init__.py -> build/lib/syft/frameworks/torch/hook\n",
            "copying syft/frameworks/torch/hook/hook.py -> build/lib/syft/frameworks/torch/hook\n",
            "creating build/lib/syft/frameworks/torch/pointers\n",
            "copying syft/frameworks/torch/pointers/pointer_tensor.py -> build/lib/syft/frameworks/torch/pointers\n",
            "copying syft/frameworks/torch/pointers/__init__.py -> build/lib/syft/frameworks/torch/pointers\n",
            "copying syft/frameworks/torch/pointers/object_wrapper.py -> build/lib/syft/frameworks/torch/pointers\n",
            "copying syft/frameworks/torch/pointers/callable_pointer.py -> build/lib/syft/frameworks/torch/pointers\n",
            "copying syft/frameworks/torch/pointers/object_pointer.py -> build/lib/syft/frameworks/torch/pointers\n",
            "creating build/lib/syft/frameworks/torch/federated\n",
            "copying syft/frameworks/torch/federated/__init__.py -> build/lib/syft/frameworks/torch/federated\n",
            "copying syft/frameworks/torch/federated/dataset.py -> build/lib/syft/frameworks/torch/federated\n",
            "copying syft/frameworks/torch/federated/dataloader.py -> build/lib/syft/frameworks/torch/federated\n",
            "copying syft/frameworks/torch/federated/utils.py -> build/lib/syft/frameworks/torch/federated\n",
            "creating build/lib/syft/frameworks/torch/crypto\n",
            "copying syft/frameworks/torch/crypto/__init__.py -> build/lib/syft/frameworks/torch/crypto\n",
            "copying syft/frameworks/torch/crypto/spdz.py -> build/lib/syft/frameworks/torch/crypto\n",
            "copying syft/frameworks/torch/crypto/securenn.py -> build/lib/syft/frameworks/torch/crypto\n",
            "creating build/lib/syft/frameworks/torch/tensors\n",
            "copying syft/frameworks/torch/tensors/__init__.py -> build/lib/syft/frameworks/torch/tensors\n",
            "creating build/lib/syft/frameworks/torch/differential_privacy\n",
            "copying syft/frameworks/torch/differential_privacy/__init__.py -> build/lib/syft/frameworks/torch/differential_privacy\n",
            "copying syft/frameworks/torch/differential_privacy/pate.py -> build/lib/syft/frameworks/torch/differential_privacy\n",
            "creating build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/abstract.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/native.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/gradients.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/plusisminus.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/additive_shared.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/__init__.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/precision.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/polynomial.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/autograd.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/build_gradients.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/gradients_core.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "copying syft/frameworks/torch/tensors/interpreters/multi_pointer.py -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "creating build/lib/syft/frameworks/torch/tensors/decorators\n",
            "copying syft/frameworks/torch/tensors/decorators/logging.py -> build/lib/syft/frameworks/torch/tensors/decorators\n",
            "copying syft/frameworks/torch/tensors/decorators/__init__.py -> build/lib/syft/frameworks/torch/tensors/decorators\n",
            "creating build/lib/syft/frameworks/keras/layers\n",
            "copying syft/frameworks/keras/layers/__init__.py -> build/lib/syft/frameworks/keras/layers\n",
            "copying syft/frameworks/keras/layers/constructor.py -> build/lib/syft/frameworks/keras/layers\n",
            "creating build/lib/syft/frameworks/keras/model\n",
            "copying syft/frameworks/keras/model/sequential.py -> build/lib/syft/frameworks/keras/model\n",
            "copying syft/frameworks/keras/model/__init__.py -> build/lib/syft/frameworks/keras/model\n",
            "creating build/lib/test/keras\n",
            "copying test/keras/test_sequential.py -> build/lib/test/keras\n",
            "copying syft/frameworks/keras/README.md -> build/lib/syft/frameworks/keras\n",
            "copying syft/frameworks/torch/tensors/interpreters/derivatives.yaml -> build/lib/syft/frameworks/torch/tensors/interpreters\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/test_sandbox.py -> build/bdist.linux-x86_64/egg/test\n",
            "creating build/bdist.linux-x86_64/egg/test/torch\n",
            "creating build/bdist.linux-x86_64/egg/test/torch/pointers\n",
            "copying build/lib/test/torch/pointers/test_callable_pointer.py -> build/bdist.linux-x86_64/egg/test/torch/pointers\n",
            "copying build/lib/test/torch/pointers/__init__.py -> build/bdist.linux-x86_64/egg/test/torch/pointers\n",
            "copying build/lib/test/torch/pointers/test_pointer_tensor.py -> build/bdist.linux-x86_64/egg/test/torch/pointers\n",
            "creating build/bdist.linux-x86_64/egg/test/torch/federated\n",
            "copying build/lib/test/torch/federated/test_utils.py -> build/bdist.linux-x86_64/egg/test/torch/federated\n",
            "copying build/lib/test/torch/federated/__init__.py -> build/bdist.linux-x86_64/egg/test/torch/federated\n",
            "copying build/lib/test/torch/federated/test_dataset.py -> build/bdist.linux-x86_64/egg/test/torch/federated\n",
            "copying build/lib/test/torch/federated/test_dataloader.py -> build/bdist.linux-x86_64/egg/test/torch/federated\n",
            "copying build/lib/test/torch/test_federated_learning.py -> build/bdist.linux-x86_64/egg/test/torch\n",
            "creating build/bdist.linux-x86_64/egg/test/torch/crypto\n",
            "copying build/lib/test/torch/crypto/__init__.py -> build/bdist.linux-x86_64/egg/test/torch/crypto\n",
            "copying build/lib/test/torch/crypto/test_snn.py -> build/bdist.linux-x86_64/egg/test/torch/crypto\n",
            "creating build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_autograd.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_polynomial.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_gc.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_tensor.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_precision.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_additive_shared.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_multi_pointer.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/__init__.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_variable.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_native.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_logging.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/tensors/test_parameter.py -> build/bdist.linux-x86_64/egg/test/torch/tensors\n",
            "copying build/lib/test/torch/__init__.py -> build/bdist.linux-x86_64/egg/test/torch\n",
            "copying build/lib/test/torch/test_hook.py -> build/bdist.linux-x86_64/egg/test/torch\n",
            "creating build/bdist.linux-x86_64/egg/test/torch/differential_privacy\n",
            "copying build/lib/test/torch/differential_privacy/test_pate.py -> build/bdist.linux-x86_64/egg/test/torch/differential_privacy\n",
            "copying build/lib/test/torch/differential_privacy/__init__.py -> build/bdist.linux-x86_64/egg/test/torch/differential_privacy\n",
            "copying build/lib/test/torch/test_functions.py -> build/bdist.linux-x86_64/egg/test/torch\n",
            "creating build/bdist.linux-x86_64/egg/test/generic\n",
            "copying build/lib/test/generic/test_id_provider.py -> build/bdist.linux-x86_64/egg/test/generic\n",
            "copying build/lib/test/generic/__init__.py -> build/bdist.linux-x86_64/egg/test/generic\n",
            "copying build/lib/test/test_local_worker.py -> build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/conftest.py -> build/bdist.linux-x86_64/egg/test\n",
            "creating build/bdist.linux-x86_64/egg/test/keras\n",
            "copying build/lib/test/keras/test_sequential.py -> build/bdist.linux-x86_64/egg/test/keras\n",
            "creating build/bdist.linux-x86_64/egg/test/federated\n",
            "copying build/lib/test/federated/test_federated_client.py -> build/bdist.linux-x86_64/egg/test/federated\n",
            "copying build/lib/test/federated/test_plan.py -> build/bdist.linux-x86_64/egg/test/federated\n",
            "copying build/lib/test/federated/__init__.py -> build/bdist.linux-x86_64/egg/test/federated\n",
            "copying build/lib/test/federated/test_train_config.py -> build/bdist.linux-x86_64/egg/test/federated\n",
            "creating build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/workers/test_virtual.py -> build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/workers/test_base.py -> build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/workers/test_worker.py -> build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/workers/test_websocket_worker.py -> build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/workers/__init__.py -> build/bdist.linux-x86_64/egg/test/workers\n",
            "copying build/lib/test/test_grid.py -> build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/__init__.py -> build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/test_udacity.py -> build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/test_exceptions.py -> build/bdist.linux-x86_64/egg/test\n",
            "copying build/lib/test/test_serde.py -> build/bdist.linux-x86_64/egg/test\n",
            "creating build/bdist.linux-x86_64/egg/syft\n",
            "creating build/bdist.linux-x86_64/egg/syft/generic\n",
            "copying build/lib/syft/generic/id_provider.py -> build/bdist.linux-x86_64/egg/syft/generic\n",
            "copying build/lib/syft/generic/__init__.py -> build/bdist.linux-x86_64/egg/syft/generic\n",
            "copying build/lib/syft/generic/object_storage.py -> build/bdist.linux-x86_64/egg/syft/generic\n",
            "copying build/lib/syft/codes.py -> build/bdist.linux-x86_64/egg/syft\n",
            "copying build/lib/syft/exceptions.py -> build/bdist.linux-x86_64/egg/syft\n",
            "creating build/bdist.linux-x86_64/egg/syft/serde\n",
            "copying build/lib/syft/serde/native_serde.py -> build/bdist.linux-x86_64/egg/syft/serde\n",
            "copying build/lib/syft/serde/__init__.py -> build/bdist.linux-x86_64/egg/syft/serde\n",
            "copying build/lib/syft/serde/serde.py -> build/bdist.linux-x86_64/egg/syft/serde\n",
            "copying build/lib/syft/serde/torch_serde.py -> build/bdist.linux-x86_64/egg/syft/serde\n",
            "creating build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/federated/__init__.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/federated/federated_client.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/federated/plan.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "copying build/lib/syft/federated/train_config.py -> build/bdist.linux-x86_64/egg/syft/federated\n",
            "creating build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/websocket_client.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/abstract.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/base.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/__init__.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/websocket_server.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/virtual.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/workers/tfe.py -> build/bdist.linux-x86_64/egg/syft/workers\n",
            "copying build/lib/syft/__init__.py -> build/bdist.linux-x86_64/egg/syft\n",
            "copying build/lib/syft/grid.py -> build/bdist.linux-x86_64/egg/syft\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook\n",
            "copying build/lib/syft/frameworks/torch/hook/hook_args.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook\n",
            "copying build/lib/syft/frameworks/torch/hook/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook\n",
            "copying build/lib/syft/frameworks/torch/hook/hook.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook\n",
            "copying build/lib/syft/frameworks/torch/overload_torch.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/pointers/pointer_tensor.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/pointers/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/pointers/object_wrapper.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/pointers/callable_pointer.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "copying build/lib/syft/frameworks/torch/pointers/object_pointer.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated\n",
            "copying build/lib/syft/frameworks/torch/federated/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated\n",
            "copying build/lib/syft/frameworks/torch/federated/dataset.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated\n",
            "copying build/lib/syft/frameworks/torch/federated/dataloader.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated\n",
            "copying build/lib/syft/frameworks/torch/federated/utils.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto\n",
            "copying build/lib/syft/frameworks/torch/crypto/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto\n",
            "copying build/lib/syft/frameworks/torch/crypto/spdz.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto\n",
            "copying build/lib/syft/frameworks/torch/crypto/securenn.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto\n",
            "copying build/lib/syft/frameworks/torch/functions.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/abstract.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/native.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/gradients.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/plusisminus.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/derivatives.yaml -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/additive_shared.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/precision.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/polynomial.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/autograd.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/build_gradients.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/gradients_core.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "copying build/lib/syft/frameworks/torch/tensors/interpreters/multi_pointer.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/decorators\n",
            "copying build/lib/syft/frameworks/torch/tensors/decorators/logging.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/decorators\n",
            "copying build/lib/syft/frameworks/torch/tensors/decorators/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/decorators\n",
            "copying build/lib/syft/frameworks/torch/tensors/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors\n",
            "copying build/lib/syft/frameworks/torch/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch\n",
            "copying build/lib/syft/frameworks/torch/torch_attributes.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/torch/differential_privacy\n",
            "copying build/lib/syft/frameworks/torch/differential_privacy/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/differential_privacy\n",
            "copying build/lib/syft/frameworks/torch/differential_privacy/pate.py -> build/bdist.linux-x86_64/egg/syft/frameworks/torch/differential_privacy\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/keras\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/keras/layers\n",
            "copying build/lib/syft/frameworks/keras/layers/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras/layers\n",
            "copying build/lib/syft/frameworks/keras/layers/constructor.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras/layers\n",
            "creating build/bdist.linux-x86_64/egg/syft/frameworks/keras/model\n",
            "copying build/lib/syft/frameworks/keras/model/sequential.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras/model\n",
            "copying build/lib/syft/frameworks/keras/model/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras/model\n",
            "copying build/lib/syft/frameworks/keras/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras\n",
            "copying build/lib/syft/frameworks/keras/README.md -> build/bdist.linux-x86_64/egg/syft/frameworks/keras\n",
            "copying build/lib/syft/frameworks/keras/hook.py -> build/bdist.linux-x86_64/egg/syft/frameworks/keras\n",
            "copying build/lib/syft/frameworks/__init__.py -> build/bdist.linux-x86_64/egg/syft/frameworks\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_sandbox.py to test_sandbox.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/pointers/test_callable_pointer.py to test_callable_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/pointers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/pointers/test_pointer_tensor.py to test_pointer_tensor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/federated/test_utils.py to test_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/federated/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/federated/test_dataset.py to test_dataset.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/federated/test_dataloader.py to test_dataloader.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/test_federated_learning.py to test_federated_learning.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/crypto/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/crypto/test_snn.py to test_snn.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_autograd.py to test_autograd.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_polynomial.py to test_polynomial.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_gc.py to test_gc.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_tensor.py to test_tensor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_precision.py to test_precision.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_additive_shared.py to test_additive_shared.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_multi_pointer.py to test_multi_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_variable.py to test_variable.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_native.py to test_native.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_logging.py to test_logging.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/tensors/test_parameter.py to test_parameter.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/test_hook.py to test_hook.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/differential_privacy/test_pate.py to test_pate.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/differential_privacy/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/torch/test_functions.py to test_functions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/generic/test_id_provider.py to test_id_provider.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/generic/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_local_worker.py to test_local_worker.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/conftest.py to conftest.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/keras/test_sequential.py to test_sequential.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/federated/test_federated_client.py to test_federated_client.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/federated/test_plan.py to test_plan.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/federated/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/federated/test_train_config.py to test_train_config.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/workers/test_virtual.py to test_virtual.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/workers/test_base.py to test_base.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/workers/test_worker.py to test_worker.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/workers/test_websocket_worker.py to test_websocket_worker.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/workers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_grid.py to test_grid.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_udacity.py to test_udacity.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_exceptions.py to test_exceptions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/test/test_serde.py to test_serde.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/generic/id_provider.py to id_provider.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/generic/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/generic/object_storage.py to object_storage.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/codes.py to codes.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/exceptions.py to exceptions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/serde/native_serde.py to native_serde.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/serde/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/serde/serde.py to serde.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/serde/torch_serde.py to torch_serde.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/federated_client.py to federated_client.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/plan.py to plan.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/federated/train_config.py to train_config.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/websocket_client.py to websocket_client.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/abstract.py to abstract.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/base.py to base.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/websocket_server.py to websocket_server.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/virtual.py to virtual.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/workers/tfe.py to tfe.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/grid.py to grid.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook/hook_args.py to hook_args.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/hook/hook.py to hook.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/overload_torch.py to overload_torch.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers/pointer_tensor.py to pointer_tensor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers/object_wrapper.py to object_wrapper.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers/callable_pointer.py to callable_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/pointers/object_pointer.py to object_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated/dataset.py to dataset.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated/dataloader.py to dataloader.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/federated/utils.py to utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto/spdz.py to spdz.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/crypto/securenn.py to securenn.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/functions.py to functions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/abstract.py to abstract.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/native.py to native.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/gradients.py to gradients.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/plusisminus.py to plusisminus.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/additive_shared.py to additive_shared.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/precision.py to precision.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/polynomial.py to polynomial.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/autograd.py to autograd.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/build_gradients.py to build_gradients.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/gradients_core.py to gradients_core.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/interpreters/multi_pointer.py to multi_pointer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/decorators/logging.py to logging.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/decorators/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/tensors/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/torch_attributes.py to torch_attributes.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/differential_privacy/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/torch/differential_privacy/pate.py to pate.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/layers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/layers/constructor.py to constructor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/model/sequential.py to sequential.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/model/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/keras/hook.py to hook.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syft/frameworks/__init__.py to __init__.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syft.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syft.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syft.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syft.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying syft.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/syft-0.1.19a1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing syft-0.1.19a1-py3.6.egg\n",
            "Copying syft-0.1.19a1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding syft 0.1.19a1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/syft-0.1.19a1-py3.6.egg\n",
            "Processing dependencies for syft==0.1.19a1\n",
            "Searching for zstd==1.4.1.0\n",
            "Best match: zstd 1.4.1.0\n",
            "Adding zstd 1.4.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for websockets==8.0.1\n",
            "Best match: websockets 8.0.1\n",
            "Adding websockets 8.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for websocket-client==0.56.0\n",
            "Best match: websocket-client 0.56.0\n",
            "Adding websocket-client 0.56.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for torchvision==0.3.0\n",
            "Best match: torchvision 0.3.0\n",
            "Adding torchvision 0.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for torch==1.1.0\n",
            "Best match: torch 1.1.0\n",
            "Adding torch 1.1.0 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tf-encrypted==0.5.7\n",
            "Best match: tf-encrypted 0.5.7\n",
            "Adding tf-encrypted 0.5.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tblib==1.4.0\n",
            "Best match: tblib 1.4.0\n",
            "Adding tblib 1.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scikit-learn==0.21.2\n",
            "Best match: scikit-learn 0.21.2\n",
            "Adding scikit-learn 0.21.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.16.4\n",
            "Best match: numpy 1.16.4\n",
            "Adding numpy 1.16.4 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for msgpack==0.6.1\n",
            "Best match: msgpack 0.6.1\n",
            "Adding msgpack 0.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for lz4==2.1.10\n",
            "Best match: lz4 2.1.10\n",
            "Adding lz4 2.1.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Flask-SocketIO==4.2.0\n",
            "Best match: Flask-SocketIO 4.2.0\n",
            "Adding Flask-SocketIO 4.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Flask==1.1.1\n",
            "Best match: Flask 1.1.1\n",
            "Adding Flask 1.1.1 to easy-install.pth file\n",
            "Installing flask script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.12.0\n",
            "Best match: six 1.12.0\n",
            "Adding six 1.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Pillow==4.3.0\n",
            "Best match: Pillow 4.3.0\n",
            "Adding Pillow 4.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for PyYAML==5.1.1\n",
            "Best match: PyYAML 5.1.1\n",
            "Adding PyYAML 5.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorflow==1.14.0\n",
            "Best match: tensorflow 1.14.0\n",
            "Adding tensorflow 1.14.0 to easy-install.pth file\n",
            "Installing freeze_graph script to /usr/local/bin\n",
            "Installing saved_model_cli script to /usr/local/bin\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "Installing tf_upgrade_v2 script to /usr/local/bin\n",
            "Installing tflite_convert script to /usr/local/bin\n",
            "Installing toco script to /usr/local/bin\n",
            "Installing toco_from_protos script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for joblib==0.13.2\n",
            "Best match: joblib 0.13.2\n",
            "Adding joblib 0.13.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scipy==1.3.0\n",
            "Best match: scipy 1.3.0\n",
            "Adding scipy 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for python-socketio==4.3.0\n",
            "Best match: python-socketio 4.3.0\n",
            "Adding python-socketio 4.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Click==7.0\n",
            "Best match: Click 7.0\n",
            "Adding Click 7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Werkzeug==0.15.5\n",
            "Best match: Werkzeug 0.15.5\n",
            "Adding Werkzeug 0.15.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for itsdangerous==1.1.0\n",
            "Best match: itsdangerous 1.1.0\n",
            "Adding itsdangerous 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Jinja2==2.10.1\n",
            "Best match: Jinja2 2.10.1\n",
            "Adding Jinja2 2.10.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for olefile==0.46\n",
            "Best match: olefile 0.46\n",
            "Adding olefile 0.46 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorboard==1.14.0\n",
            "Best match: tensorboard 1.14.0\n",
            "Adding tensorboard 1.14.0 to easy-install.pth file\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for wrapt==1.11.2\n",
            "Best match: wrapt 1.11.2\n",
            "Adding wrapt 1.11.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Keras-Preprocessing==1.1.0\n",
            "Best match: Keras-Preprocessing 1.1.0\n",
            "Adding Keras-Preprocessing 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Keras-Applications==1.0.8\n",
            "Best match: Keras-Applications 1.0.8\n",
            "Adding Keras-Applications 1.0.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for absl-py==0.7.1\n",
            "Best match: absl-py 0.7.1\n",
            "Adding absl-py 0.7.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for gast==0.2.2\n",
            "Best match: gast 0.2.2\n",
            "Adding gast 0.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for grpcio==1.15.0\n",
            "Best match: grpcio 1.15.0\n",
            "Adding grpcio 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for protobuf==3.7.1\n",
            "Best match: protobuf 3.7.1\n",
            "Adding protobuf 3.7.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for termcolor==1.1.0\n",
            "Best match: termcolor 1.1.0\n",
            "Adding termcolor 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tensorflow-estimator==1.14.0\n",
            "Best match: tensorflow-estimator 1.14.0\n",
            "Adding tensorflow-estimator 1.14.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for google-pasta==0.1.7\n",
            "Best match: google-pasta 0.1.7\n",
            "Adding google-pasta 0.1.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for astor==0.8.0\n",
            "Best match: astor 0.8.0\n",
            "Adding astor 0.8.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for wheel==0.33.4\n",
            "Best match: wheel 0.33.4\n",
            "Adding wheel 0.33.4 to easy-install.pth file\n",
            "Installing wheel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for python-engineio==3.9.0\n",
            "Best match: python-engineio 3.9.0\n",
            "Adding python-engineio 3.9.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for MarkupSafe==1.1.1\n",
            "Best match: MarkupSafe 1.1.1\n",
            "Adding MarkupSafe 1.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for setuptools==41.0.1\n",
            "Best match: setuptools 41.0.1\n",
            "Adding setuptools 41.0.1 to easy-install.pth file\n",
            "Installing easy_install script to /usr/local/bin\n",
            "Installing easy_install-3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Markdown==3.1.1\n",
            "Best match: Markdown 3.1.1\n",
            "Adding Markdown 3.1.1 to easy-install.pth file\n",
            "Installing markdown_py script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for h5py==2.8.0\n",
            "Best match: h5py 2.8.0\n",
            "Adding h5py 2.8.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for syft==0.1.19a1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0730 13:44:33.990236 139716123875200 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0730 13:44:34.005762 139716123875200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rH43NCDHpLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Arg14U-ASzh9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net1, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        return F.max_pool2d(x, 2, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1dpCwgUSzXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Net1()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55SVy3TSTEeG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "150f440a-1a73-43f6-84e0-d8749408b9de"
      },
      "source": [
        "for p in model.parameters():\n",
        "  print(p[0][0][0][0].nelement())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-6d5666813772>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BfrtLhiTGkA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=torch.tensor([1,2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQZM0-W2Nw-q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5a178604-4aa2-4230-bddb-af45fb618e6c"
      },
      "source": [
        "a.element_size()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtT5qyJqNzMs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b43aa8a9-8efc-43d5-be90-95dbe5dba4d4"
      },
      "source": [
        "a.nelement()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiPfcoywN99u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f84ff64d-5d90-441b-bcb7-f75f5a23c929"
      },
      "source": [
        "a.dtype"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nll9ANSyV3gh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b = torch.tensor([1.,2.])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BujTXn3eWlZq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "813e9493-09a7-49b9-ef4a-d973d40a5887"
      },
      "source": [
        "b.element_size()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icrFPLk9Wo5o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d30f484a-a4c9-4cfc-9515-79c1bca3628f"
      },
      "source": [
        "b.dtype"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDqWw5NiWrAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d8c07242-ff3e-447e-fe9b-c466bad60782"
      },
      "source": [
        "b.nelement()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcMgxfSzWvcv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "34758339-8ee6-47fd-bf41-f27d3d86c44d"
      },
      "source": [
        "for p in model.parameters():\n",
        "  print(p.element_size(),p.nelement())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4 500\n",
            "4 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlGB--w1W3IR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAUCU1fOMPKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXHS7FV4sNhf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.arange(0.6,100,0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDIq04SPsWEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y1 = 1/X+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIE7c8ZGseKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y2 = 2/X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikvXWHYbsiQV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "63a7ea82-e94b-47e9-b343-40f9f2cb3fcf"
      },
      "source": [
        "plt.plot(X,Y1)\n",
        "plt.plot(X,Y2)\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZEWpHAXEWlB/x+Hu9MkwM2imAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZp9ac2tsoCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}